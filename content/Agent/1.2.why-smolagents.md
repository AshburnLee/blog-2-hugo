+++
date = '2025-04-30T12:13:26+08:00'
draft = false
title = '1.2.why Smolagents'
tags = ["Agent","Smolagents","prompts.yaml"]
categories = ["Agent"]
+++


`Smolagents` 是一个框架，用户通过它构建自己的agents。其他的框架包括 `LlamaIndex` 和 `LangGraph`

**它专注于 CodeAgent**，就是通过 code 块执行 Actions，并且 Observe 结果。

`Smolagents` 会执行 TAO cycle 来回应给他打指令。


# First glance

在 HF 自己的空间中，创建一个 `HF_TOKEN`，确保有 inference 权限。

HF 中的 workspace 称作 `Space`，进入自己的 `<USERNAME>/First_agent_template` 的 `Space`。查看 `Files`，其中的`app.y` 是 main 文件。

比如，Smolagents [CodeAgent 模版](https://huggingface.co/spaces/agents-course/First_agent_template/blob/main/app.py)


## `app.py` 中有什么

1. import 了 Smolagents
2. 定义了两个 tools，一个是计算当前时间，另一个是空的，由自己发挥
3. `model = HfApiModel()` 中给出来使用到了LLM模型：`Qwen/Qwen2.5-Coder-32B-Instruct` 。这个就是前文提到的 serveless API。使用托管的LLM，而非本地部署的LLM。
4. 让模型可见自定义的工具，通过在 CodeAgent 中添加 自定义工具列表即可。而且不需要给 tool 参数，LLM会自行传入。
5. 特殊工具 `FinalAnswerTool` 的作用是 终止 **TAO 循环**并提供最终答案，表示 Agent 任务完成。


## KAQ：Smolagents 如何体现 TAO 循环？

~~~py
agent = CodeAgent(
    model=model,
    tools=[final_answer], # tools 列表
    max_steps=6,  # 参数限制了 TAO/ReAct 循环的迭代次数，避免无限循环。
    verbosity_level=1,
    grammar=None,
    planning_interval=None,
    name=None,
    description=None,
    prompt_templates=prompt_templates  # ！
)
~~~

**TAO 循环**不是用户定义的，而是 Smolagents 框架内部架构的核心部分，通过 ReAct 框架实现。上述CodeAgent 的参数 `max_steps=6 `限制了 TAO/ReAct 循环的迭代次数。

框架自动捕获执行输出或错误（观察阶段）并反馈给 LLM。这是 Smolagents 的内置功能，用户无需定义。框架自动捕获执行输出或错误（观察阶段）并反馈给 LLM。这是 Smolagents 的内置功能，用户无需定义。

LLM 根据 `prompt_templates` 推理任务和工具使用。这个是 TAO 中的 `Thought`。

~~~py
with open("prompts.yaml", 'r') as stream:
    prompt_templates = yaml.safe_load(stream)
~~~

`prompts.yaml` 是用户定义的，指导 LLM 如何理解人户和调用工具


## KAQ：`prompts.yaml` 影响了LLM的行为方式？TAO、ReAct 其实是从这个文件中体现的？ 

Smolagents 可能提供默认模板或示例，用户可以直接使用或修改。或者用户设计或自定义。**默认模板**可能不完全适配特定任务或工具，用户通常需要根据自己的工具集和任务需求进行调整。

CodeAgent 中，`prompts.yaml` 是驱动 TAO / ReAct 框架的关键组件。

## KAQ：所以 编写 `prompts.yaml` 及其重要？对于使用Smolagents？

待验证


## Smolagents 的主要优势包括

1. 简单：代码复杂度小，抽象程度低，易于理解和使用。
2. 灵活地集成大模型：通过集成HF工具和外部API，可以与任何LLM 一同工作。
3. **首要支持 CodeAgent**：agents 自己写工具的 python code，并执行。（JSON Action 需要解析JSON, code action 很直接）
4. 与 HF 集成，可以使用 Gradio Spaces。**并且在 HF 社区共享tools & Agents。**


## 使用 Smolagents 的情形

1. 当需要**轻量级**和 minimal 的解决方案时
2. 当需要**快速实验**并且没有负责配置时
3. 当app的**逻辑是较为直接**的时候


## Smolagents 代理类型

Smolagents 中的 agent 都是 multi-step 的 agents，每一个 `MultiStepAgent` 执行一个 Thought。一个 ToolCall 和 execution。

CodeAgent 是 Smolagents 的主要类型，他还支持 `ToolCallingAgent`，即上述的 将工具调用写入 JSON，但是需要解析 JSON。


## Smolagent 中 tool 的定义

工具是使用 `@tool` 装饰器包装一个 Python 函数或 Tool 类来定义的。


## Smolagents 中模型的集成

只要复合[条件](https://huggingface.co/docs/smolagents/main/en/reference/models)，就可以集成任何LLM.

该框架提供了一些**预定义的类来帮助大模型链接**：

1. `TransformersModel`：实现本地 transformers 管道，实现无缝集成。
2. `InferenceClientModel`：通过 Hugging Face 的基础设施支持无服务器推理调用，或通过越来越多的第三方推理提供者。
3. `LiteLLMModel`：利用 LiteLLM 进行轻量级模型交互。
4. `OpenAIServerModel`：连接到任何提供 OpenAI API 接口的服务。
5. `AzureOpenAIServerModel`: 支持与任何 Azure OpenAI 部署集成。

根据自己的使用场景选择大模型，并且容易地进行实验。


## KAQ: code agent 既然可以自己实现 Python 工具并调用，为什么还要设计者自己实现 python code

开发者仍然需要手动编写代码来实现复杂的、创新的、高质量的应用程序。开发者编写代码能够更好地控制代码的逻辑、性能、安全性和可维护性。Code Agent 应该被视为开发者的辅助工具，而不是替代品。


## KAQ：Smolagents 框架可以实现多种模态的输入（图像输入）吗？，可以返回图像输出吗

这取决于用户使用的 LLM 的能力，如果用户使用的是支持图像输入和输出的 LLM 如 `Qwen/Qwen2-VL-7B-Instruct`，那么 Smolagents 框架就能够实现多种模态的输入输出。
