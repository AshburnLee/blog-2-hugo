+++
date = '2025-04-30T12:13:32+08:00'
draft = false
title = '3.4.实例sentence Embedding'
tags = ["Agent","LangChain"]
categories = ["Agent"]
+++


`paraphrase-multilingual-MiniLM-L12-v2` 是一个预训练的 Sentence Transformers 模型，由 Hugging Face 社区提供，专门用于生成句子的语义嵌入（embeddings）。这是个公开模型，不需要 `huggingface token`。

下载内容有 MiniLM 模型权值文件，配置文件，分词文件，等，下载位置是 `~/.cache/huggingface/hub/`

首次调用 HuggingFaceEmbeddings 时，如果本地无缓存，sentence-transformers 会自动从 Hugging Face Hub 下载。

`Chroma.from_documents` 创建一个本地的向量数据库，将文档嵌入存储在内存或磁盘中，`collection_name="weather_collection"` 是数据库中用于组织文档的集合名称。

~~~py
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

# 定义文档列表
docs = [
    Document(page_content="上海的天气通常在夏季炎热潮湿，冬季寒冷干燥。夏季平均气温约 30°C，冬季约 5°C。", metadata={"city": "上海", "source": "weather_guide"}),
    Document(page_content="北京的天气四季分明，夏季炎热，冬季非常寒冷且有沙尘暴。冬季气温可低至 -10°C。", metadata={"city": "北京", "source": "weather_guide"}),
    Document(page_content="广州的天气全年温暖，夏季多雨，冬季温和。年平均气温约 22°C。", metadata={"city": "广州", "source": "weather_guide"})
]

# 初始化 sentence-transformers 嵌入模型
embedding_model = HuggingFaceEmbeddings(
    model_name="paraphrase-multilingual-MiniLM-L12-v2",  # 支持中文的多语言模型
    model_kwargs={"device": "cpu"}  # 可改为 "cuda" 如果有 GPU
)

# 初始化 Chroma 向量存储
# Vector Store 是 LangChain 的核心组件之一
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embedding_model,
    collection_name="weather_collection"
)

# 创建检索器，设置 top-k=1
retriever = vectorstore.as_retriever(search_kwargs={"k": 1})

# 查询
query = "有沙尘暴的城市"

# 调用检索器,索引相关内容
results = retriever.invoke(query)

# 输出结果
print("查询:", query)
print("\n检索结果:")
for i, doc in enumerate(results, 1):
    print(f"文档 {i}:")
    print(f"内容: {doc.page_content}")
    print(f"元数据: {doc.metadata}")
    
"""
正确输出
"""
~~~

