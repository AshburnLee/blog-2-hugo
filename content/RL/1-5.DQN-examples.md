+++
date = '2025-08-31T12:52:04+08:00'
draft = true
title = '1.5.DQN Examples'
tags = ["Reinforcement Learning"]
categories = ["Reinforcement Learning"]
+++



è®­ç»ƒ Space Invaders 

ä½¿ç”¨RL baselines3-zoo åº“ï¼Œå®ƒåŸºäº stable baseline3ï¼Œå®ƒæä¾›äº†è®­ç»ƒçš„è„šæœ¬ï¼Œè¯„ä¼°Agentï¼Œè°ƒå‚æ•°ï¼Œç”»å›¾ï¼Œç­‰ã€‚

ç›®æ ‡ï¼š

1. ç†è§£ RLbaselines3-zoo åº“çš„ä½¿ç”¨
2. è®­ç»ƒè‡ªå·±çš„Agentï¼Œpush codeåˆ° huggingfaceï¼Œ

push your trained model to the Hub and get a result of >= 200.


colab å°†å…¶ä»–åœ°æ–¹çš„notebook æ‹·è´åˆ°è‡ªå·±çš„colabä¸‹ã€‚

ä¸ºäº†è®­ç»ƒä¸€ä¸ª RL-Baselines3-Zoo çš„agent, éœ€è¦åšçš„äº‹æƒ…ï¼š

1. åˆ›å»ºä¸€ä¸ªåä¸ºdqn.ymlçš„é…ç½®æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æˆ‘ä»¬çš„è®­ç»ƒè¶…å‚æ•°ã€‚

~~~yml
# é’ˆå¯¹ç‰¹å®šç¯å¢ƒ SpaceInvadersNoFrameskip-v4 çš„é…ç½®ï¼Œnoframeskip è¡¨ç¤ºæ¯ä¸€å¸§éƒ½å¤„ç†
SpaceInvadersNoFrameskip-v4:  
  # ç¯å¢ƒå˜é‡å°è£…ï¼Œå¯¹ç¯å¢ƒè¿›è¡Œé¢„å¤„ç†
  env_wrapper:  
    # ä½¿ç”¨ Atari å°è£…å™¨ï¼Œä½¿ç”¨ Stable Baselines3 æä¾›çš„ Atari å°è£…å™¨ï¼ŒåŒ…æ‹¬ç°åº¦åŒ–ã€ç¼©æ”¾ç­‰é¢„å¤„ç†æ­¥éª¤ï¼Œä»¥ç®€åŒ–ç¯å¢ƒå¹¶æé«˜è®­ç»ƒæ•ˆç‡ã€‚
    - stable_baselines3.common.atari_wrappers.AtariWrapper  
  # å¸§å †å æ•°é‡ï¼Œå°†è¿ç»­çš„ 4 å¸§å †å åœ¨ä¸€èµ·ä½œä¸ºè¾“å…¥ï¼Œå¸®åŠ©ç½‘ç»œç†è§£æ—¶é—´ä¿¡æ¯
  frame_stack: 4  
  # ä½¿ç”¨çš„ç­–ç•¥ç½‘ç»œç±»å‹ï¼ŒCnnPolicy è¡¨ç¤ºå·ç§¯ç¥ç»ç½‘ç»œç­–ç•¥ï¼Œé€‚ç”¨äºå›¾åƒè¾“å…¥
  policy: 'CnnPolicy'  
  # æ€»çš„è®­ç»ƒæ­¥æ•°ï¼Œè¿™é‡Œæ˜¯ 100 ä¸‡æ­¥
  n_timesteps: !!float 1e6  
  # å›æ”¾ç¼“å†²åŒºçš„å¤§å°ï¼Œç”¨äºå­˜å‚¨ç»éªŒæ ·æœ¬ï¼Œè¿™é‡Œæ˜¯ 10 ä¸‡
  buffer_size: 100000  
  # å­¦ä¹ ç‡ï¼Œç”¨äºæ§åˆ¶ç½‘ç»œæƒé‡æ›´æ–°çš„å¹…åº¦ï¼Œè¿™é‡Œæ˜¯ 0.0001
  learning_rate: !!float 1e-4  
  # æ‰¹é‡å¤§å°ï¼Œæ¯æ¬¡æ›´æ–°ç½‘ç»œæ—¶ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼Œè¿™é‡Œæ˜¯ 32
  batch_size: 32  
  # å¼€å§‹å­¦ä¹ çš„æ—¶é—´æ­¥ï¼Œåœ¨æœ€åˆçš„ 10 ä¸‡æ­¥å†…ï¼Œä¸è¿›è¡Œç½‘ç»œæ›´æ–°ï¼Œç”¨äºæ”¶é›†è¶³å¤Ÿå¤šçš„ç»éªŒ
  learning_starts: 100000  
  # ç›®æ ‡ç½‘ç»œæ›´æ–°çš„é¢‘ç‡ï¼Œæ¯ 1000 æ­¥æ›´æ–°ä¸€æ¬¡ç›®æ ‡ç½‘ç»œ
  target_update_interval: 1000  
  # è®­ç»ƒé¢‘ç‡ï¼Œæ¯ 4 æ­¥è¿›è¡Œä¸€æ¬¡ç½‘ç»œæ›´æ–°
  train_freq: 4  
  # æ¢¯åº¦æ­¥æ•°ï¼Œæ¯æ¬¡è®­ç»ƒæ›´æ–°çš„æ¢¯åº¦æ­¥æ•°ï¼Œè¿™é‡Œæ˜¯ 1
  gradient_steps: 1  
   # æ¢ç´¢æ¯”ä¾‹ï¼Œåœ¨è®­ç»ƒåˆæœŸï¼Œæ¢ç´¢çš„æ¯”ä¾‹è¾ƒé«˜ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ¢ç´¢æ¯”ä¾‹é€æ¸é™ä½ï¼Œè¿™é‡Œæ˜¯ 0.1
  exploration_fraction: 0.1 
  # æœ€ç»ˆçš„æ¢ç´¢ç‡ï¼Œåœ¨æ¢ç´¢æ¯”ä¾‹é™åˆ°æœ€ä½æ—¶ï¼Œä¿æŒçš„æ¢ç´¢ç‡ï¼Œè¿™é‡Œæ˜¯ 0.01
  exploration_final_eps: 0.01  

  # If True, you need to deactivate handle_timeout_termination
  # in the replay_buffer_kwargs
  # æ˜¯å¦ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¦‚æœè®¾ç½®ä¸º Trueï¼Œéœ€è¦ç¦ç”¨ replay_buffer_kwargs ä¸­çš„ handle_timeout_termination
  optimize_memory_usage: False  
~~~
åœ¨æœ‹å‹ä»–å’Œä½ notebookä¸­é€šè¿‡é­”æœ¯å‘½ä»¤å°†å†…å®¹å†™å…¥æ–‡ä»¶ï¼š

~~~
%%writefile dqn.yml
line1
line2
line3
~~~


2. å¼€å§‹è®­ç»ƒå¹¶æŠŠè®­ç»ƒå¥½çš„æ¨¡å‹ å­˜è¿› logs folder

`python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml`

è¿™é‡Œçš„å®æˆ˜åªæ˜¯åœ¨å‘½ä»¤ä¸­æŒ‡å®šçš„ dqn è¿™ä¸ªç®—æ³•ï¼Œä¸è®¾è®¡ä»»ä½• dqn çš„ç»†èŠ‚ã€‚


3. è¯„ä¼°è®­ç»ƒå¥½çš„Agent

`python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/`


## è®­ç»ƒå¥½çš„ Agent


The Stable-Baselines3 team uploaded more than 150 trained Deep Reinforcement Learning agents on the Hub.

You can find them here: ğŸ‘‰ https://huggingface.co/sb3

Some examples:

  - Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4
  - Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4
  - Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4
  - Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4

Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4

