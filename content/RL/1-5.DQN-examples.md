+++
date = '2025-08-31T12:52:04+08:00'
draft = true
title = '1.5.DQN Examples'
tags = ["Reinforcement Learning"]
categories = ["Reinforcement Learning"]
+++



训练 Space Invaders 

使用RL baselines3-zoo 库，它基于 stable baseline3，它提供了训练的脚本，评估Agent，调参数，画图，等。

目标：

1. 理解 RLbaselines3-zoo 库的使用
2. 训练自己的Agent，push code到 huggingface，

push your trained model to the Hub and get a result of >= 200.


colab 将其他地方的notebook 拷贝到自己的colab下。

为了训练一个 RL-Baselines3-Zoo 的agent, 需要做的事情：

1. 创建一个名为dqn.yml的配置文件，其中包含我们的训练超参数。

~~~yml
# 针对特定环境 SpaceInvadersNoFrameskip-v4 的配置，noframeskip 表示每一帧都处理
SpaceInvadersNoFrameskip-v4:  
  # 环境变量封装，对环境进行预处理
  env_wrapper:  
    # 使用 Atari 封装器，使用 Stable Baselines3 提供的 Atari 封装器，包括灰度化、缩放等预处理步骤，以简化环境并提高训练效率。
    - stable_baselines3.common.atari_wrappers.AtariWrapper  
  # 帧堆叠数量，将连续的 4 帧堆叠在一起作为输入，帮助网络理解时间信息
  frame_stack: 4  
  # 使用的策略网络类型，CnnPolicy 表示卷积神经网络策略，适用于图像输入
  policy: 'CnnPolicy'  
  # 总的训练步数，这里是 100 万步
  n_timesteps: !!float 1e6  
  # 回放缓冲区的大小，用于存储经验样本，这里是 10 万
  buffer_size: 100000  
  # 学习率，用于控制网络权重更新的幅度，这里是 0.0001
  learning_rate: !!float 1e-4  
  # 批量大小，每次更新网络时使用的样本数量，这里是 32
  batch_size: 32  
  # 开始学习的时间步，在最初的 10 万步内，不进行网络更新，用于收集足够多的经验
  learning_starts: 100000  
  # 目标网络更新的频率，每 1000 步更新一次目标网络
  target_update_interval: 1000  
  # 训练频率，每 4 步进行一次网络更新
  train_freq: 4  
  # 梯度步数，每次训练更新的梯度步数，这里是 1
  gradient_steps: 1  
   # 探索比例，在训练初期，探索的比例较高，随着训练的进行，探索比例逐渐降低，这里是 0.1
  exploration_fraction: 0.1 
  # 最终的探索率，在探索比例降到最低时，保持的探索率，这里是 0.01
  exploration_final_eps: 0.01  

  # If True, you need to deactivate handle_timeout_termination
  # in the replay_buffer_kwargs
  # 是否优化内存使用，如果设置为 True，需要禁用 replay_buffer_kwargs 中的 handle_timeout_termination
  optimize_memory_usage: False  
~~~
在朋友他和你notebook中通过魔术命令将内容写入文件：

~~~
%%writefile dqn.yml
line1
line2
line3
~~~


2. 开始训练并把训练好的模型 存进 logs folder

`python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml`

这里的实战只是在命令中指定的 dqn 这个算法，不设计任何 dqn 的细节。


3. 评估训练好的Agent

`python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/`


## 训练好的 Agent


The Stable-Baselines3 team uploaded more than 150 trained Deep Reinforcement Learning agents on the Hub.

You can find them here: 👉 https://huggingface.co/sb3

Some examples:

  - Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4
  - Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4
  - Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4
  - Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4

Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4

