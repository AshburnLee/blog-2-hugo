+++
date = '2025-05-31T12:52:04+08:00'
draft = false
title = '1.6.tools Find Parameters'
tags = ["Reinforcement Learning","Optuna"]
categories = ["Reinforcement Learning"]
+++


[来自](https://www.youtube.com/watch?v=AidFTOdGNFQ)

# Optuna

Deep RL 中有一个重要的任务是找到好的训练超参数。库[Optuna](https://optuna.org/) 帮助自动化这个搜索。


# 自动化超参数微调

什么是超参数：是需要手动设置参数，不会通过学习算法本身进行优化，不模型内部的参数不同，超参数是需要在模型开始训练前就设定好。

在强化学习中，常见的超参数包括：

  - 学习率 (Learning Rate)：控制 Q 网络或策略更新的幅度。
  - 折扣因子 (Discount Factor)：决定未来奖励对当前决策的影响程度。
  - 探索率 (Exploration Rate)：控制智能体探索环境的程度。
  - 回放缓冲区大小 (Replay Buffer Size)：决定存储多少经验样本。
  - 批量大小 (Batch Size)：每次更新网络时使用的样本数量。
  - 神经网络结构 (Network Architecture)：例如，神经网络的层数和每层的神经元数量。
  - 优化器 (Optimizer)：例如，Adam、RMSprop 等。
  - 目标网络更新频率 (Target Network Update Frequency)：控制目标 Q 网络更新的频率。

为什么要搜索超参数？超参数的选择对强化学习算法的性能有很大影响。不同的超参数值可能导致算法收敛速度、稳定性和最终性能的显著差异。

常见超参数搜索方法：Manual Search，Grid Search, Random Search, Bayesian Optimization，Evolutionary Algorithms, 模拟退火等随机性算法。


自动超参数微调的组件: Sampling && Schedular，

## 1. Sampler，搜索算法，如何选择采样点？

在搜索空间中搜索最优解的问题。

给定一个搜索空间（也称为解空间或状态空间）和一个目标函数（也称为适应度函数或成本函数），目标是在搜索空间中找到使目标函数达到最大值（或最小值）的解。

本质上是一个优化问题 (Optimization Problem)。

优化问题可表示为：
~~~
maximize f(x)   或   minimize f(x)
subject to x ∈ S
~~~

x属于搜索空间，找到一个x使得目标函数最大化或最小化。

常见解法：

  - 梯度下降 (Gradient Descent)：一种基于梯度的优化算法，适用于连续可导的目标函数。
  - 遗传算法 (Genetic Algorithm)：一种基于生物进化思想的优化算法，适用于离散和连续优化问题。
  - 粒子群优化 (Particle Swarm Optimization)：一种基于鸟群觅食行为的优化算法，适用于连续优化问题。
  - 模拟退火 (Simulated Annealing)：一种基于物理退火过程的优化算法，适用于离散和连续优化问题。
  - 贝叶斯优化 (Bayesian Optimization)：一种基于贝叶斯模型的优化算法，适用于目标函数评估成本高的问题。


## 2. Schedular, 决定了如何给每一次实验分配预算

有一个平衡 trade-off，“N vs B/n trade-off”

# 步骤

1. 定义搜索空间
2. 定义目标函数，你要优化什么？
3. 选择 Sampler && Schedular
4. 跑起来

# Optuna 实例

[这里](https://youtu.be/ihP7E76KGOI)
