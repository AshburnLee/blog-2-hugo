+++
date = '2025-08-31T12:49:36+08:00'
draft = true
title = 'Read as Needed'
tags = ["LLM"]
categories = ["LLM"]
+++

- LLM 部署的高级框架:文本生成推理（TGI）、vLLM 和 llama.cpp

- Attention 机制
    - Standard attenion
    - Flash Attention
    - vLLM 采用 PagedAttention

- KV 缓存内存管理

- 【done】llama.cpp 可以在各种硬件上运行，依赖项极少，且拥有简单的 C/C++ 核心

- 【done】利用框架 部署LLM（已完成，使用Ollama 部署在 Jetson ORIN上）

