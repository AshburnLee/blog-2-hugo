+++
date = '2025-08-31T12:49:36+08:00'
draft = true
title = '1.4.read as Needed'
tags = ["LLM"]
categories = ["LLM"]
+++

- LLM 部署的高级框架:文本生成推理（TGI）、vLLM 和 llama.cpp

- Attention 机制
    - Standard attenion
    - Flash Attention
    - vLLM 采用 PagedAttention

- KV 缓存内存管理

- llama.cpp 可以在各种硬件上运行，依赖项极少，且拥有简单的 C/C++ 核心

- 利用框架 部署LLM【已完成，使用Ollama 部署在 Jetson ORIN上】

