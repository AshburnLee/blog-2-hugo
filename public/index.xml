<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Content on Junhui&#39;s Journal 2</title>
    <link>https://ashburnLee.github.io/blog-2-hugo/</link>
    <description>Recent content in Content on Junhui&#39;s Journal 2</description>
    <generator>Hugo -- 0.149.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Aug 2025 12:57:46 +0800</lastBuildDate>
    <atom:link href="https://ashburnLee.github.io/blog-2-hugo/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Triton Workflow</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/triton-workflow/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:46 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/triton-workflow/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-s&#34; data-lang=&#34;s&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TorchDynamo &lt;span style=&#34;color:#75715e&#34;&gt;#FX Graph。是一个即时编译器，将一系列 PyTorch 操作转换成一个 FX 图 。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 这个 FX 图是一个中间表示，可以被不同的后端编译器优化和执行。 TorchDynamo 本身并&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 不直接进行优化，而是将优化工作交给其他的后端，例如 Inductor。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;Inductor &lt;/span&gt;(这是一个编译器后端 , 它接收 TorchDynamo 生成的 FX 图，并将它们编译成优化的 C&lt;span style=&#34;color:#f92672&#34;&gt;++/&lt;/span&gt;Triton 内核) 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#  Inductor 将 TorchDynamo 提供的 FX 图转换成其自身的 IR，这个 IR 考虑了循环融合、内存访问优化等因素。 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 然后，Inductor 会根据目标硬件 (GPU 或 CPU) 和其他配置，将这个自身 IR 转换成优化的代码。 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 对于 GPU，它会使用 Triton 作为代码生成的后端。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;(Triton Kernels)  &lt;span style=&#34;color:#75715e&#34;&gt;# @triton.jit, python function。 用户使用 Python 和 Triton API &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 定义 Triton kernel 的计算逻辑，Triton 编译器将这个 Python 定义的 kernel 转换成实际的 CUDA 或 ROCm 代码，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 作为最终的 GPU kernel。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## Triton 里边&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# FrontEnd 是 python 表达的计算-&amp;gt; Triton IR&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TritonDialect, Triton IR [upstream]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Comnbine pass
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Braodcast reordering
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Tensor pointer rewriting
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; other optimizers &lt;span style=&#34;color:#66d9ef&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Middle End&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TritonGPU Dialect, TrtionGPU IR [upstream]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Pass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Coalescing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Layout conversion removal
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; Thread Locality optimization
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# TritonGPU Dialect 中最重要的是通过添加Layout 来改变一个tensor的表示形式，表达一个data在GPU的thread是&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 如何partition的&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# .mlir 文件中的变量会通过 Blocked 和 Shared 这两中Layout 类型描述，blocked 表示数据切割方式是有 blocked 定义，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 如: &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# #blocked0 = #triton_gpu.blocked&amp;lt;{versionMajor = 3, &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  versionMinor = 0, &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  warpsPerCTA = [8, 1], &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  CTAsPerCGA = [1, 1], &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  CTASplitNum = [1, 1], &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  CTAOrder = [1, 0], &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#                                  instrShape = [16, 256, 32]}&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 它定义了数据的切割方式&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# %cts : tensor&amp;lt;256xi1, #blocked0&amp;gt;, 逗号前是 mlir 定义的，后边是 TritonGPUDialect 自己定义的&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[Shared Layout, Distributed &lt;span style=&#34;color:#a6e22e&#34;&gt;layout &lt;/span&gt;(Block layout), Do operand laytout, MMA layout]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## BackEnd&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Intel (&amp;amp;NV, AMD) 各家vendor自己的Dialect&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Intel specified Dialect&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; TritonGEN, TritonIntelGPU 和 许多优化Pass。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;At the same time re&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;use most of the Triton upstream infrastructure and optimizations
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vvv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LLVM Dialect, LLVM IR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vvv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Intel&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; GenISA&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;GenX  &lt;span style=&#34;color:#75715e&#34;&gt;# IGC 编译器得到 SPIRV 中间表示, Intel 没有与 nvcc 对应的工具来生成asambly，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 所以只能生成 SPIRV，然后使用官方的工具将 SPIRV 翻译为 LLVM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Nvidia&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; cubin &lt;span style=&#34;color:#75715e&#34;&gt;#  nvcc 得到 PTX 表示（nvcc 会生成 PTX（一种IR，与硬件无关）代码，并将其传递给 ptxas，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 最终得到cubin，它是针对特定 GPU 架构编译的二进制可执行文件）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# IGC has 2 path to compile Triton kernels: SIMT &amp;amp; SIMD (Triton 走 SIMT，没有应用IMEX)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# SIMD： lowerTritonGPU IR to lowe level IR and maps to XeGPU Dialect (来自IMEX)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;|||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    vvv
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Runtime &lt;span style=&#34;color:#75715e&#34;&gt;# IPEX, 目前是 Stock Pytorch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;tools-spirv-llvm-translator&#34;&gt;Tools SPIRV-LLVM-Translator&lt;/h1&gt;
&lt;h2 id=&#34;in-tree-mode-在-mlir-project-中使用&#34;&gt;In-tree mode 在 mlir project 中使用&lt;/h2&gt;
&lt;p&gt;cmake 中通过使用 FetchContent(cmake, in-tree mode) 作为依赖构建它的编译， 详见 open source code。&lt;/p&gt;</description>
    </item>
    <item>
      <title>网络 Clash</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/%E7%BD%91%E7%BB%9C-clash/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:46 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/%E7%BD%91%E7%BB%9C-clash/</guid>
      <description>&lt;h1 id=&#34;路由路径&#34;&gt;路由路径&lt;/h1&gt;
&lt;p&gt;查看Windows系统中的路由路径，可以使用命令行工具 tracert（Trace Route），它可以显示数据包从本机到目标主机经过的每个路由节点（跳数），帮助分析路由路径和每跳延迟。也可使用 pathping 命令结合了 ping 和 tracert 的功能，带来更详细的路径和丢包统计。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tracert 目标域名或IP地址
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pathping www.baidu.com
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;cookies&#34;&gt;cookies&lt;/h1&gt;
&lt;p&gt;Cookie 是网页服务器发送到你的浏览器中并储存的一小段数据文件（文本信息）。网页浏览器会保存这些Cookie，并在你访问同一网站时自动发送给服务器，使服务器能够识别你之前的访问和身份，并为你提供个性化服务。&lt;/p&gt;
&lt;h1 id=&#34;requests-库&#34;&gt;requests 库&lt;/h1&gt;
&lt;p&gt;requests 库是基于 HTTP 协议的客户端库。&lt;code&gt;requests.get()&lt;/code&gt; 等方法默认且仅支持 &lt;code&gt;HTTP/HTTPS&lt;/code&gt; 请求，这些方法定义的请求类型（&lt;code&gt;GET、POST、PUT、DELETE&lt;/code&gt;等）都是 HTTP 协议定义的动作。&lt;/p&gt;
&lt;p&gt;在发送请求时，优势需要给出&lt;code&gt;header&lt;/code&gt;。用来传递额外的元信息，比如访问指定服务器的 token。&lt;code&gt;headers&lt;/code&gt; 是一个字典，可以张这样：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;GITHUB_TOKEN &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; xxx  &lt;span style=&#34;color:#75715e&#34;&gt;# Copy your GitHub token here&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;headers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;User-Agent&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MyApp/1.0&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Authorization&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bearer my_secret_token&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accept&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;application/json&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Authorization&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;token &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;GITHUB_TOKEN&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://api.example.com/data&amp;#34;&lt;/span&gt;, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;headers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;status_code)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;json())
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;路由器负责将局域网的私有-ip-地址转换为互联网上的公网-ip-地址从而保证了互联网上的地址唯一性&#34;&gt;路由器负责将局域网的私有 IP 地址转换为互联网上的公网 IP 地址，从而保证了互联网上的地址唯一性&lt;/h1&gt;
&lt;p&gt;用一个具体的例子来说明路由器如何将局域网的私有 IP 地址转换为互联网上的公网 IP 地址，从而保证互联网地址的唯一性（通过 （Network Address Translation）NAT）。&lt;/p&gt;
&lt;p&gt;场景： 一个家庭网络，包含一台路由器、一台笔记本电脑和一手机。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenkins</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/jenkins/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:45 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/jenkins/</guid>
      <description>&lt;h2 id=&#34;tutorial&#34;&gt;tutorial&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Pipline &amp;amp; jenkinsfile 手册：https://www.jenkins.io/doc/book/pipeline/getting-started/&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供的全局变量 &lt;code&gt;env.&lt;/code&gt;: &lt;code&gt;&amp;lt;Jenkins master的地址&amp;gt;/pipeline-syntax/globals#env&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pipline 实例：https://www.jenkins.io/doc/pipeline/examples/&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;尽可能应用jenkins提供的命令而不是一股脑儿使用shell脚本&#34;&gt;尽可能应用Jenkins提供的命令，而不是一股脑儿使用shell脚本&lt;/h2&gt;
&lt;p&gt;比如，git clone，使用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;checkout &lt;span style=&#34;color:#a6e22e&#34;&gt;scmGit&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;branches: &lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt;name: params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;BRANCH&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                extensions: &lt;span style=&#34;color:#f92672&#34;&gt;[],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                userRemoteConfigs: &lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt;credentialsId: params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;GITHUB_CREDENTIAL&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; url: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://github.com/xxx.git&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;jenkins是面向过程的对于任务配置多考虑使用表驱动&#34;&gt;jenkins是面向过程的，对于任务配置，多考虑使用表驱动&lt;/h2&gt;
&lt;h2 id=&#34;pipline-中访问-env-变量&#34;&gt;Pipline 中访问 env 变量&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stage&lt;span style=&#34;color:#f92672&#34;&gt;(){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    println &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;WORKSPACE: ${env.WORKSPACE}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    echo env&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;WORKSPACE&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    echo WORKSPACE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;环境变量可以通过 Groovy 代码访问，方式为 &lt;code&gt;env.VARNAME&lt;/code&gt; 或者直接使用 &lt;code&gt;VARNAME&lt;/code&gt;。你也可以修改这些属性，但只能通过使用 &lt;code&gt;env.&lt;/code&gt; 前缀来写入。所以：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jenkins job 中有保留的 env 变量，避免疑惑这些变量要加上 &lt;code&gt;env.&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;env 变量即使在机器上设定了，也是可以修改的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;groovy中的数学计算&#34;&gt;groovy中的数学计算&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; number &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;243&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 要计算的数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; fifthRoot &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; number &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/5)  /&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;计算&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;次方根&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;两种pipline&#34;&gt;两种pipline&lt;/h2&gt;
&lt;p&gt;在Jenkins中，有两种主要类型的Pipeline：Scripted Pipeline 和 Declarative Pipeline。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scripted Pipeline【我的工作中都是这种的脚本】:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;使用Groovy语法编写，允许更灵活的流程控制和自定义逻辑。&lt;/li&gt;
&lt;li&gt;通过node和stage等关键字来定义流水线的执行节点和阶段。&lt;/li&gt;
&lt;li&gt;可以直接编写Groovy脚本来构建流水线。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Declarative Pipeline:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;使用更结构化的语法，更易于阅读和维护。&lt;/li&gt;
&lt;li&gt;通过pipeline、agent、stages等关键字来定义流水线的结构和执行环境。&lt;/li&gt;
&lt;li&gt;提供了更丰富的语法来定义构建、部署和测试等阶段。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jenkins-中如何在多个-node-并行执行任务&#34;&gt;jenkins 中如何在多个 NODE 并行执行任务&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-groovy&#34; data-lang=&#34;groovy&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; parallel_tasks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[:]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;GPU_TASK&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    parallel_tasks&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GPU_TASK&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        node&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;GPU_NODE&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            stage&lt;span style=&#34;color:#f92672&#34;&gt;(){}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;CPU_TASK&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    parallel_tasks&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CPU_TASK&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        node&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;params&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;CPU_NODE&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            stage&lt;span style=&#34;color:#f92672&#34;&gt;(){}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;parallel&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;parallel_tasks&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;elvis-操作符-&#34;&gt;Elvis 操作符 &lt;code&gt;?:&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;这两句句话有什么不同：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux Shell</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/linux-shell/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:45 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/linux-shell/</guid>
      <description>&lt;h2 id=&#34;内存占用排序&#34;&gt;内存占用排序&lt;/h2&gt;
&lt;p&gt;实时查看和排序： &lt;code&gt;top → Shift+M&lt;/code&gt; 键入 &amp;lsquo;c&amp;rsquo; 隐藏/显示 完整命令&lt;/p&gt;
&lt;p&gt;快速查看排序列表： &lt;code&gt;ps aux --sort=-rss | head -10&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在资源受限的 Jetson 系统上是自愿检测的有力工具。&lt;/p&gt;
&lt;h2 id=&#34;cpptools-srv&#34;&gt;cpptools-srv&lt;/h2&gt;
&lt;p&gt;cpptools语言服务器。该进程提供代码智能提示（IntelliSense）、代码补全、语法检查、调试支持等功能。负责解析你的C/C++项目源代码，提升编辑和调试体验。&lt;/p&gt;
&lt;h2 id=&#34;vscode-ssh-链接服务-问题&#34;&gt;vscode ssh 链接服务 问题&lt;/h2&gt;
&lt;p&gt;VSCode 通过 SSH 连接目标服务器时，发现该服务器的主机密钥（host key）与本地保存的记录不一致。&lt;/p&gt;
&lt;p&gt;查看host上的key：&lt;code&gt;C:\Users\name\.ssh\kown_hosts&lt;/code&gt; 中的记录&lt;/p&gt;
&lt;p&gt;和&lt;/p&gt;
&lt;p&gt;服务器上的key：&lt;code&gt;ssh-keyscan -t rsa 192.168.x.x&lt;/code&gt; 应该一致。&lt;/p&gt;
&lt;p&gt;不一致时，将 host 上的删除，重新链接。不能删除服务器上的。因为你是host，想要链接服务器，你改变服务器的 key，很荒唐。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-t&lt;/code&gt; 指定密钥算法类型（rsa、ecdsa、ed25519等），所以你要先看看是哪个算法。发现两者密钥不一致，应该先确认服务器端主机密钥的正确性和安全性，然后删除本地客户端的旧密钥记录，再重新连接接受新的服务器密钥。&lt;/p&gt;
&lt;h2 id=&#34;服务器上的-key-secure-shell-host-key&#34;&gt;服务器上的 key 【Secure Shell Host Key】&lt;/h2&gt;
&lt;p&gt;ssh host key 是服务器用来唯一标识自身的SSH密钥对中的公钥部分。&lt;/p&gt;
&lt;p&gt;这个密钥是&lt;strong&gt;服务器的身份证&lt;/strong&gt;，用来确保客户端连接的是正确的服务器。当你用 VSCode 连接服务器时，VSCode（通过它的SSH扩展）会自动从服务器&lt;strong&gt;拉取&lt;/strong&gt;该服务器的host key（公钥），并在本地 &lt;strong&gt;known_hosts 文件里缓存&lt;/strong&gt;起来。这个过程并不是生成密钥，而是“拿到”和“保存”服务器提前生成好的密钥，以便后续验证。&lt;/p&gt;
&lt;p&gt;在大多数 Linux 服务器系统安装过程中，系统会自动调用 ssh-keygen 生成一组 SSH 主机密钥对（包括公钥和私钥），文件通常存放在 &lt;code&gt;/etc/ssh/&lt;/code&gt; 目录下，如 &lt;code&gt;ssh_host_rsa_key&lt;/code&gt; 和对应的 &lt;code&gt;.pub&lt;/code&gt; 文件等。用于 永久性保存用于识别服务器身份。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/python/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:45 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/python/</guid>
      <description>&lt;h2 id=&#34;pyenv--poetry&#34;&gt;pyenv &amp;amp;&amp;amp; poetry&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt upgrade
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv install 3.9.0 -v &lt;span style=&#34;color:#75715e&#34;&gt;#建议不要使用系统python，而是为虚拟环境安装独立python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 如果上述命令失败，看看log，大概率是某个package没有安装，log 通过 去掉 ‘-v’&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建一个名为 ppo_me 的 virtualenv，它基于 Python 3.9.0 版本。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv virtualenv 3.9.0 ppo_me
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 激活虚拟环境。在当前目录下创建一个 .python-version 文件，并将 ppo_me 写入该文件。 当你进入这个目录或其子目录时，pyenv 会自动读取 .python-version 文件，并将 Python 环境设置为 ppo_me 这个 virtualenv。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv local ppo_me
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 删除ppo_me 的虚拟环境，并删除对应的Python版本。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv deactivate
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv virtualenv-delete ppo_me
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv uninstall 3.10.14
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -rf .python-version 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv install 3.9.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv virtualenv 3.9.0 ppo_me
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建一个 .python-version 文件，指定该项目使用的虚拟环境。 当你进入项目目录时，pyenv 会自动激活该虚拟环境。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pyenv local ppo_me
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;【KAQ】： 然后在当前目录下 执行 which python， 还是返回系统 Python 版本，而不是 指定的虚拟空间中的3.9.0 为什么? 通过 pyenv rehash&lt;/p&gt;</description>
    </item>
    <item>
      <title>CICD</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cicd/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:44 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cicd/</guid>
      <description>&lt;p&gt;回忆 Jenkin 是如何实现当 PR push 时自动触发执行的？需要找一个 jenkins 插件帮助我实现 PR 通过 关键字 触发 CI.&lt;/p&gt;
&lt;p&gt;使用什么插件？尝试了 “GitHub Branch Source” 中的 “Multibranch Pipeline projects”，需要在目标 repo 的根目录中创建并编辑 JenkinsFile 文件并且在 github repo 中配置一个webhook，每当有新 PR 到这个 repo，扫描 repo 并触发新 branch 执行 JenkinsFile。每一个 branch 触发一个 job，而这个 job 是不能通过修改 job config 来参数化的，需要通过 property step 在 JenkinsFile 中将这个branch 的 job 参数化。如此就可以执行任何内容了。&lt;/p&gt;
&lt;h1 id=&#34;pytest&#34;&gt;Pytest&lt;/h1&gt;
&lt;h2 id=&#34;pytest-测试框架&#34;&gt;Pytest 测试框架&lt;/h2&gt;
&lt;p&gt;pytest 提供了许多装饰器，比如 &lt;code&gt;@pytest.mark.parametrize&lt;/code&gt; 让你为一个测试用例提供多个输入（输出参数，不同参数之间会进行&lt;strong&gt;笛卡尔积组合&lt;/strong&gt;）。减少了重复代码。&lt;/p&gt;
&lt;p&gt;更多用法 看看 pytest 命令参数。结果有4中状态，xfailed 等。实例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pytest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@pytest.mark.parametrize&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;a&amp;#34;&lt;/span&gt;, [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@pytest.mark.parametrize&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;, [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;test_example&lt;/span&gt;(a, b):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Testing with a=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;a&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; and b=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;b&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 输出将会是：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Testing with a=1 and b=x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Testing with a=1 and b=y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Testing with a=2 and b=x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Testing with a=2 and b=y&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;跳过某些-test-cases&#34;&gt;跳过某些 test cases&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;pytest.mark.skip&lt;/code&gt; 标记 case。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;--deselect-from-file&lt;/code&gt; 接受一个文件，这个文件中的所有 cases 都会被跳过。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;--ignore=test_xxx.py&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;与-pytest-一同使用的插件&#34;&gt;与 pytest 一同使用的插件&lt;/h2&gt;
&lt;p&gt;pytest-select&lt;/p&gt;</description>
    </item>
    <item>
      <title>Git</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/git/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:44 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/git/</guid>
      <description>&lt;p&gt;Push 和提 PR 是两个概念。&lt;strong&gt;一个PR其实是一个分支的概念&lt;/strong&gt;，push 就 PR 该后，需要在 github 页面中手动提 PR（当然也可以通过gh命令）。这里要表达的是push和提PR是两回事。&lt;/p&gt;
&lt;p&gt;要想在 github 页面显示自己的分支，必须要 push。不想让别人看见自己的分支就不要提 PR。&lt;/p&gt;
&lt;h1 id=&#34;git&#34;&gt;Git&lt;/h1&gt;
&lt;h2 id=&#34;常用命令&#34;&gt;常用命令&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git log --oneline
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rm -r --cached build  &lt;span style=&#34;color:#75715e&#34;&gt;# 将git上的build文件夹删除，同时保留本地。然后commit push后，远端的build也就被删除了。这里有个cache的概念。 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git reflog
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git reset --hard 1359d449
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git show-ref --verify --quiet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rebase
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rev-parse HEAD
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git submodule sync &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; git submodule update --init --recursive
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git diff &amp;gt; my.diff
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git apply my.diff  &lt;span style=&#34;color:#75715e&#34;&gt;# 在新的 branch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone --single-branch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git log --author&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Author Name&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git log --grep&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git revert
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git config --list
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git commit --amend -m &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;new commit message&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git push origin junhui_typo --force
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git reset --soft HEAD^  &lt;span style=&#34;color:#75715e&#34;&gt;# 撤销上一个commit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git reset --hard HEAD^  &lt;span style=&#34;color:#75715e&#34;&gt;# 撤销所有commit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git reset --hard        &lt;span style=&#34;color:#75715e&#34;&gt;# 撤销上一个操作（当上一个操作结果不如预期时）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;如果我有两个commit先有commit-a-后有commit-b如何在commit-a中修改代码&#34;&gt;如果我有两个commit，先有commit a 后有commit b，如何在commit a中修改代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# To modify code in commit a, you can use the `git rebase` command.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Here&amp;#39;s an example:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1. Start an interactive rebase session&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rebase -i HEAD~2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 2. In the interactive rebase editor, change &amp;#34;pick&amp;#34; to &amp;#34;edit&amp;#34; for commit a&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#    and save the file&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 3. Git will stop at commit a. Now you can modify the code as needed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 在commit a中添加你的修改&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4. Stage the changes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5. Amend the commit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git commit --amend  &lt;span style=&#34;color:#75715e&#34;&gt;# 似乎不能是 --no-edit, 佛则这个commit就会消失&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 6. Continue the rebase&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rebase --continue
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# The code in commit a is now modified.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;3个commit压缩为一个commit&#34;&gt;3个commit，压缩为一个commit&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# step1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rebase -i lastCommitID  //lastCommitID 倒数第四次提交
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# OR&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git rebase -i HEAD~3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# step2 vim 编辑&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 要把*下面*两个红色框 ‘pick’ 改为‘s’,表示第三次提交合并入第二次，第二次提交合并入第一次。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 保存退出&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git push -f BRANCHNAME
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;cherry-pick&#34;&gt;Cherry-pick&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    a - b - c - d     Master
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;           e - f - g  Feature
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout master
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Cherry pick 操作, 【仅仅pick这一个commit】&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git cherry-pick f
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#结果&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    a - b - c - d - f   Master
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;           e - f - g    Feature
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 若有冲突，解决后&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git cherry-pick --continue
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;优势：cherry-pick 比笨方法好，笨方法会将重命名后的文件都保留&lt;/p&gt;</description>
    </item>
    <item>
      <title>Github Actions</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/github-actions/</link>
      <pubDate>Sun, 31 Aug 2025 12:57:44 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/github-actions/</guid>
      <description>&lt;h2 id=&#34;使用-actionscache&#34;&gt;使用 actions/cache&lt;/h2&gt;
&lt;p&gt;如果你的工作流程经常运行，使用缓存来存储依赖项（如 Bandit）可以减少安装时间。
比如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Cache Python dependencies&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;uses&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;actions/cache@v2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;with&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;path&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;~/.cache/pip&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;key&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;${{ runner.os }}-pip-${{ hashFiles(&amp;#39;**/requirements.txt&amp;#39;) }}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          &lt;span style=&#34;color:#f92672&#34;&gt;restore-keys&lt;/span&gt;: |&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            ${{ runner.os }}-pip-&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;我的-github-workflow-工作流程经常运行但是不一定是在同一台机器上这种情况下actionscache-如何cache&#34;&gt;我的 github workflow 工作流程经常运行，但是不一定是在同一台机器上，这种情况下actions/cache 如何cache&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;actions/cache@v2&lt;/code&gt; 是跨工作流程和跨运行器设计的，这意味着即使工作流程在不同的机器上运行，缓存仍然是有效的。&lt;strong&gt;缓存是与仓库相关联的&lt;/strong&gt;，而不是与特定的运行器实例相关联。&lt;/p&gt;
&lt;p&gt;这是 &lt;code&gt;actions/cache&lt;/code&gt; 的一个重要特性。缓存不是存储在某一台特定的运行器或机器上，而是&lt;strong&gt;存储在 GitHub 的云端基础设施中&lt;/strong&gt;。当你使用 &lt;code&gt;actions/cache&lt;/code&gt; 创建缓存时，GitHub 会将缓存内容保存在其服务器上，这样无论后续的工作流程在哪里运行，都可以访问和恢复这些缓存。&lt;/p&gt;
&lt;h2 id=&#34;坑&#34;&gt;坑&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;actions/checkout@v4 只会最少的 repo 内容给你，与手动 clone 不同，所以你需要提供一些其他参数来给出更多的 commit 等信息。&lt;strong&gt;因为actions/checkout@v4 默认不会把历史commit 给你&lt;/strong&gt; 需要添加 &lt;code&gt;fetch-depth: 0&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;github 不希望你访问除了当前repo之外的目录，所以&lt;strong&gt;所有的操作都应该在这个repo的目录中&lt;/strong&gt;，比如你想clone例外一个repo，那么把它clone到当前repo的 external/new_repo&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由于GitHub Actions的安全限制，工作流中的步骤&lt;strong&gt;不能直接传递&lt;/strong&gt;输出到触发下一次工作流的schedule触发器。因此，你需要考虑其他方法来存储和检索PR编号，例如使用仓库的Secrets、工作流的**工件(artifacts)**或者外部存储服务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;${{ env.TARGET_PRID }}&lt;/code&gt; 这种方式的变量是 yml 变量，不应该在 shell 命令中使用（即不应该使用在 &lt;code&gt;run: |&lt;/code&gt;）,但功能上也可以在shell 中这样访问。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;echo &amp;quot;TARGET_PRID=$(&amp;lt;file_downloaded/PRID.txt)&amp;quot; &amp;gt;&amp;gt; $GITHUB_ENV&lt;/code&gt; 这句话表示将变量 &lt;code&gt;TARGET_PRID&lt;/code&gt; 放在环境变量中，并且在&lt;strong&gt;相同的job&lt;/strong&gt;中的后续步骤中的 shell 总可以直接访问 &lt;code&gt;$TARGET_PRID&lt;/code&gt;。而且 在非shell的地方可以通过 &lt;code&gt;{{ env.TARGET_PRID }}&lt;/code&gt; 访问其值。在当前job中之后的步骤里，已经有值了，生效了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.9.A2C</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-9.a2c/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:05 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-9.a2c/</guid>
      <description>&lt;p&gt;回顾 ppo-from scratch 后，在总结这篇文章。&lt;/p&gt;
&lt;p&gt;前面已经了解了 Policy-based 的方法的理论，这里学习 Policy-based 的一个算法：&lt;/p&gt;
&lt;p&gt;1-7 中学习了 Reinforce 是 Policy-Based 方法的一个子类，称为 Policy-Gradient methods。这个子类通过估计最优策略的权重来直接优化策略，使用梯度上升的方法。&lt;/p&gt;
&lt;p&gt;Policy-Based methods 直接参数化策略并优化策略，而不使用价值函数。&lt;/p&gt;
&lt;h2 id=&#34;问题是蒙特卡洛采样的估计方差很大&#34;&gt;问题是蒙特卡洛采样的估计方差很大&lt;/h2&gt;
&lt;p&gt;MC 的思想是使用完整的 episode 样本来估计回报，而这个过程就是一种采样。通过策略采样生成&lt;strong&gt;各个 Episode 的路径&lt;/strong&gt;（s,a,r的序列），然后使用 episode 中的实际奖励来计算回报，最后通过对多个 episode 的回报和策略梯度进行平均来估计整体的策略梯度。&lt;/p&gt;
&lt;p&gt;这种方式的估计会导致 策略梯度估计的方差（variance）很大。&lt;/p&gt;
&lt;h2 id=&#34;方差来源&#34;&gt;方差来源&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;随机性&lt;/strong&gt;：强化学习环境通常具有随机性。这意味着即使在相同的状态下采取相同的动作，也可能获得不同的奖励，并导致不同的后续状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;episode 长度&lt;/strong&gt;：episode 的长度可能会有很大的变化。有些 episode 可能很短，而有些 episode 可能很长。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;奖励的稀疏性&lt;/strong&gt;：在某些环境中，奖励可能非常稀疏。这意味着智能体可能需要运行很长时间才能获得一个正面的奖励。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;高方差的影响&#34;&gt;高方差的影响&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;不稳定的学习&lt;/strong&gt;：高方差会导致策略梯度估计不稳定，使得策略参数的更新方向波动很大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缓慢的收敛&lt;/strong&gt;：高方差会减慢算法的收敛速度，使得智能体需要更长的时间才能学习到最优策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对学习率的敏感性&lt;/strong&gt;：高方差会使得算法对学习率的选择非常敏感。如果学习率太大，可能会导致策略参数的更新方向错误；如果学习率太小，可能会导致学习速度过慢。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;actor-critic-methods&#34;&gt;Actor-Critic methods&lt;/h2&gt;
&lt;p&gt;Actor-Critic 方法，这是一种结合了价值方法和策略方法的混合架构，通过减小方差，来 Stablilize 训练过程。&lt;/p&gt;
&lt;h2 id=&#34;理解-actor-critic&#34;&gt;理解 Actor-Critic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Actor（行动者）：负责控制智能体的行为方式（基于策略的方法）。&lt;/li&gt;
&lt;li&gt;Critic（评论者）：负责评估所采取的行动的好坏（基于价值的方法）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actor 负责学习策略，决定在给定状态下应该采取什么动作；Critic 负责评估 Actor 的策略，告诉 Actor 它做得好不好。通过 Actor 和 Critic 的相互协作，可以更有效地学习到最优策略。&lt;/p&gt;
&lt;p&gt;Actor 根据 Critic 的评价来调整自己的策略。如果 Critic 认为某个动作是好的，Actor 就会更倾向于采取这个动作；如果 Critic 认为某个动作是坏的，Actor 就会&lt;strong&gt;减少采取这个动作的概率&lt;/strong&gt;。通过不断地学习和调整，Actor 最终可以学会一套最优的游戏策略。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Concept</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/concept/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:05 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/concept/</guid>
      <description>&lt;h2 id=&#34;环境包装器-environment-wrappers&#34;&gt;环境包装器 (environment wrappers)&lt;/h2&gt;
&lt;p&gt;是一种修改现有环境而不直接更改其底层代码的便捷方法 . 包装器允许您避免大量重复代码，并使您的环境更模块化 . 重要的是，包装器可以链接起来以组合它们的效果，并且大多数通过 gym.make() 【python gymnasium 包】生成的环境默认情况下已经被包装。&lt;/p&gt;
&lt;h3 id=&#34;环境包装器的作用&#34;&gt;环境包装器的作用:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;转换 Actions (动作)：&lt;/li&gt;
&lt;li&gt;转换 Observations (观测)：&lt;/li&gt;
&lt;li&gt;转换 Rewards (奖励)：&lt;/li&gt;
&lt;li&gt;自动重置环境：有些用户可能想要一个包装器，当其包装的环境达到完成状态时，该包装器将自动重置其包装的环境。这种环境的一个优点是，当超出完成状态时，它永远不会像标准 gym 环境那样产生未定义的行为。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;如何使用包装器&#34;&gt;如何使用包装器&lt;/h3&gt;
&lt;p&gt;要包装一个环境，您必须首先初始化一个基本环境。 然后，您可以将此环境以及（可能可选的）参数传递给包装器的构造函数&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; gymnasium &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; gym
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; gymnasium.wrappers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; RescaleAction
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建一个基本环境&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;base_env &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gym&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;make(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hopper-v4&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 使用 RescaleAction 包装器，将动作范围缩放到 [0, 1]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wrapped_env &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; RescaleAction(base_env, min_action&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, max_action&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;gymnasium-中的常见包装器&#34;&gt;Gymnasium 中的常见包装器&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;gymnasium.Wrapper: 所有包装器的基类&lt;/li&gt;
&lt;li&gt;gymnasium.ActionWrapper: 用于转换动作的包装器&lt;/li&gt;
&lt;li&gt;gymnasium.ObservationWrapper: 用于转换观测的包装器&lt;/li&gt;
&lt;li&gt;gymnasium.RewardWrapper: 用于转换奖励的包装器&lt;/li&gt;
&lt;li&gt;gym.wrappers.AutoResetWrapper: 用于自动重置环境的包装器&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;环境包装器是强化学习中一个强大的工具，可以帮助您修改和定制环境，以满足您的特定需求。它们提供了一种模块化和可重用的方式来转换动作、观测和奖励，并添加其他功能。&lt;/p&gt;
&lt;h2 id=&#34;归一化&#34;&gt;归一化&lt;/h2&gt;
&lt;p&gt;为什么RL 需要归一化？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提高训练稳定性：归一化可以使神经网络的输入或输出值接近正态分布，这有&lt;strong&gt;助于激活函数正常工作&lt;/strong&gt;，并避免随机初始化的参数需要被过度调整. 它可以减少模型对初始化的敏感性，使得训练过程更加稳定。&lt;/li&gt;
&lt;li&gt;加速收敛：归一化消除了数据特征之间的&lt;strong&gt;量纲影响&lt;/strong&gt;，使得梯度下降算法更快地找到全局最优解，从而加速模型的收敛速度。&lt;/li&gt;
&lt;li&gt;提高泛化能力：归一化可以减少&lt;strong&gt;特征之间的相关性&lt;/strong&gt;，从而提高模型的稳定性和精度，增强模型的泛化能力。&lt;/li&gt;
&lt;li&gt;允许使用更高的学习率：归一化可以使&lt;strong&gt;参数空间更加平滑&lt;/strong&gt;，因此可以使用更高的学习率，而不会导致训练过程不稳定。&lt;/li&gt;
&lt;li&gt;解决数据可比性问题：归一化可以将&lt;strong&gt;有量纲转化为无量纲&lt;/strong&gt;，同时将数据归一化至同一量级，解决数据间的可比性问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bellman-方程&#34;&gt;Bellman 方程&lt;/h2&gt;
&lt;p&gt;Value-based methods 通过迭代更新价值函数来学习。更新的依据是 贝尔曼方程 (Bellman Equation)，该方程描述了当前状态的价值与未来状态的价值之间的关系&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.4.DQN</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-4.dqn/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:04 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-4.dqn/</guid>
      <description>&lt;h2 id=&#34;deep-q-learning-dqn&#34;&gt;Deep-Q-learning (DQN)&lt;/h2&gt;
&lt;h3 id=&#34;环境&#34;&gt;环境&lt;/h3&gt;
&lt;p&gt;与环境有关，简单的环境中，state的可选个数（state space）是有限的， (16 different states for FrozenLake-v1 and 500 for Taxi-v3)，但是对于大部分都环境，State space 非常大，比如 10^9 到 10^11 个可选state。如此以来，更新 Q-table 就会非常低效。&lt;/p&gt;
&lt;p&gt;所以最好的方法是使用一个参数化的 Q-function（ Qθ​(s,a)，theta 是网络参数 ）来估计 Q-value。&lt;/p&gt;
&lt;p&gt;Deep Q-learning，不适用 Q-table ，而是通过一个NN，这个NN 根据一个state，给出这个 state 时不同 Action 的Q-value。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img alt=&#34;Q vs deep Q&#34; loading=&#34;lazy&#34; src=&#34;../../pics/deep.jpg&#34;&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;em&gt;Q vs deep Q&lt;/em&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;loss-function&#34;&gt;Loss function&lt;/h3&gt;
&lt;p&gt;创建一个损失函数，比较 Q-value预测 和 Q-target，并使用梯度下降来更新深度 Q 网络的权重以更好地近似 Q-value。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img alt=&#34;图片描述&#34; loading=&#34;lazy&#34; src=&#34;../../pics/Q-target.jpg&#34;&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;em&gt;Q-loss 这样计算&lt;/em&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;相同与q-learning&#34;&gt;相同与Q-learning&lt;/h2&gt;
&lt;p&gt;还是会用到 epsilon-greedy policy 确定在当前 state 执行哪个Action。&lt;/p&gt;
&lt;h2 id=&#34;输入预处理&#34;&gt;输入预处理&lt;/h2&gt;
&lt;p&gt;减少不必要的计算量，减少输入的不必要信息。通常，讲reduce frame 的尺寸，并且讲frame 灰度化（这个场景下，颜色并不会指导Agent的行为，反而增加不用计算量）。即将RGB 3通道改为1个通道。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.6.tools Find Parameters</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-6.tools-find-parameters/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:04 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-6.tools-find-parameters/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AidFTOdGNFQ&#34;&gt;来自&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;optuna&#34;&gt;Optuna&lt;/h1&gt;
&lt;p&gt;Deep RL 中有一个重要的任务是找到好的训练超参数。库&lt;a href=&#34;https://optuna.org/&#34;&gt;Optuna&lt;/a&gt; 帮助自动化这个搜索。&lt;/p&gt;
&lt;h1 id=&#34;自动化超参数微调&#34;&gt;自动化超参数微调&lt;/h1&gt;
&lt;p&gt;什么是超参数：是需要手动设置参数，不会通过学习算法本身进行优化，不模型内部的参数不同，超参数是需要在模型开始训练前就设定好。&lt;/p&gt;
&lt;p&gt;在强化学习中，常见的超参数包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率 (Learning Rate)：控制 Q 网络或策略更新的幅度。&lt;/li&gt;
&lt;li&gt;折扣因子 (Discount Factor)：决定未来奖励对当前决策的影响程度。&lt;/li&gt;
&lt;li&gt;探索率 (Exploration Rate)：控制智能体探索环境的程度。&lt;/li&gt;
&lt;li&gt;回放缓冲区大小 (Replay Buffer Size)：决定存储多少经验样本。&lt;/li&gt;
&lt;li&gt;批量大小 (Batch Size)：每次更新网络时使用的样本数量。&lt;/li&gt;
&lt;li&gt;神经网络结构 (Network Architecture)：例如，神经网络的层数和每层的神经元数量。&lt;/li&gt;
&lt;li&gt;优化器 (Optimizer)：例如，Adam、RMSprop 等。&lt;/li&gt;
&lt;li&gt;目标网络更新频率 (Target Network Update Frequency)：控制目标 Q 网络更新的频率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么要搜索超参数？超参数的选择对强化学习算法的性能有很大影响。不同的超参数值可能导致算法收敛速度、稳定性和最终性能的显著差异。&lt;/p&gt;
&lt;p&gt;常见超参数搜索方法：Manual Search，Grid Search, Random Search, Bayesian Optimization，Evolutionary Algorithms, 模拟退火等随机性算法。&lt;/p&gt;
&lt;p&gt;自动超参数微调的组件: Sampling &amp;amp;&amp;amp; Schedular，&lt;/p&gt;
&lt;h2 id=&#34;1-sampler搜索算法如何选择采样点&#34;&gt;1. Sampler，搜索算法，如何选择采样点？&lt;/h2&gt;
&lt;p&gt;在搜索空间中搜索最优解的问题。&lt;/p&gt;
&lt;p&gt;给定一个搜索空间（也称为解空间或状态空间）和一个目标函数（也称为适应度函数或成本函数），目标是在搜索空间中找到使目标函数达到最大值（或最小值）的解。&lt;/p&gt;
&lt;p&gt;本质上是一个优化问题 (Optimization Problem)。&lt;/p&gt;
&lt;p&gt;优化问题可表示为：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;maximize f(x)   或   minimize f(x)
subject to x ∈ S
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;x属于搜索空间，找到一个x使得目标函数最大化或最小化。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.7.Policy Bases Methods</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-7.policy-bases-methods/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:04 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-7.policy-bases-methods/</guid>
      <description>&lt;p&gt;RL 的目的是找到一个最优的 Policy，使得它可以找到 expected cumulative reward。&lt;/p&gt;
&lt;p&gt;方法有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ashburnLee.github.io/blog-2-hugo/rl/1-1.value-bases-methods/&#34;&gt;Value-Based&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Policy-Based&lt;/li&gt;
&lt;li&gt;Actor-Critic&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;policy-based-方法&#34;&gt;Policy-based 方法&lt;/h1&gt;
&lt;p&gt;Policy-based 方法直接学习一个策略，该策略将 State 映射到 Action 的概率分布。策略可以是确定性的 (deterministic)，即在给定状态下选择一个特定的行动；也可以是随机的 (stochastic)，即在给定状态下，对所有可能的行动给出一个概率分布。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img loading=&#34;lazy&#34; src=&#34;../../pics/stochastic_policy.png&#34;&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;em&gt;输入一个state，输出一个概率分布&lt;/em&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;policy-based-方法的核心&#34;&gt;Policy-based 方法的核心&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;策略参数化&lt;/strong&gt; (Policy Parameterization)：使用一个参数化的函数来表示策略。例如，可以使用神经网络来表示策略，网络的输入是状态，输出是行动的概率分布。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;目标函数&lt;/strong&gt; (Objective Function)：定义一个目标函数，用于评估策略的性能。目标函数通常是期望累积奖励 (expected cumulative reward)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;策略优化&lt;/strong&gt; (Policy Optimization)：使用优化算法来调整策略的参数，以最大化目标函数。常用的优化算法包括梯度上升 (gradient ascent) 和进化算法 (evolutionary algorithms)。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;policy-gradient-方法及常见实现&#34;&gt;Policy-Gradient 方法及常见实现&lt;/h1&gt;
&lt;p&gt;直接对 Policy 求梯度，然后更新参数。而非间接地寻找最优 Policy。&lt;/p&gt;
&lt;p&gt;Policy-Gradient 方法是 Policy-based 方法中最常用的一类算法。它使用&lt;strong&gt;梯度上升&lt;/strong&gt;来优化策略参数。常见实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Trust Region Policy Optimization&lt;/strong&gt; (TRPO)：一种改进的 Policy-Gradient 方法，可以提高训练稳定性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Proximal Policy Optimization&lt;/strong&gt; (PPO)：一种更简单、更高效的 TRPO 变体。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;policy-based-方法的一般步骤是什么&#34;&gt;Policy-Based 方法的一般步骤是什么？&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://ashburnLee.github.io/blog-2-hugo/rl/1-13.ppo-from-scratch/&#34;&gt;见ppo&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;policy-gradient-policy-参数更新&#34;&gt;Policy-gradient policy 参数更新&lt;/h1&gt;
&lt;p&gt;有个目标函数 &lt;code&gt;J(θ)&lt;/code&gt;,  通过更新参数 &lt;code&gt;θ&lt;/code&gt; 最大化这个目标函数，方法是梯度上升：&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.11.MARL</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-11.marl/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:03 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-11.marl/</guid>
      <description>&lt;p&gt;之前的内容，我们的环境中的只有一个 Agent，现实中，一个人是会与环境和环境中的其他 Agent 交互的。&lt;/p&gt;
&lt;p&gt;所以实际的需求是，我们希望可以在一个 Multi-agent system 中训练一个更加鲁棒的，可以适应并与其他 Agent 或人类合作。&lt;/p&gt;
&lt;h2 id=&#34;marl&#34;&gt;MARL&lt;/h2&gt;
&lt;p&gt;一个 Agent 只是与环境交互，多个 Agent 除了与环境交互，还要和其他 Agent 交互，所以Agent之间的交互可以分为以下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;合作：Agents 需要最大化 common 收益。&lt;/li&gt;
&lt;li&gt;竞争：Agents 需要最大化自己的收益，同时尽可能减少其他Agent的收益。&lt;/li&gt;
&lt;li&gt;混合：Agent 需要最大化己方的收益，同时减少敌队的收益。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;在-multi-agent-中-如何训练我们的-agent&#34;&gt;在 Multi-Agent 中 如何训练我们的 Agent&lt;/h2&gt;
&lt;p&gt;两种解决方法来设计 MARL&lt;/p&gt;
&lt;h3 id=&#34;1-去中心化的&#34;&gt;1. 去中心化的&lt;/h3&gt;
&lt;p&gt;每个 Agent 独立训练，就行之前的single agent一样，其他agent作为环境的一部分，只不过对于这个agent而言，这个环境变为动态的了。去中心化的设计，是 Non-Stationary 的， Markov decision process 一直在变化，导致agent永远不能学习到全局最优解。&lt;/p&gt;
&lt;h3 id=&#34;2-中心化的&#34;&gt;2. 中心化的&lt;/h3&gt;
&lt;p&gt;讲多个 Agents 视为一个 Entity ，他们共同学习一个相同的Policy。这时代 Reward 是全局的。&lt;/p&gt;
&lt;h2 id=&#34;self-play&#34;&gt;Self-Play&lt;/h2&gt;
&lt;p&gt;当对手太强时，你的Agent 总是会失败，是学习不到任何东西的。当对手它弱时，你的Agent总是胜利，总是 overlearn 一些没有用的行为。这两种情况，你的Agent都不能学习到好的Policy。&lt;/p&gt;
&lt;p&gt;最好的解决方案是有一个对手，它的水平和你一样，并且随着你的水平的提升而升级。这就是 Self_play。&lt;/p&gt;
&lt;p&gt;将自己拷贝一份作为自己的 对手，如此一来，你的Agent 的对手的水平就和你的水平是一样的（打败它会有挑战，但是不会太困难）。也就是，对手的Policy也是在逐渐变好（增强）的，你的Agent的policy也是逐渐增强的。&lt;/p&gt;
&lt;p&gt;这种机制是很自然的。没啥新的东西。&lt;/p&gt;
&lt;p&gt;Self_play 已经集成在了 Multi-Agent 库中，我们要关注的是超参数。这是个实例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;self_play&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;save_steps&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;50000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;team_change&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;200000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;swap_steps&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;2000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;window&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;play_against_latest_model_ratio&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;initial_elo&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1200.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;elo-score&#34;&gt;ELO Score&lt;/h2&gt;
&lt;p&gt;在对抗游戏中，通常使用 ELO Score 来评估 Agent 的水平。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.12.PPO</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-12.ppo/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:03 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-12.ppo/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Proximal Policy Optimization&lt;/strong&gt; 是基于 Actor-Critic 的一种算法，它的核&lt;strong&gt;心是通过不让 Policy 更新的太快，进而稳定训练过程&lt;/strong&gt;（与 KL div 所用类似）。&lt;/p&gt;
&lt;p&gt;为达成以上，使用使用一个比率来表示当前策略和旧策略之间的差异，并将此比率裁剪到特定的范围 $[1-\epsilon, 1+\epsilon]$ 中。&lt;/p&gt;
&lt;h2 id=&#34;intuition&#34;&gt;Intuition&lt;/h2&gt;
&lt;p&gt;当前策略（current policy）相对于之前策略（former policy）的变化程度 进行剪裁，这个范围通常是 $[1-\epsilon, 1+\epsilon]$ ，其中 $\epsilon$ 是一个小的超参数（例如0.2）。 如果比例小于 $1 - \epsilon$ ，则将其设置为 $1 - \epsilon$；如果比例大于 $1 + \epsilon$ ，则将其设置为 $1 + \epsilon$。&lt;/p&gt;
&lt;p&gt;所以 PPO 算法不允许当前策略相对于之前策略发生过大的变化。较之前策略&lt;strong&gt;过大的偏离将会被移除&lt;/strong&gt;，通过上述的 Clip 区间。&lt;/p&gt;
&lt;h2 id=&#34;举例说明&#34;&gt;举例说明&lt;/h2&gt;
&lt;p&gt;假设 $\epsilon = 0.2$，当前策略和之前策略在状态 s 下采取动作 a 的概率如下：&lt;/p&gt;
&lt;p&gt;$π_θ(a|s) = 0.8$（当前策略）, $π_θ^{old}(a|s) = 0.5$（之前策略）&lt;/p&gt;
&lt;p&gt;则比例为：&lt;code&gt;ratio = 0.8 / 0.5 = 1.6&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;由于 $1.6 &amp;gt; (1 + \epsilon) = 1.2$，因此需要对比例进行裁剪，将其设置为 &lt;code&gt;1.2&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.13.PPO From Scratch</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-13.ppo-from-scratch/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:03 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-13.ppo-from-scratch/</guid>
      <description>&lt;h1 id=&#34;工具&#34;&gt;工具&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;MuJoCo&lt;/strong&gt; environments 指的是使用 MuJoCo 物理引擎构建的模拟环境 . MuJoCo (Multi-Joint dynamics with Contact) 是一款用于机器人、生物力学、图形和动画等领域的研究和开发的物理引擎，它能够进行快速而精确的仿真。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CartPole-v1&lt;/strong&gt; 环境主要存在于 Gymnasium 库中，它是 Gym 库的后继者 。Gym 库已经停止更新，所有开发工作都已转移到 Gymnasium。&lt;/p&gt;
&lt;h2 id=&#34;cartpole-v1-环境信息&#34;&gt;CartPole-v1 环境信息&lt;/h2&gt;
&lt;p&gt;首先要知道 CartPole-v1 环境的动作和观测空间：&lt;/p&gt;
&lt;h3 id=&#34;1-动作空间-action-space&#34;&gt;1. 动作空间 (Action Space):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;类型: Discrete(2)&lt;/li&gt;
&lt;li&gt;动作数量: 2&lt;/li&gt;
&lt;li&gt;取值：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0: 将车向左推&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1: 将车向右推&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-观测空间-observation-space&#34;&gt;2. 观测空间 (Observation Space):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;类型: Box(4,)&lt;/li&gt;
&lt;li&gt;观测数量: 4&lt;/li&gt;
&lt;li&gt;取值：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0: 车的位置（Cart Position）&lt;/strong&gt;，范围为 &lt;code&gt;[-4.8, 4.8]&lt;/code&gt;，但如果超出 &lt;code&gt;[-2.4, 2.4]&lt;/code&gt; 范围，则 episode 结束&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1: 车的速度（Cart Velocity）&lt;/strong&gt;，范围为 &lt;code&gt;[-Inf, Inf]&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2: 杆的角度（Pole Angle）&lt;/strong&gt;，范围约为 &lt;code&gt;[-0.418 rad (-24°), 0.418 rad (24°)]&lt;/code&gt;，但如果超出 &lt;code&gt;[-0.2095, 0.2095]&lt;/code&gt; (±12°) 范围，则 episode 结束&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3: 杆的角速度（Pole Angular Velocity）&lt;/strong&gt;，范围为 &lt;code&gt;[-Inf, Inf]&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kaq-observation-和-state的区别&#34;&gt;KAQ: Observation 和 State的区别&lt;/h3&gt;
&lt;p&gt;在完全可观测环境中（如CartPole），&lt;strong&gt;Agent 可以直接获取环境的真实状态，即 observation 等于 state&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.2.Q Learning</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-2.q-learning/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:03 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-2.q-learning/</guid>
      <description>&lt;h2 id=&#34;q-learning中的元素&#34;&gt;Q-learning中的元素&lt;/h2&gt;
&lt;p&gt;Q-learning 算法中的 Q-function 就是 value-based 方法中的价值函数。Q-table 存储了 Q-function 的价值估计。&lt;/p&gt;
&lt;p&gt;Q-table 是一种表示 Q-function 的一种具体实现方式。适用于状态空间和动作空间都是&lt;strong&gt;离散且有限&lt;/strong&gt;的情况。当状态空间或动作空间很大时，需要使用其他函数逼近方法 来表示Q-function。Q-learning 更新规则就是更新 Q-table，即 Q-Learning 的更新规则直接作用于 Q-table，用于更新 Q-table 中存储的价值估计。通过不断地更新 Q-table，Q-Learning 可以学习到最优的 Q-function，从而帮助 Agent 做出最优的决策。&lt;/p&gt;
&lt;p&gt;Q-learning 是一种 TD approach 来训练Agent的 action-value function。使用全零初始化 Q-table，通过学习，将得到 optimal 的 Q-table 作为 Agent 的 cheat-sheet.&lt;/p&gt;
&lt;h2 id=&#34;recap-cumulative-reward-vs-immediate-reward&#34;&gt;Recap: Cumulative Reward VS Immediate Reward&lt;/h2&gt;
&lt;p&gt;一个 State 的 Value，或者 Q-table 中的 State-action 对儿，是 Agent 从当前 State 开始到结束的 Cumulative Reward&lt;/p&gt;
&lt;p&gt;Reward 是 Agent 在某个状态下执行操作后，从当前 State 中得到的及时反馈。&lt;/p&gt;
&lt;h2 id=&#34;q-learning-算法&#34;&gt;Q-learning 算法&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&#34;Q&#34; loading=&#34;lazy&#34; src=&#34;https://ashburnLee.github.io/blog-2-hugo/pics/Q-learning-2.png&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>0 1.学习路径 Source</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/0-1.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84-source/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:02 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/0-1.%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84-source/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://stable-baselines3.readthedocs.io/en/master/guide/rl.html&#34;&gt;https://stable-baselines3.readthedocs.io/en/master/guide/rl.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;openai-spinning-up&#34;&gt;OpenAI Spinning Up&lt;/h2&gt;
&lt;h2 id=&#34;the-deep-reinforcement-learning-course&#34;&gt;The Deep Reinforcement Learning Course&lt;/h2&gt;
&lt;h2 id=&#34;david-silvers-course&#34;&gt;David Silver’s course&lt;/h2&gt;
&lt;h2 id=&#34;lilian-wengs-blog&#34;&gt;Lilian Weng’s blog&lt;/h2&gt;
&lt;h2 id=&#34;berkeleys-deep-rl-bootcamp&#34;&gt;Berkeley’s Deep RL Bootcamp&lt;/h2&gt;
&lt;h2 id=&#34;berkeleys-deep-reinforcement-learning-course&#34;&gt;Berkeley’s Deep Reinforcement Learning course&lt;/h2&gt;
&lt;h2 id=&#34;dqn-tutorial&#34;&gt;DQN tutorial&lt;/h2&gt;
&lt;h2 id=&#34;decisions--dragons---faq-for-rl-foundations&#34;&gt;Decisions &amp;amp; Dragons - FAQ for RL foundations&lt;/h2&gt;
&lt;h2 id=&#34;more-resources&#34;&gt;More resources&lt;/h2&gt;</description>
    </item>
    <item>
      <title>1.0.RL框架</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-0.rl%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:02 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-0.rl%E6%A1%86%E6%9E%B6/</guid>
      <description>&lt;p&gt;note 来自 &lt;a href=&#34;https://huggingface.co/learn/deep-rl-course/unit0/introduction&#34;&gt;https://huggingface.co/learn/deep-rl-course/unit0/introduction&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;the-deep-reinforcement-learning-course&#34;&gt;The Deep Reinforcement Learning Course&lt;/h1&gt;
&lt;h2 id=&#34;账号&#34;&gt;账号&lt;/h2&gt;
&lt;p&gt;【done】创建 Hugging Face 账号
【done】创建 Hugging Face 的 Discord server
【done】使用 Discord&lt;/p&gt;
&lt;h2 id=&#34;1-rl-基本理论&#34;&gt;1. RL 基本理论&lt;/h2&gt;
&lt;p&gt;一个代理（AI）将从环境中通过与环境交互（试错），并接收奖励（正面或负面）作为反馈来学习。所以是无监督的学习。RL 仅仅是从行动中学习的计算方法。&lt;/p&gt;
&lt;p&gt;RL 的流程是 State、Action、Reward 和下一个 State 的&lt;strong&gt;循环&lt;/strong&gt;。Agent 的目的是最大化累计 Reward。所以 RL 是基于 Reward Hypothesis 的。&lt;/p&gt;
&lt;p&gt;Markov Decision Process (MDP) 简单讲：马尔可夫性质意味着我们的代理只需要当前状态来决定采取什么行动，而不需要它们之前所有状态的全部历史。&lt;/p&gt;
&lt;p&gt;Markov Decision Process 有以下要素组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态空间 (State Space, $S$)：所有可能的状态的集合，$S = {s_1, s_2, \dots}$&lt;/li&gt;
&lt;li&gt;动作空间 (Action Space, $A$)：所有可能的动作的集合，$A = {a_1, a_2, \dots}$&lt;/li&gt;
&lt;li&gt;状态转移概率 (Transition Probability, $P(s&amp;rsquo;|s, a)$)：在状态 $s \in S$ 下执行动作 $a \in A$ 后，转移到状态 $s&amp;rsquo; \in S$ 的概率。&lt;/li&gt;
&lt;li&gt;奖励函数 (Reward Function, $R(s, a)$)：在状态 $s \in S$ 下执行动作 $a \in A$ 后获得的奖励。&lt;/li&gt;
&lt;li&gt;折扣因子 (Discount Factor, $\gamma$)：用于衡量未来奖励的重要性, $\gamma \in [0, 1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;单 Agent 强化学习中，环境通常被认为是 Stationary 的，这意味着&lt;strong&gt;状态转移概率&lt;/strong&gt; $P$ 和&lt;strong&gt;奖励函数&lt;/strong&gt; $R$ &lt;strong&gt;不会随着时间变化&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.1.Value Bases Methods</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/rl/1-1.value-bases-methods/</link>
      <pubDate>Sun, 31 Aug 2025 12:52:02 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/rl/1-1.value-bases-methods/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;Learn about value-based methods.&lt;/li&gt;
&lt;li&gt;Learn about the differences between Monte Carlo and Temporal Difference Learning.&lt;/li&gt;
&lt;li&gt;Study and implement our first RL algorithm: Q-Learning.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;value-based-methods&#34;&gt;Value-Based Methods&lt;/h1&gt;
&lt;p&gt;先给出一个例子：假设你正在玩一个走迷宫的游戏。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;状态 (State): 你当前在迷宫中的位置。&lt;/li&gt;
&lt;li&gt;策略 (Policy): 你决定如何走迷宫 (例如，总是选择离终点最近的方向)。&lt;/li&gt;
&lt;li&gt;价值函数 (Value Function): 对于迷宫中的每个位置，价值函数会告诉你，如果你从这个位置开始，按照你的策略走，最终到达终点的可能性有多大 (或者说，你期望获得多少奖励，例如到达终点奖励 +1，每走一步奖励 -0.1)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Value-based methods 的目标就是学习这个价值函数。一旦你学会了价值函数，你就可以根据价值函数来选择行动，从而更快地到达终点。例如，如果你发现某个位置的价值很高，那么你就应该尽量走到那个位置。&lt;/p&gt;
&lt;p&gt;理解它的核心是理解 Value-based method 和 Policy-based method的区别。&lt;/p&gt;
&lt;h2 id=&#34;你先要有一个-policy&#34;&gt;你先要有一个 Policy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Value-based 是先给出一个 Policy，我们自己定义的（比如 Greedy Policy），来学习一个价值函数。实践中，通常会使用一个Epsilon-Greedy policy，它的另一个优势是处理 探索/利用的权衡。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Policy-based 是直接学习一个 Policy， $\pi(a | s) = P(a | s)$，它不需要一个价值函数。所以我们不会定义Policy 的行为，是训练的过程定义的这个 Policy。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jetson Ollama</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/ollama/jetson-ollama/</link>
      <pubDate>Sun, 31 Aug 2025 12:50:42 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/ollama/jetson-ollama/</guid>
      <description>&lt;p&gt;NVIDIA Orin 是一款专为&lt;strong&gt;自动驾驶汽车&lt;/strong&gt;和&lt;strong&gt;机器人&lt;/strong&gt;设计的高性能系统级芯片，包含新一代 Ampere GPU 架构和 Arm Hercules CPU 内核，以及深度学习加速器和计算机视觉加速器。&lt;/p&gt;
&lt;p&gt;应用领域：Orin 芯片不仅适用于自动驾驶汽车，还广泛应用于机器人、工业边缘计算等领域。&lt;/p&gt;
&lt;p&gt;支持C/C++, python, cuda, pytorch, ROS (Robot Operating System), JetPack SDK, DeepStream, VScode&lt;/p&gt;
&lt;p&gt;TensorRT 是 NVIDIA 开发的一个高性能深度学习推理 SDK。它不是完全开源的.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Linux for Tegra (L4T) &lt;/code&gt;是 NVIDIA 为其 Tegra 系列系统芯片 (SoC) 开发的嵌入式 Linux 发行版。它主要用于 NVIDIA Jetson 系列开发套件等嵌入式系统。L4T 提供了运行在 Tegra SoC 上的内核、驱动程序、库和工具，支持各种应用，包括机器人、人工智能、自动驾驶和媒体处理等。 它包含了 NVIDIA 专有的驱动程序，以充分利用 Tegra SoC 的硬件加速功能。不同的 L4T 版本支持不同的 Tegra 系列芯片和功能。 例如，较新的版本可能支持 Vulkan 和更新的 CUDA 版本。 开发者可以使用 L4T 来构建和部署各种嵌入式应用。&lt;/p&gt;
&lt;h1 id=&#34;部署-ollama&#34;&gt;部署 Ollama&lt;/h1&gt;
&lt;p&gt;Ollama 中的大模型（如 Llama、Qwen、DeepSeek、Gemma 等）本身与 Ollama 框架的本地使用是完全免费的。你可以免费下载、部署这些开源大模型在自己的设备上，运行、推理和本地开发时都免费，唯一成本是自己的硬件资源，如 Jetson 设备。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ollama</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/ollama/ollama/</link>
      <pubDate>Sun, 31 Aug 2025 12:50:42 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/ollama/ollama/</guid>
      <description>&lt;p&gt;Ollama 是一个开源的本地大型语言模型（LLM）运行框架，旨在降低使用大型语言模型的门槛，同时确保数据隐私。&lt;/p&gt;
&lt;p&gt;硬件加速：虽然主要针对 CPU 优化，但 Ollama 也可能支持 GPU 或 TPU 加速，以进一步提升推理速度&lt;/p&gt;
&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;
&lt;p&gt;适用场景：CPU/GPU 显存不足或计算速度慢。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 查看当前模型量化类型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ollama show deepseek-r1 --modelfile
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 替换为更低精度的量化版本（如 2-bit）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ollama pull deepseek-r1:2b
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;适用场景：使用 AMD/NVIDIA GPU 时显存未被充分利用。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 尝试增加卸载层数（如 -ngl 40）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ollama run deepseek-r1 --gpu-layers &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 调整分块模式（如 row 或 layer）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--split-mode row &lt;span style=&#34;color:#75715e&#34;&gt;# 修改 GPU 核函数的分块大小（-split-mode 参数）以匹配硬件特性&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;适用场景：CPU 利用率低或多卡并行效率不足。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 设置 CPU 线程数为物理核心数（如 16）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ollama run deepseek-r1 --threads &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 启用多 GPU 并行&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CUDA_VISIBLE_DEVICES&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0,1 ollama run deepseek-r1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;适用场景：内存/显存不足导致频繁交换。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 减小分块大小以减少峰值内存占用&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ollama run deepseek-r1 --chunk-size &lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;llamacpp&#34;&gt;llama.cpp&lt;/h1&gt;
&lt;p&gt;llama.cpp 是一个轻量级的 C++ 实现，旨在高效地运行 LLaMA（Large Language Model Meta AI）模型。它通过简化的 API 与 Ollama 集成，使得用户能够在本地环境中快速部署和使用语言模型。
最佳实践&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.9 Topk Topp Temperature</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.9.topk-topp-temperature/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:41 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.9.topk-topp-temperature/</guid>
      <description>&lt;h2 id=&#34;top-k-采样&#34;&gt;Top-K 采样&lt;/h2&gt;
&lt;p&gt;定义：从模型输出的概率分布中选择概率&lt;strong&gt;最高的 $ K $ 个 token 作为候选集&lt;/strong&gt;，其余 token 概率置零，再归一化后采样。&lt;/p&gt;
&lt;p&gt;数学定义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;给定 logits $ z_i $（模型输出），经 softmax 得概率：
$$p_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择 $ p_i $ 最大的 $ K $ 个 token，重新归一化：
$$p_i&amp;rsquo; = \frac{p_i}{\sum_{j \in \text{top-K}} p_j}, \quad p_i = 0 \text{ if } i \notin \text{top-K}$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;限制词汇量，减少低概率、无意义 token（如拼写错误）。&lt;/li&gt;
&lt;li&gt;提高连贯性，降低创造性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;llama.cpp&lt;/code&gt; 中实现：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;llama_sampler_top_k_impl&lt;/span&gt;(llama_token_data_array &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; cur_p, &lt;span style=&#34;color:#66d9ef&#34;&gt;int32_t&lt;/span&gt; k) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (k &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) {&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    k &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;min(k, (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;) cur_p&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;size);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 降序排序
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    bucket_sort(cur_p&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;data);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cur_p&lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt;size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; k;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;top-p-采样&#34;&gt;Top-P 采样&lt;/h2&gt;
&lt;p&gt;定义：选择累积概率达到 $ p $ 的&lt;strong&gt;最小 token 集&lt;/strong&gt;，过滤低于阈值的 token，再归一化后采样。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Concepts</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/concepts/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:41 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/concepts/</guid>
      <description>&lt;h2 id=&#34;json-lines-vs-json&#34;&gt;JSON Lines vs JSON&lt;/h2&gt;
&lt;p&gt;JSON Lines（也称为 JSONL）是一种数据格式，其中每个记录都是一个单独的 JSON 对象，并以换行符分隔。如：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-jsonl&#34; data-lang=&#34;jsonl&#34;&gt;{&amp;#34;name&amp;#34;: &amp;#34;Alice&amp;#34;, &amp;#34;age&amp;#34;: 30}
{&amp;#34;name&amp;#34;: &amp;#34;Bob&amp;#34;, &amp;#34;age&amp;#34;: 25}
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;相比之下，传统的 JSON 数据通常包含一个数组或对象，如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;people&amp;#34;&lt;/span&gt;: [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Alice&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Bob&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;age&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;JSON Lines 更适合处理&lt;strong&gt;大量独立的数据条目&lt;/strong&gt;，因为每条记录都是独立的实体，易于逐个读取和处理。&lt;/li&gt;
&lt;li&gt;传统 JSON 更适用于&lt;strong&gt;嵌套结构和复杂的多层关系&lt;/strong&gt;，更适合一次性加载整个数据集到内存中进行分析或操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;查看内存使用&#34;&gt;查看内存使用&lt;/h2&gt;
&lt;p&gt;在 Python 中测量内存使用的一种简单方法是使用 psutil 库。数据集在磁盘上的大小，使用 dataset_size 属性&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; psutil
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Process.memory_info is expressed in bytes, so convert to megabytes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RAM used: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;psutil&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Process()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;memory_info()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rss &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;)&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.2f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; MB&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Dataset size in bytes: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;pubmed_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dataset_size&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;size_gb &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pubmed_dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dataset_size &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Dataset size (cache file) : &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;size_gb&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.2f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; GB&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;http-请求的头部信息-header&#34;&gt;HTTP 请求的头部信息 header&lt;/h2&gt;
&lt;p&gt;请求中非常重要的组成部分，用来传递额外的&lt;strong&gt;元信息&lt;/strong&gt;，提升请求的准确性和安全性。内容包括：&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.4.llama.cpp Cli</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.4.llama.cpp-cli/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:40 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.4.llama.cpp-cli/</guid>
      <description>&lt;p&gt;【设Q找A，避免陷入细节陷阱】&lt;/p&gt;
&lt;h2 id=&#34;-llamacpp-项目中的关于推理任务的核心的内容&#34;&gt;@ &lt;code&gt;llama.cpp&lt;/code&gt; 项目中的关于推理任务的核心的内容&lt;/h2&gt;
&lt;p&gt;从工具入口开始 llama-cli，它是 llama.cpp 项目的门面，最佳起点。&lt;/p&gt;
&lt;h2 id=&#34;搜索-gguf-文件&#34;&gt;搜索 gguf 文件&lt;/h2&gt;
&lt;p&gt;获取 gguf 文件：&lt;code&gt;https://huggingface.co/unsloth/Qwen3-1.7B-GGUF&lt;/code&gt;。HF 的 models 页面没有 &lt;code&gt;.gguf&lt;/code&gt; 的文件，如何找到的？其实是有的，通过 &lt;code&gt;tag=gguf&lt;/code&gt; 标签筛选：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://huggingface.co/models&lt;/code&gt; ==&amp;gt; &lt;code&gt;https://huggingface.co/models?library=gguf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;另外，可以使用 &lt;a href=&#34;https://huggingface.co/spaces/ggml-org/gguf-my-repo&#34;&gt;ggml-org/gguf-my-repo&lt;/a&gt; 工具将模型权重转换为 GGUF 格式。&lt;/p&gt;
&lt;p&gt;找到 gguf 文件后，在页面的 &lt;code&gt;Files and versions&lt;/code&gt; 页面，点击 gguf 文件后的箭头，可以在线查看参数：包括模型 metadate、模型参数、tokenizer 参数、Tensors、结构每一层中每一个tensor的shape和精度。&lt;/p&gt;
&lt;h2 id=&#34;将模型转换成gguf格式&#34;&gt;将模型转换成gguf格式&lt;/h2&gt;
&lt;p&gt;使用 llama.cpp 提供的工具：&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; 完整步骤见 &lt;code&gt;llama.cpp/tools/quantize/README.md&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;-找到一个可以在-4gb-的-jetson-orin-设备上加载的量化模型-使用-llama-cli-将模型跑起来&#34;&gt;@ 找到一个可以在 4GB 的 Jetson orin 设备上加载的量化模型 使用 llama-cli 将模型跑起来&lt;/h2&gt;
&lt;p&gt;目标：&lt;code&gt;Qwen3-1.7B-Q4_K_M.gguf&lt;/code&gt;   大小 1.2GB。将文件放到 &lt;code&gt;llama.cpp/models&lt;/code&gt; 目录下.&lt;/p&gt;
&lt;p&gt;非交互模式：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;llama-cli -m ../models/Qwen3-1.7B-Q4_K_M.gguf -no-cnv --prompt &amp;quot;Hello, tell me something about llama.cpp&amp;quot;&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.5.llama.cpp Cli Pipline</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.5.llama.cpp-cli-pipline/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:40 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.5.llama.cpp-cli-pipline/</guid>
      <description>&lt;p&gt;【设Q找A，避免陷入细节陷阱】&lt;/p&gt;
&lt;p&gt;&lt;code&gt;llama-cli -m /home/junhui/workspace/llama.cpp/models/Qwen3-1.7B-Q4_K_M.gguf -no-cnv --prompt &amp;quot;What is the result of 1 + 1 in Math?&amp;quot; --no-warmup&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;从-meta-data-获取信息llama_model_loader&#34;&gt;从 meta Data 获取信息，llama_model_loader()&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;llama_model_load_from_file_impl: using device CUDA0 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Orin&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; - &lt;span style=&#34;color:#ae81ff&#34;&gt;696&lt;/span&gt; MiB free
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loaded meta data with &lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt; key-value pairs and &lt;span style=&#34;color:#ae81ff&#34;&gt;311&lt;/span&gt; tensors from ../models/Qwen3-1.7B-Q4_K_M.gguf &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;version GGUF V3 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;latest&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dumping metadata keys/values. Note: KV overrides &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; not apply in this output.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   0:                       general.architecture str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; qwen3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   1:                               general.type str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   2:                               general.name str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Qwen3 1.7B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   3:                           general.basename str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Qwen3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   4:                         general.size_label str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 1.7B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   5:                            general.license str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; apache-2.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   6:                       general.license.link str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; https://huggingface.co/Qwen/Qwen3-1.7...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   7:                   general.base_model.count u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   8:                  general.base_model.0.name str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Qwen3 1.7B Base
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv   9:          general.base_model.0.organization str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Qwen
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  10:              general.base_model.0.repo_url str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; https://huggingface.co/Qwen/Qwen3-1.7...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  11:                               general.tags arr&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;str,1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;       &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;text-generation&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  12:                          qwen3.block_count u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  13:                       qwen3.context_length u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;40960&lt;/span&gt;   &lt;span style=&#34;color:#75715e&#34;&gt;# 模型元数据中定义的最大上下文长度，表示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 模型在训练或设计时支持的最大 token 数（包括输入 prompt 和生成输出）。 模型设计时的最大上下文长度，固定在 GGUF 元数据中，无法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 修改。要改必须重新训练&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  14:                     qwen3.embedding_length u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  15:                  qwen3.feed_forward_length u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6144&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  16:                 qwen3.attention.head_count u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  17:              qwen3.attention.head_count_kv u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  18:                       qwen3.rope.freq_base f32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 1000000.000000
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  19:     qwen3.attention.layer_norm_rms_epsilon f32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 0.000001
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  20:                 qwen3.attention.key_length u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  21:               qwen3.attention.value_length u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  22:                       tokenizer.ggml.model str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gpt2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  23:                         tokenizer.ggml.pre str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; qwen2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  24:                      tokenizer.ggml.tokens arr&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;str,151936&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;!&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\&amp;#34;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;#&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;amp;&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#39;&amp;#34;&lt;/span&gt;, ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  25:                  tokenizer.ggml.token_type arr&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;i32,151936&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  26:                      tokenizer.ggml.merges arr&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;str,151387&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ġ Ġ&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ĠĠ ĠĠ&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;i n&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Ġ t&amp;#34;&lt;/span&gt;,...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  27:                tokenizer.ggml.eos_token_id u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;151645&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  28:            tokenizer.ggml.padding_token_id u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;151643&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  29:                tokenizer.ggml.bos_token_id u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;151643&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  30:               tokenizer.ggml.add_bos_token bool             &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; false
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  31:                    tokenizer.chat_template str              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;%- &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; tools %&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;{{&lt;/span&gt;- &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt;&amp;lt;|im_start|&amp;gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  32:               general.quantization_version u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- kv  33:                          general.file_type u32              &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- type  f32:  &lt;span style=&#34;color:#ae81ff&#34;&gt;113&lt;/span&gt; tensors
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- type q4_K:  &lt;span style=&#34;color:#ae81ff&#34;&gt;169&lt;/span&gt; tensors
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- type q6_K:   &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt; tensors
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;模型结构信息：&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.7.llama.cpp Follow Code</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.7.llama.cpp-follow-code/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:40 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.7.llama.cpp-follow-code/</guid>
      <description>&lt;p&gt;【设Q找A，避免陷入细节陷阱】&lt;/p&gt;
&lt;p&gt;&lt;code&gt;llama-simple -m ./models/Qwen3-1.7B-Q4_K_M.gguf -n 30 &amp;quot;What is the result of 5/0 in math?&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;推理过程-in-code&#34;&gt;推理过程 in code&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt; () {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ggml_backend_load_all();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 初始化model 参数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_model_params model_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_model_default_params();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_params.n_gpu_layers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ngl;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 创建 model对象
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_model &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_model_load_from_file(model_path.c_str(), model_params);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 得到vocab, 得到tokenizer model 和 type，得到 特殊token id，得到token-to-id 列表，包括了padding token id
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 得到id-to-token列表，得到 cached-token-to-piece 列表
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; llama_vocab &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; vocab &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_model_get_vocab(model);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 将prompt tokenize，得到 id 表示的 prompt : prompt_tokens。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;vector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;llama_token&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; prompt_tokens(n_prompt);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    llama_tokenize(vocab, prompt.c_str(), prompt.size(), prompt_tokens.data(), prompt_tokens.size(), true, true)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 首先得到 ctx 参数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_context_params ctx_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_context_default_params();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ctx_params.n_ctx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_prompt &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; n_predict &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 用上述 ctx 参数创建一个 ctx 对象 ***********
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_context &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; ctx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_init_from_model(model, ctx_params);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 初始化 sampler 参数
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; sparams &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_sampler_chain_default_params();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 创建 samplers 对象 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_sampler &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; smpl &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_sampler_chain_init(sparams);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    llama_sampler_chain_add(smpl, llama_sampler_init_greedy());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 输出 prompt one by one
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 循环 prompt_tokens 中每一个id，
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; id : prompt_tokens) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt; buf[&lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;];  &lt;span style=&#34;color:#75715e&#34;&gt;// 假设每个 token 至多 127 个字符
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_token_to_piece(vocab, id, buf, &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(buf), &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, true);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (n &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            fprintf(stderr, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s: error: failed to convert token to piece&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, __func__);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        } 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;string s(buf, n);   &lt;span style=&#34;color:#75715e&#34;&gt;// 从 bug中读前n个写入s。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s&amp;#34;&lt;/span&gt;, s.c_str()); 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// prepare a batch ？总不能是空的batch
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    llama_batch batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_batch_get_one(prompt_tokens.data(), prompt_tokens.size());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    llama_token new_token_id;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// generate token by token
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; n_pos &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; batch.n_tokens &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n_prompt &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; n_predict; ) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 1. 这里是forward pass 的实际计算，每生成一个token 前都需要一次forward 计算
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        llama_decode(ctx, batch)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 2. 这里都开始 采样了，所以forward pass 在其之前
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        new_token_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_sampler_sample(smpl, ctx, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// is it an end of generation?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (llama_vocab_is_eog(vocab, new_token_id)) {&lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_token_to_piece(vocab, new_token_id, buf,...)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// show generated
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;string s(buf, n); &lt;span style=&#34;color:#75715e&#34;&gt;// 确保每个 token 立即打印到终端，适合实时交互或调试。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s&amp;#34;&lt;/span&gt;, s.c_str());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        fflush(stdout);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 3. prepare the next batch 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 包含这个 token 的新输入
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_batch_get_one(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;new_token_id, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// perf 相关，clean up
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于cuda的信息：&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.8.llama.cpp Quant Cuda Kernel</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.8.llama.cpp-quant-cuda-kernel/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:40 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.8.llama.cpp-quant-cuda-kernel/</guid>
      <description>&lt;p&gt;【设Q找A，避免陷入细节陷阱】&lt;/p&gt;
&lt;p&gt;&lt;code&gt;llama-simple -m ./models/Qwen3-1.7B-Q4_K_M.gguf -n 30 &amp;quot;What is the result of 5/0 in math?&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;-backend-如何进行计算-graph-compute-&#34;&gt;@ backend 如何进行计算 graph-compute ？&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ggml_status llama_context&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;graph_compute(ggml_cgraph &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gf, &lt;span style=&#34;color:#66d9ef&#34;&gt;bool&lt;/span&gt;   batched) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 设置线程池
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n_threads        &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; batched &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt; cparams.n_threads_batch : cparams.n_threads;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ggml_threadpool_t tp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; batched &lt;span style=&#34;color:#f92672&#34;&gt;?&lt;/span&gt; threadpool_batch        : threadpool;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (backend_cpu &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;nullptr&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; reg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ggml_backend_dev_backend_reg(ggml_backend_get_device(backend_cpu));
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; set_threadpool_fn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            (&lt;span style=&#34;color:#66d9ef&#34;&gt;decltype&lt;/span&gt;(ggml_backend_cpu_set_threadpool) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;) ggml_backend_reg_get_proc_address(reg,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ggml_backend_cpu_set_threadpool&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        set_threadpool_fn(backend_cpu, tp);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt; set_n_threads_fn : set_n_threads_fns) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        set_n_threads_fn.second(set_n_threads_fn.first, n_threads);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 异步执行计算
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// sched（ggml_backend_sched）根据节点的后端（CPU 或 CUDA）分配任务
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; status &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ggml_backend_sched_graph_compute_async(sched.get(), gf);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (status &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; GGML_STATUS_SUCCESS) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        LLAMA_LOG_ERROR(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;%s: ggml_backend_sched_graph_compute_async failed with error %d&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, __func__, status);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; status;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;进入异步计算&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.0.GGML Llama.cpp</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.0.ggml-llama.cpp/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:39 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.0.ggml-llama.cpp/</guid>
      <description>&lt;h1 id=&#34;llamacpp-本身是一个仓库&#34;&gt;&lt;code&gt;llama.cpp&lt;/code&gt; 本身是一个仓库&lt;/h1&gt;
&lt;p&gt;其作用是 LLM inference in C/C++ 。用最少配置和最先进的性能在广泛的硬件上进行 LLM 推理。&lt;/p&gt;
&lt;h2 id=&#34;作用&#34;&gt;作用&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;纯 C/C++ 实现，不需要额外的复杂依赖，易于部署。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持 Windows、macOS、Linux，并针对不同硬件（如 ARM NEON、AVX、CUDA 等）进行优化。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;支持 1.5 位、2 位、4 位等整数量化技术，大幅降低模型的内存需求和计算开销。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;针对本地硬件（CPU、GPU、Apple Silicon 等）优化了 LLM 的推理过程，支持低资源设备运行大模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与 GGUF（GGML 的升级版）模型格式紧密结合，用于高效加载和运行量化模型。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简言之 &lt;code&gt;llama.cpp&lt;/code&gt; 是一个轻量、高效的工具，用于在本地运行和推理 LLM，特别适合资源受限的环境或需要隐私保护的场景。&lt;/p&gt;
&lt;h2 id=&#34;如何使用&#34;&gt;如何使用&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;安装并准备好模型文件。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装与C++ 编译器相关的依赖。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;源码编译,具体见&lt;a href=&#34;https://ashburnLee.github.io/blog-2-hugo/llm/5.1.llama.cpp/##源码编译&#34;&gt;源码编译&lt;/a&gt;，生成可执行文件 &lt;code&gt;llama-cli&lt;/code&gt; 和 &lt;code&gt;llama-server&lt;/code&gt; 等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从 Hugging Face 或其他模型托管平台下载 GGUF 格式的模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;llama-cli&lt;/code&gt; 工具适合快速测试模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;llama-server&lt;/code&gt; 提供一个 HTTP 服务器，可以用于集成到其他应用中。启动后，可以通过 &lt;code&gt;http://localhost:8080/v1/chat/completions&lt;/code&gt; 访问 API。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与 &lt;code&gt;llama-cpp-python&lt;/code&gt; 包一起使用，可以在 Python 中调用 &lt;code&gt;llama.cpp&lt;/code&gt; 功能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;llama-bench&lt;/code&gt;: benchmark 模型在各种 backend，parameter 等时的推理性能&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.1.llama.cpp</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.1.llama.cpp/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:39 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.1.llama.cpp/</guid>
      <description>&lt;h2 id=&#34;-库有哪些内容&#34;&gt;@ 库有哪些内容&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;大模型推理实现，Transformer 模型的核心组件，如注意力机制、前馈神经网络、层归一化等。模型加载和解析。量化技术。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性能优化，SIMD 指令和 CUDA 加速，多线程编程等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;现代 C++ 在高性能场景中的应用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;llama-cli，命令行交互生成文本。类似 ollama&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;llama-serve, 开启本地 llm 推理服务，便于集成到其他应用中。类似 ollama&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;。。。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-学习资源&#34;&gt;@ 学习资源&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Karpathy 的视频，理解 Transformer 和采样。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KV cache，top-k top-p等内容的引用：https://medium.com/data-science/llama-cpp-writing-a-simple-c-inference-program-for-gguf-llm-models-12bc5f58505f&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;检查编译环境&#34;&gt;检查编译环境&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install build-essential git cmake g++ make
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install nvidia-cuda-toolkit
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvidia-smi
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install libcudart11.0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;源码编译&#34;&gt;源码编译&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/ggerganov/llama.cpp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd llama.cpp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir build &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; cd build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# GPU 编译&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cmake .. -DGGML_CUDA&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;ON -DCMAKE_BUILD_TYPE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Debug
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;这里的 build type 还可以是：&lt;code&gt;RelWithDebInfo&lt;/code&gt;，带 debug 调试信息的 release 模式。&lt;/li&gt;
&lt;li&gt;debug 模式启用了断言检查，debug 时可能要报错。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;报错1&#34;&gt;报错1：&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;-- Could NOT find CURL (missing: CURL_LIBRARY CURL_INCLUDE_DIR)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CMake Error at common/CMakeLists.txt:85 (message):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Could NOT find CURL.  Hint: to disable this feature, set -DLLAMA_CURL=OFF
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;解释：&lt;code&gt;llama.cpp&lt;/code&gt; 使用 &lt;code&gt;CURL&lt;/code&gt; 实现 &lt;code&gt;HTTP&lt;/code&gt; 相关功能（例如通过 &lt;code&gt;HTTP&lt;/code&gt; 下载模型或提供 &lt;code&gt;API&lt;/code&gt; 服务）&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.10 Llama.cpp Attention kv Cache</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.10-llama.cpp-attention-kv-cache/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:39 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.10-llama.cpp-attention-kv-cache/</guid>
      <description>&lt;p&gt;Transformer 的注意力机制 Attention 是核心组件，用于捕捉输入&lt;strong&gt;序列中 token 之间的关系&lt;/strong&gt;，这个&lt;strong&gt;关系是通过 Q、K、V 结构建模&lt;/strong&gt;的, QKV 是 Attention 的&lt;strong&gt;核心矩阵&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KV-cache 是 Transformer 模型推理中的关键&lt;strong&gt;优化技术&lt;/strong&gt;，用于存储注意力机制 Attention 中的键 Key 和值 Value 张量，以加速自回归生成&lt;/p&gt;
&lt;p&gt;在自回归生成中，每个新 token 的生成需要计算当前 token 的 Query (Q) 与之前所有 token 的 Key 和 Value 进行注意力计算。KV-cache 保存之前的 K 和 V，避免重复计算&lt;/p&gt;
&lt;p&gt;KV-cache 占用额外内存，但它避免重复计算整个序列的 K 和 V，整体效率更高&lt;/p&gt;
&lt;h2 id=&#34;transformer-中的-attention&#34;&gt;Transformer 中的 Attention&lt;/h2&gt;
&lt;p&gt;绝大多数 LLM（如 Qwen3、LLaMA、GPT）使用 Scaled Dot-Product Attention 或其变体（比如 GQA），&lt;strong&gt;Attention 都是 Q、K、V 的函数&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q（Query）：当前 token 的查询向量。&lt;/li&gt;
&lt;li&gt;K（Key）：所有 token 的键向量。&lt;/li&gt;
&lt;li&gt;V（Value）：所有 token 的值向量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自回归生成：每个新 token 的 Q 需要与之前所有 token 的 K 和 V 计算注意力&lt;/p&gt;</description>
    </item>
    <item>
      <title>5.3.llama.cpp 推理pipline</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/5.3.llama.cpp-%E6%8E%A8%E7%90%86pipline/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:39 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/5.3.llama.cpp-%E6%8E%A8%E7%90%86pipline/</guid>
      <description>&lt;h2 id=&#34;llamacpp-使用-gguf-模型进行推理流程code-aspect&#34;&gt;llama.cpp 使用 GGUF 模型进行推理流程。code aspect&lt;/h2&gt;
&lt;h3 id=&#34;1-模型加载&#34;&gt;1. 模型加载&lt;/h3&gt;
&lt;p&gt;加载 GGUF 文件，解析权重和配置&lt;/p&gt;
&lt;p&gt;将权重加载到内存（支持内存映射 mmap 以减少内存占用）。&lt;/p&gt;
&lt;p&gt;初始化上下文（llama_context），包括 KV 缓存（用于加速多轮对话）和计算图。&lt;/p&gt;
&lt;p&gt;llama.cpp 文件中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;llama_model &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_model_load_from_file(model_path, params);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;llama_context &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; lctx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_init_from_model(model, cparams);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-预处理&#34;&gt;2. 预处理&lt;/h3&gt;
&lt;p&gt;将输入文本（prompt）通过分词器（tokenizer）转换为 token ID 序列。分词器信息通常存储在 GGUF 文件中，llama.cpp 使用它将文本编码为输入向量。&lt;/p&gt;
&lt;p&gt;llama.cpp 中&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;vector&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;llama_token&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; llama_tokenize(model, prompt, true);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-推理-pipline&#34;&gt;3. 推理 pipline&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;llama.cpp&lt;/code&gt; 构建了一个推理 pipeline，基于 GGUF 文件中的配置，首先执行 Transformer 的前向传播。包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;嵌入层：将 token ID 转换为嵌入向量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Transformer 层：循环执行多层 Transformer 块，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Head Attention&lt;/strong&gt; ：计算查询、键、值并应用注意力机制。&lt;/li&gt;
&lt;li&gt;层归一化（&lt;strong&gt;Layer Normalization&lt;/strong&gt;）：归一化中间结果。&lt;/li&gt;
&lt;li&gt;前馈网络（&lt;strong&gt;Feed-Forward Network&lt;/strong&gt;）：应用全连接层。&lt;/li&gt;
&lt;li&gt;残差连接（&lt;strong&gt;Residual Connections&lt;/strong&gt;）：确保信息流动。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;输出层：将最后一层的输出转换为 logits（对下一个 token 的概率分布）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>4.3.实例 GRPO</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/4.3.%E5%AE%9E%E4%BE%8Bgrpo-in-myself/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:38 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/4.3.%E5%AE%9E%E4%BE%8Bgrpo-in-myself/</guid>
      <description>&lt;h2 id=&#34;-kl-离散度自实现&#34;&gt;@ KL 离散度自实现&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torch.nn.functional &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; kl_div, log_softmax, softmax
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoModelForCausalLM, AutoTokenizer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; load_dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; copy &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; deepcopy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1. 加载数据集&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;openai/gsm8k&amp;#34;&lt;/span&gt;, split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train[:5%]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 2. 奖励函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 组件：奖励函数，用于评估每一个响应的好坏&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reward_function&lt;/span&gt;(completions, answers, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewards &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pattern &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;lt;answer&amp;gt;(.*?)&amp;lt;/answer&amp;gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; completion, correct_answer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(completions, answers):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;search(pattern, completion)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            reward &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;group(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; str(correct_answer) &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            reward &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        rewards&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(reward)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; rewards
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 3. 数据预处理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;format_dataset&lt;/span&gt;(example):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    system_prompt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Solve the math problem step-by-step, providing reasoning in &amp;lt;think&amp;gt; tags &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;and the final answer in &amp;lt;answer&amp;gt; tags.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;prompt&amp;#34;&lt;/span&gt;: [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: system_prompt},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: example[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;question&amp;#34;&lt;/span&gt;]}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;: example[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(format_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4. 初始化模型和分词器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Qwen/Qwen2-0.5B-Instruct&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(model_name)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoModelForCausalLM&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(model_name, torch_dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;float16)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model_old &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; deepcopy(model)  &lt;span style=&#34;color:#75715e&#34;&gt;# 参考模型（旧策略），保持不变&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cuda&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;is_available() &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model_old&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cuda&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;is_available() &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5. 自定义训练循环&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;train_with_kl&lt;/span&gt;(dataset, num_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, num_generation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, kl_weight&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Adam 优化器的目标是最小化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optim&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;AdamW(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;parameters(), lr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; epoch &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_epochs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(dataset), batch_size):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset[i:i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; batch_size]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            prompts &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; batch[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;prompt&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            answers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; batch[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 生成多个候选输出&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            completions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            new_logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            old_logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; prompt &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; prompts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer([&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;prompt[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;prompt[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;], 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                    return_tensors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                    padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#75715e&#34;&gt;# 组件分组采样：每一个prompt 生成4个响应，形成一个响应组&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(num_generation):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;generate(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;inputs, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                             max_new_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                             do_sample&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                             return_dict_in_generate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                             output_scores&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#75715e&#34;&gt;# 生成响应，evla值&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    completion &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(outputs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sequences[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], skip_special_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    completions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(completion)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    &lt;span style=&#34;color:#75715e&#34;&gt;# 获取 logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    logits &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack(outputs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scores, dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)[:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :]  &lt;span style=&#34;color:#75715e&#34;&gt;# 最后一层的 logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    new_logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(logits)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#75715e&#34;&gt;# 旧策略 logits&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    ref_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model_old(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;inputs, return_dict&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    old_logits&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(ref_outputs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;logits[:, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, :])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 计算奖励&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 评估响应，响应值与真值比较&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            rewards &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; reward_function(completions, answers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 计算 KL 散度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            kl_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; new_logit, old_logit &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(new_logits, old_logits):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                kl_loss &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; kl_div(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    log_softmax(new_logit, dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    softmax(old_logit, dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    reduction&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batchmean&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            kl_loss &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; num_generation
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 计算奖励loss&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            reward_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor(rewards, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;device)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 总loss&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            total_loss &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; reward_loss &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; kl_weight &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; kl_loss
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#75715e&#34;&gt;# 优化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            total_loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;step()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Epoch &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;epoch&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, Batch &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt;batch_size&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, Total Loss: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;total_loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, KL Loss: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;kl_loss&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 6. 开始训练&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;train_with_kl(dataset, num_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, num_generation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, kl_weight&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;kaq-如何体现新旧模型的不同&#34;&gt;KAQ： 如何体现新旧模型的不同&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;model_old = deepcopy(model) &lt;/code&gt; model_old 保持不变，即旧 Policy 的表达无变化。model 是在学习的模型，它表达 Policy 的更新。&lt;/p&gt;</description>
    </item>
    <item>
      <title>4.4.实例GRPO Fine Tune Models</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/4.4.%E5%AE%9E%E4%BE%8Bgrpo-fine-tune-models/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:38 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/4.4.%E5%AE%9E%E4%BE%8Bgrpo-fine-tune-models/</guid>
      <description>&lt;h1 id=&#34;使用-grpo-微调一个模型&#34;&gt;使用 GRPO 微调一个模型&lt;/h1&gt;
&lt;p&gt;使用到 PEFT（Parameter-Efficient Fine-Tuning）库&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# pip install -qqq datasets==3.2.0 transformers==4.47.1 trl==0.14.0 peft==0.14.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# pip install -qqq accelerate==1.2.1 bitsandbytes==0.45.2 wandb==0.19.7 --progress-bar off&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# pip install -qqq flash-attn --no-build-isolation --progress-bar off&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; load_dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; peft &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; LoraConfig, get_peft_model
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoModelForCausalLM, AutoTokenizer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; trl &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; GRPOConfig, GRPOTrainer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; wandb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wandb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;login()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 短篇小说训练数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;mlabonne/smoltldr&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 使用小模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model_id &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;HuggingFaceTB/SmolLM-135M-Instruct&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoModelForCausalLM&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_id,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    torch_dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;auto&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    device_map&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;auto&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    attn_implementation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;flash_attention_2&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(model_id)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Load LoRA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Before lora: &amp;#34;&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;print_trainable_parameters())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lora_config &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LoraConfig(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    task_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CAUSAL_LM&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lora_alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    target_modules&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;all-linear&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_peft_model(model, lora_config)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;After lora: &amp;#34;&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;print_trainable_parameters())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Reward function&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ideal_length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reward_len&lt;/span&gt;(completions, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;abs(ideal_length &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; len(completion)) &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; completion &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; completions]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Training arguments&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_args &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRPOConfig(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output_dir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GRPO&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2e-5&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    per_device_train_batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    gradient_accumulation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_prompt_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_completion_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;96&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    num_generations&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;adamw_8bit&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    num_train_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    bf16&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    report_to&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;wandb&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    remove_unused_columns&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    logging_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 开始 Trainer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRPOTrainer(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    reward_funcs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[reward_len],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    args&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;training_args,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;dataset[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Train model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wandb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;init(project&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GRPO&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 保存并发布&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;merged_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; trainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;merge_and_unload()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;merged_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;push_to_hub(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SmolLM-135M-Instruct-GRPO-135M&amp;#34;&lt;/span&gt;, private&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;, tags&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;GRPO&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Reasoning-Course&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;解释训练结果&#34;&gt;解释训练结果&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;GRPOTrainer&lt;/code&gt; 记录了奖励函数的奖励值、损失值以及其他一系列指标&lt;/p&gt;</description>
    </item>
    <item>
      <title>4.5.实例unsloth</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/4.5.%E5%AE%9E%E4%BE%8Bunsloth/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:38 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/4.5.%E5%AE%9E%E4%BE%8Bunsloth/</guid>
      <description>&lt;h1 id=&#34;unloth&#34;&gt;Unloth&lt;/h1&gt;
&lt;p&gt;Unsloth 是一个加速 LLM 微调的库，它使得训练模型更快，并减少计算资源的需求。Unsloth 与 TRL 集成。&lt;/p&gt;
&lt;p&gt;可在 Google Colab T4 GPU 上免费运行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install unsloth vllm
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install --upgrade pillow
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;setup-unsloth-加载模型&#34;&gt;Setup unsloth 加载模型&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;from unsloth import FastLanguageModel&lt;/code&gt; 这个类将 transformers 与 Unsloth 优化集成。&lt;/p&gt;
&lt;p&gt;加载 Google 的 Gemma 3 1B Instruct 模型并配置它进行微调。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; unsloth &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; FastLanguageModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;max_seq_length &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1024&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Can increase for longer reasoning traces&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lora_rank &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Larger rank = smarter, but slower&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model, tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; FastLanguageModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;google/gemma-3-1b-it&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_seq_length&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;max_seq_length,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    load_in_4bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# False for LoRA 16bit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    fast_inference&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# Enable vLLM fast inference&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_lora_rank&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lora_rank,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    gpu_memory_utilization&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.6&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# Reduce if out of memory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; FastLanguageModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_peft_model(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    r&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lora_rank,  &lt;span style=&#34;color:#75715e&#34;&gt;# Choose any number &amp;gt; 0 ! Suggested 8, 16, 32, 64, 128&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    target_modules&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;q_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;o_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gate_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;up_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;down_proj&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ],  &lt;span style=&#34;color:#75715e&#34;&gt;# Remove QKVO if out of memory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lora_alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lora_rank,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    use_gradient_checkpointing&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;unsloth&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# Enable long context finetuning&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    random_state&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3407&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;用 &lt;strong&gt;4 位量化&lt;/strong&gt;方式加载模型以节省内存，并应用 &lt;strong&gt;LoRA 低秩适配&lt;/strong&gt;进行高效微调。 &lt;code&gt;target_modules&lt;/code&gt; 参数指定要微调模型的哪些层， &lt;code&gt;use_gradient_checkpointing&lt;/code&gt; 参数启用使用更长的上下文进行训练。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2.0.dataset库</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/2.0.dataset%E5%BA%93/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:37 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/2.0.dataset%E5%BA%93/</guid>
      <description>&lt;h1 id=&#34;load_dataset&#34;&gt;load_dataset&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;from datasets import load_dataset&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;方法 load_dataset 功能强大，它可以加载多种格式的数据集：huggingface上的数据集、单个文件、文件集合、压缩包、远程数据集。&lt;/p&gt;
&lt;h1 id=&#34;切片切块数据&#34;&gt;切片切块数据&lt;/h1&gt;
&lt;p&gt;大多数情况下，你得到的数据是不会完全符合训练模型期望的。所以你需要&lt;strong&gt;处理、清理原始数据集&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在进行任何数据分析时，一个好的做法是抓取一小部分随机样本，以便快速了解你正在处理的数据类型。在 Datasets 中，我们可以通过将 &lt;code&gt;Dataset.shuffle() &lt;/code&gt; 和 &lt;code&gt;Dataset.select()&lt;/code&gt; 函数连接起来来创建随机样本：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Datasets.map(func)&lt;/code&gt; 功能强大，传入一个处理原始数据的方法，就可以将这个方法应用到数据集的每一个样本上，以转换、处理或增强数据。输出一个新的 Dataset 对象，包含处理后的数据，原数据集保持不变。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;Dataset.map()&lt;/code&gt; 中指定 &lt;code&gt;batched=True&lt;/code&gt;，表示快速进行映射操作。在对大量文本进行 tokenize 的时候尤其快速，成为快速分词。原因是分词代码是用 Rust 编写的，而 Rust 是一种易于并行化代码执行的语言。&lt;/p&gt;
&lt;p&gt;强大的功能集中在一个方法中，使用起来非常方便。&lt;/p&gt;
&lt;p&gt;Datasets 提供了一个 &lt;code&gt;Dataset.set_format()&lt;/code&gt; 函数。实现与各种第三方库之间的转换。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Dataset.train_test_split()&lt;/code&gt; 函数将训练集分成 train 和 validation 分割。&lt;/p&gt;
&lt;p&gt;还有其他功能，explore as needed.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;使用&lt;strong&gt;验证集&lt;/strong&gt;而非滥用&lt;strong&gt;测试集&lt;/strong&gt;。目的是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;测试集应保持完全独立，仅在开发完成后用于最终评估模型性能。&lt;/li&gt;
&lt;li&gt;如果在开发中反复使用测试集，会导致模型“间接学习”测试数据，产生过于乐观的性能估计。&lt;/li&gt;
&lt;li&gt;验证集作为中间评估工具，避免测试集被污染。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;大数据集&#34;&gt;大数据集&lt;/h1&gt;
&lt;p&gt;如果从头训练LLMs，所需的数据量是巨大的，比如几十 GB 的文本加载到内存都是巨大的挑战。并且有个经验，通常你需要的内存大小要比比数据集大小多 5 到 10 倍！Datasets 库提供了解决办法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;内存映射文件&lt;/code&gt;：将数据集视为 内存映射文件，让开发者免除了内存管理的麻烦。即 Datasets 将每个数据集视为一个内存映射文件，它提供了 RAM 和文件系统存储之间的映射，允许该库在不将整个数据集加载到内存中的情况下访问和操作数据集的元素。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Streaming&lt;/code&gt;：通过 streaming 传输语料库中的条目来摆脱硬盘限制。它允许我们在不需要下载整个数据集的情况下动态下载和访问元素。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;faiss&#34;&gt;FAISS&lt;/h1&gt;
&lt;p&gt;Facebook AI Similarity Search 是一个提供高效算法以快速搜索和聚类嵌入向量的库。Datasets 中有其实现：FAISS 索引。去基本思想是创建一个特殊的索引数据结构，该结构允许我们找到与输入嵌入相似的嵌入。它的应用场景：&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.1.训练tokenizer</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/3.1.%E8%AE%AD%E7%BB%83tokenizer/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:37 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/3.1.%E8%AE%AD%E7%BB%83tokenizer/</guid>
      <description>&lt;h1 id=&#34;为什么要训练分词器&#34;&gt;为什么要训练分词器&lt;/h1&gt;
&lt;p&gt;如果我感兴趣的语言没有现成的语言模型，或者我的语料库与我语言模型训练所用的语料库差异很大，我很可能需要使用&lt;strong&gt;适合我数据的 tokenizer&lt;/strong&gt;从头开始重新训练模型。这将需要在&lt;strong&gt;我自己的数据集&lt;/strong&gt;上&lt;strong&gt;训练一个新的 tokenizer&lt;/strong&gt;。分词器需要分析语料库中的所有文本，识别哪些子词在当前语料库中具&lt;strong&gt;有重要性&lt;/strong&gt;且&lt;strong&gt;出现频率最高&lt;/strong&gt;，这就是分词器的训练。&lt;/p&gt;
&lt;p&gt;训练分词器与&lt;strong&gt;训练模型&lt;/strong&gt;并不相同。模型训练使用随机梯度下降，目标是使每个批次的损失稍微减小。从而得到训练后的权值。这个过程有随机性。而分词器训练&lt;strong&gt;是一个统计过程&lt;/strong&gt;，试图识别给定语料库中哪些子词是最佳选择，而&lt;strong&gt;选择它们的规则&lt;/strong&gt;取决于&lt;strong&gt;分词算法&lt;/strong&gt;。这个过程是确定的。&lt;/p&gt;
&lt;p&gt;Transformers 中有一个非常简单的 API，你可以用它来训练一个与现有分词器具有相同特性的新分词器： &lt;code&gt;AutoTokenizer.train_new_from_iterator()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;假设我们想从头开始训练 GPT-2，但使用的语言不是英语，而是 Python 语言。第一个任务是收集大量该语言的数据，形成一个&lt;strong&gt;训练语料库&lt;/strong&gt;。&lt;/p&gt;
&lt;h1 id=&#34;codesearchnet-数据集-中获取目标数据集&#34;&gt;CodeSearchNet 数据集 中获取目标数据集&lt;/h1&gt;
&lt;p&gt;含了 GitHub 上多个编程语言的开源库中的数百万个函数。在这里，我们将加载这个数据集中 Python 部分的内容。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; load_dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# This can take a few minutes to load, so grab a coffee or tea while you wait!&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;raw_datasets &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;code_search_net&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;事实是，数据集将&lt;strong&gt;文档字符串&lt;/strong&gt;和&lt;strong&gt;代码分开&lt;/strong&gt;，并建议对两者进行分词。在这里，我们将仅使用 &lt;code&gt;whole_func_string&lt;/code&gt; 列来训练我们的分词器。&lt;/p&gt;
&lt;p&gt;注意避免将所有预料一股脑儿加载到内存，像这样：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_corpus &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    raw_datasets[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;][i: i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;whole_func_string&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(raw_datasets[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;]), &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;相反地，我们应该使用 使用 Python 生成器，它在&lt;strong&gt;真正需要这个数据时才将数据加载到内存&lt;/strong&gt;中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_corpus &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    raw_datasets[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;][i : i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;whole_func_string&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, len(raw_datasets[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train&amp;#34;&lt;/span&gt;]), &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意&lt;strong&gt;生成器对象只能被使用一次&lt;/strong&gt;，所以将其包装在一个函数中，以便多次使用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.2.BPE Tokenizer</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/3.2.bpe-tokenizer/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:37 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/3.2.bpe-tokenizer/</guid>
      <description>&lt;h1 id=&#34;normalization-and-pre-tokenization&#34;&gt;Normalization and pre-tokenization&lt;/h1&gt;
&lt;p&gt;下是tokenization pipline的流程：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img alt=&#34;图片描述&#34; loading=&#34;lazy&#34; src=&#34;../../pics/tokenization_pipeline-dark.svg&#34;&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;em&gt;分词的pipline&lt;/em&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在根据其模型将文本分割为子词之前，分词器执行两个步骤：归一化 &amp;amp; 预分词。&lt;/p&gt;
&lt;h2 id=&#34;normalization&#34;&gt;Normalization&lt;/h2&gt;
&lt;p&gt;Normalization 进行常规清理工作，例如去除不必要的空白字符、转换为小写以及/或去除重音符号。一个 &lt;code&gt;tokenizer&lt;/code&gt; 对象含有底层的 &lt;code&gt;normalizer&lt;/code&gt; 属性，这个属性有一个方法 &lt;code&gt;normalize_str()&lt;/code&gt; 的作用就是进行归一化的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bert-base-uncased&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend_tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normalizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;normalize_str(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Héllò hôw are ü?&amp;#34;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hello how are u?&amp;#39;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 针对 bert-base-uncased 的归一化输出&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;不同的预训练模型的归一化方法有差别&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;预分词&#34;&gt;预分词&lt;/h2&gt;
&lt;p&gt;相同的，一个 &lt;code&gt;tokenizer&lt;/code&gt; 对象含有底层的 &lt;code&gt;pre_tokenizer&lt;/code&gt; 属性，这个属性有一个方法 &lt;code&gt;pre_tokenize_str()&lt;/code&gt; 的作用就是进行预分词的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend_tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pre_tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pre_tokenize_str(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, how are  you?&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Hello&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;,&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;how&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;are&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;you&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;?&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;))]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;看看T5 模型的分词器：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;t5-small&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backend_tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pre_tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pre_tokenize_str(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, how are  you?&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▁Hello,&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▁how&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▁are&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;)), (&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;▁you?&amp;#39;&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;))]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个分词器是包含&lt;strong&gt;偏移映射&lt;/strong&gt;的。同样的，&lt;strong&gt;不同预训练模型的预分词方法有差别&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>4.1.RL in LLMs</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/4.1.rl-in-llms/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:37 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/4.1.rl-in-llms/</guid>
      <description>&lt;h1 id=&#34;why-rl-in-llms&#34;&gt;Why RL in LLMs&lt;/h1&gt;
&lt;p&gt;LLMs 在生成任务中表现出色。然而，直到最近，它们在需要推理的复杂问题上一直存在困难。例如，它们难以处理需要多步推理的谜题或数学问题。强化学习可以鼓励 LLMs 进行“思考”和推理。&lt;/p&gt;
&lt;p&gt;RL 革新了 LLMs 训练的方式。pure RL 详细内容见 &lt;a href=&#34;../RL/&#34;&gt;笔记RL&lt;/a&gt;。RL 中的 reward 对应在 LLMs 上是为了反映 LLM 在特定任务上的表现好坏。&lt;/p&gt;
&lt;p&gt;我们希望 LLMs 不仅仅是擅长生成流畅的文本。我们希望它们能够&lt;strong&gt;提供与某些内容相关，且有帮助的信息。避免生成有害信息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;预训练 LLM 方法，主要依赖于从文本数据中预测下一个词。上述期望的方面会存在不足。微调后的模型也会生成流畅且结构化的文本，但在上述方面也会是不足的。&lt;/p&gt;
&lt;p&gt;RL 为我们提供了一种方法，可以微调预训练的 LLMs，以更好地实现上述期望生成内容的特质。&lt;/p&gt;
&lt;p&gt;如果将 LLMs 比喻成宠物狗，那么我们期望它成为一个&lt;strong&gt;行为良好且有用的伙伴&lt;/strong&gt;，而不仅仅是一只知道如何流利汪汪的狗。&lt;/p&gt;
&lt;h1 id=&#34;但是&#34;&gt;但是&lt;/h1&gt;
&lt;p&gt;不是所有大模型都应用 RLHF（Reinforcement Learning from Human Feedback） 方法。LLMs 训练过程是&lt;strong&gt;预训练&lt;/strong&gt;，然后&lt;strong&gt;监督微调&lt;/strong&gt;（SFT），只有部分模型使用 RLHF 方法，优化模型输出。&lt;/p&gt;
&lt;p&gt;关于SFT，所有流行的 LLMs 都需要一些监督微调。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RLHF 的劣势&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;成本高，它需要大量的人类反馈，预训练和 SFT 已经满足大部分需求。&lt;/li&gt;
&lt;li&gt;计算复杂性大，RLHF 使用强化学习算法（如 PPO），计算资源需求大。&lt;/li&gt;
&lt;li&gt;一些模型使用 高质量 SFT 替代 RLHF。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;rl-in-llms&#34;&gt;RL in LLMs&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;语言模型对齐&lt;/strong&gt;: 是指通过训练和优化，使 LLMs 的输出与人类价值观、意图或特定任务目标保持一致的过程。目标是确保模型生成安全、准确、符合伦理且对用户有用的内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RLHF&lt;/strong&gt;: 是一种对齐语言模型的&lt;strong&gt;具体方法&lt;/strong&gt;，通过结合强化学习和人类反馈优化模型，使其输出更符合人类偏好。&lt;/p&gt;
&lt;p&gt;在 RLHF 中使用人类反馈作为强化学习（RL）中&lt;strong&gt;奖励信号&lt;/strong&gt;的代理。原理大概如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>4.3.实例 GRPO in TRL</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/4.3.%E5%AE%9E%E4%BE%8Bgrpo-in-trl/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:37 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/4.3.%E5%AE%9E%E4%BE%8Bgrpo-in-trl/</guid>
      <description>&lt;h1 id=&#34;一个-trl-实现-grpo-的实例&#34;&gt;一个 TRL 实现 GRPO 的实例&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; trl &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; GRPOTrainer, GRPOConfig
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; datasets &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; load_dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; re
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1. 加载数据集: 使用 load_dataset 加载 GSM8K 数据集（数学问题），仅取 5% 数据以简化演示。用于 GRPO 的训练&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_dataset(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;openai/gsm8k&amp;#34;&lt;/span&gt;, split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;train[:5%]&amp;#34;&lt;/span&gt;)  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 2. 定义奖励函数: 是否与一个指定的 pattern 匹配，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;reward_function&lt;/span&gt;(completions, answers, &lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;kwargs):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;奖励函数：比较生成答案与正确答案，奖励正确格式和答案&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rewards &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pattern &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;lt;answer&amp;gt;(.*?)&amp;lt;/answer&amp;gt;&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 假设答案在 &amp;lt;answer&amp;gt; 标签中&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; completion, correct_answer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(completions, answers):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; re&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;search(pattern, completion)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                pred_answer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;match&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;group(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                &lt;span style=&#34;color:#75715e&#34;&gt;# 简单奖励：正确答案得 1.0，错误得 0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                reward &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; pred_answer &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; str(correct_answer) &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                reward &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 格式错误&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            reward &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 解析失败&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        rewards&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(reward)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; rewards
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 3. 数据预处理&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;format_dataset&lt;/span&gt;(example):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;格式化数据集为 GRPO 所需的 prompt 格式&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    system_prompt &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Solve the math problem step-by-step, providing reasoning in &amp;lt;think&amp;gt; tags &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;and the final answer in &amp;lt;answer&amp;gt; tags.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;prompt&amp;#34;&lt;/span&gt;: [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;system&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: system_prompt},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: example[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;question&amp;#34;&lt;/span&gt;]}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;: example[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;answer&amp;#34;&lt;/span&gt;]  &lt;span style=&#34;color:#75715e&#34;&gt;# 用于奖励函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 应用格式化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dataset &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map(format_dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4. 配置 GRPO 训练参数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;training_args &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRPOConfig(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output_dir&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;./grpo_output&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    num_train_epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    per_device_train_batch_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    gradient_accumulation_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    learning_rate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1e-5&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    logging_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    num_generation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 每条 prompt 生成 4 个候选答案，即 Group的大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 限制步数以便演示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    use_vllm&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 可设为 True 加速（需安装 vLLM）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5. 初始化 GRPOTrainer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; GRPOTrainer(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Qwen/Qwen2-0.5B-Instruct&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 使用小型模型以便演示&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    args&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;training_args,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    train_dataset&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;dataset,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    reward_funcs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;reward_function,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 6. 开始训练&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;trainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;-reward-函数中的-completions&#34;&gt;@ Reward 函数中的 completions&lt;/h2&gt;
&lt;p&gt;是 list of completions to evaluate。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.1.tokenizer Pass_model Post Process</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/1.1.tokenizer-pass_model-post-process/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:36 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/1.1.tokenizer-pass_model-post-process/</guid>
      <description>&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pipeline
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;classifier &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pipeline(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sentiment-analysis&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;transformer-库-pipline-背后的动作&#34;&gt;Transformer 库 pipline 背后的动作&lt;/h1&gt;
&lt;p&gt;有三个主要动作&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tokenizer 预处理&lt;/li&gt;
&lt;li&gt;将输入传递给模型&lt;/li&gt;
&lt;li&gt;后处理&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1-使用-tokenizer-进行预处理&#34;&gt;1. 使用 Tokenizer 进行预处理&lt;/h2&gt;
&lt;p&gt;模型不会理解文字的，故将文本输入转换为模型能够理解的数字。所以使用tokenizer。一个 tokenizer 做的事情包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将输入分割成单词、子词或符号（如标点符号），这些被称为 tokens&lt;/li&gt;
&lt;li&gt;将每个标记映射 map 到一个整数，input IDs是token的唯一标记所以称为ids。&lt;/li&gt;
&lt;li&gt;添加可能对模型有用的额外输入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述的预处理需要与模型预训练时结构完全相同。使用 &lt;code&gt;AutoTokenizer&lt;/code&gt; 类及其 &lt;code&gt;from_pretrained()&lt;/code&gt; 方法，会自动获取与模型分词器相关联的数据并将其缓存。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sentiment-analysis&lt;/code&gt; pipline的默认 checkpoint 是 &lt;code&gt;distilbert-base-uncased-finetuned-sst-2-english&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoTokenizer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;checkpoint &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;distilbert-base-uncased-finetuned-sst-2-english&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(checkpoint)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如此得到了 tokenizer。我的句子传给 tonkenizer，得到 input IDs，即数字表达文字。然后需要将 inputIDs 变为 tensor，作为模型的输入。transformers 库中，指定 return_tensors 即可：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;raw_inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;ve been waiting for a HuggingFace course my whole life.&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I hate this so much!&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer(raw_inputs, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, truncation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, return_tensors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(inputs)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;得到tensor 结果：&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.2.Transformer库中的models</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/1.2.transformer%E5%BA%93%E4%B8%AD%E7%9A%84models/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:36 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/1.2.transformer%E5%BA%93%E4%B8%AD%E7%9A%84models/</guid>
      <description>&lt;h1 id=&#34;transformer-库中的-models&#34;&gt;Transformer 库中的 models&lt;/h1&gt;
&lt;h2 id=&#34;创建transformer-模型&#34;&gt;创建Transformer 模型&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bert-base-cased&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;AutoModel&lt;/code&gt; 是一个 auto 类，意味着它会&lt;strong&gt;为你猜测&lt;/strong&gt;合适的模型架构并实例化正确的模型类。然而，如果你知道你想使用的模型类型，可以直接使用它来定义其架构的类,比如我确定我要使用BERT模型，则可以这样：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; BertModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BertModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bert-base-cased&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;save-models&#34;&gt;save models&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;save_pretrained()&lt;/code&gt; 方法保存模型的&lt;strong&gt;权重&lt;/strong&gt;和&lt;strong&gt;架构配置&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;model.save_pretrained(&amp;quot;directory_on_my_computer&amp;quot;)&lt;/code&gt; 会保存模型到指定路径。内容包含 &lt;code&gt;config.json&lt;/code&gt; 和 &lt;code&gt;pytorch_model.bin&lt;/code&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;config.json&lt;/code&gt; 构建模型架构所需的所有必要属性，还包括checkpoint的来源，以及那时是使用的transformer 的版本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;pytorch_model.bin&lt;/code&gt; 文件被称为 state dictionary, 它包含你模型的所有权重。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个文件协同工作：配置文件用于了解模型架构，而模型权重是模型的参数。&lt;/p&gt;
&lt;h2 id=&#34;load-saved-models&#34;&gt;load saved models&lt;/h2&gt;
&lt;p&gt;要重用保存的模型，再次使用 &lt;code&gt;from_pretrained()&lt;/code&gt; 方法：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoModel&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;directory_on_my_computer&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;分享你的模型或-embedding&#34;&gt;分享你的模型或 embedding&lt;/h2&gt;
&lt;h2 id=&#34;encoding-text&#34;&gt;Encoding text&lt;/h2&gt;
&lt;p&gt;已经知道 tokenizer 将文本分割成 tokens，然后将这些标记转换为数字 input IDs。可以观察这种转换：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoTokenizer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bert-base-cased&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;encoded_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;How are you?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;m fine, thank you!&amp;#34;&lt;/span&gt;, return_tensors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(encoded_input)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;101&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1731&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1132&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;102&lt;/span&gt;], 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ae81ff&#34;&gt;101&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1045&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1005&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1049&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2503&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;117&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5763&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1128&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;102&lt;/span&gt;]]), 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;token_type_ids&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]),   &lt;span style=&#34;color:#75715e&#34;&gt;# wrong？为什么都是0，分明是两个batch？&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;attention_mask&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;input_ids&lt;/code&gt;: token 转化为数值表示&lt;/li&gt;
&lt;li&gt;&lt;code&gt;token_type_ids&lt;/code&gt;： 些告诉模型输入的哪部分是句子 A，哪部分是句子 B。为句子 A 的 token 分配 0，为句子 B 的 token 分配 1，帮助模型理解两部分的边界和关系。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attention_mask&lt;/code&gt;: 这表示哪些标记应该被关注，哪些不应该。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tokenizer-方法这里有几个参数&#34;&gt;&lt;code&gt;tokenizer()&lt;/code&gt; 方法这里有几个参数：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;return_tensors=&amp;quot;pt&amp;quot;&lt;/code&gt; 将输出转化为 PyTorch tensors。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;padding=True/False&lt;/code&gt; 将输入填充。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;truncation=True&lt;/code&gt; 如果输入太长，则截断它们。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;1-padding-输入填充&#34;&gt;1. Padding 输入填充&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;encoded_input &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;How are you?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;m fine, thank you!&amp;#34;&lt;/span&gt;],  &lt;span style=&#34;color:#75715e&#34;&gt;# 一组，所以是一个句子&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    return_tensors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(encoded_input)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;101&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1731&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1132&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;102&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        [&lt;span style=&#34;color:#ae81ff&#34;&gt;101&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1045&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1005&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1049&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2503&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;117&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5763&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1128&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;136&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;102&lt;/span&gt;]]), 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;token_type_ids&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]]),  &lt;span style=&#34;color:#75715e&#34;&gt;# 一组，所以是一个句子&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;attention_mask&amp;#39;&lt;/span&gt;: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为什么要 Padding 成长度一样的？&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.3.transformer库中的tokenizer</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/1.3.transformer%E5%BA%93%E4%B8%AD%E7%9A%84tokenizer/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:36 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/1.3.transformer%E5%BA%93%E4%B8%AD%E7%9A%84tokenizer/</guid>
      <description>&lt;p&gt;将文本转换为模型可以处理的数据。那分词流程中具体发生了什么？内容包括分词算法，分词general流程。&lt;/p&gt;
&lt;h1 id=&#34;分词算法&#34;&gt;分词算法&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;word-based&lt;/code&gt;： 将原始文本分割成单词，并为每个单词找到一个数值表示。使用 split() 函数实现。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;character-based&lt;/code&gt;： 文本分割为字母，而不是单词&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Subword tokenization&lt;/code&gt;： 依赖的原则是，常用词不应被拆分成更小的子词，而罕见词应该被分解成有意义的子词。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Byte-level BPE&lt;/code&gt;：在 GPT-2 中使用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;WordPiece&lt;/code&gt;：在 BERT 中使用的&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SentencePiece&lt;/code&gt; 或 &lt;code&gt;Unigram&lt;/code&gt;：在多语言模型中&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;分词流程general-的流程&#34;&gt;分词流程，general 的流程&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoTokenizer
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bert-base-cased&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokenizer(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Using a Transformer network is simple&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;input_ids&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;101&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7993&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;170&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;11303&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1200&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2443&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1110&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3014&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;102&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;token_type_ids&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;attention_mask&amp;#39;&lt;/span&gt;: [&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;1-编码将文本转换为数字&#34;&gt;1. 编码：将文本转换为数字&lt;/h2&gt;
&lt;p&gt;分为两步骤：第一步：文本分割成的单词，或单词的一部分、标点符号等，称为 &lt;strong&gt;tokens&lt;/strong&gt;。第二步：将tokens 转化为数字。&lt;/p&gt;
&lt;h3 id=&#34;step1-分词&#34;&gt;step1. 分词&lt;/h3&gt;
&lt;p&gt;调用 tokenize 方法，将文本分割成 tokens：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sequence &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Using a Transformer network is simple&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tokenize(sequence)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Using&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;a&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;transform&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;##er&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;network&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;is&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;simple&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;step2-从-token-到-input-ids&#34;&gt;step2. 从 token 到 input ids&lt;/h3&gt;
&lt;p&gt;调用 convert_tokens_to_ids 方法，将 tokens 转换为数字：&lt;/p&gt;</description>
    </item>
    <item>
      <title>0.Transformers Big Pic</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/llm/0.transformers-big-pic/</link>
      <pubDate>Sun, 31 Aug 2025 12:49:35 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/llm/0.transformers-big-pic/</guid>
      <description>&lt;p&gt;使用一个新的 Python 环境，安装 轻量级 transformers &lt;code&gt;pip install &amp;quot;transformers[sentencepiece]&amp;quot;&lt;/code&gt; 除安装主包 transformers 本身，还会安装与 sentencepiece 相关的额外依赖包，这是一种标准的 Python 包管理习惯，方便用户按需安装某些功能所需的附加依赖，而不用下载安装所有不需要的依赖。&lt;/p&gt;
&lt;p&gt;HF 生态中的其他库 &lt;code&gt;transformers&lt;/code&gt;、&lt;code&gt;Datasets&lt;/code&gt;、&lt;code&gt;Tokenizers&lt;/code&gt;、&lt;code&gt;Accelerate&lt;/code&gt; 和 &lt;code&gt;Hugging Face Hub&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;nlp&#34;&gt;NLP&lt;/h2&gt;
&lt;p&gt;LLMs 是 NLP 的一项重大进步，LLM 特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;规模很大：参数量从百万到百亿两级&lt;/li&gt;
&lt;li&gt;通用能力：在没有特定任务训练的情况下执行多个任务&lt;/li&gt;
&lt;li&gt;情景学习：它可以从 prompt 的实例中学习&lt;/li&gt;
&lt;li&gt;涌现能力：随规模的增大，会出现意料之外的能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LLMs 还是有局限&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;幻觉：他会生成不正确的信息&lt;/li&gt;
&lt;li&gt;不会真正理解：它是纯粹通过统计执行动作的，没有对世界的真正理解&lt;/li&gt;
&lt;li&gt;上下文窗口：有限&lt;/li&gt;
&lt;li&gt;计算资源：需要大量计算资源，包括内存资源&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transformerspipline&#34;&gt;Transformers.pipline&lt;/h2&gt;
&lt;p&gt;Transformers 库的作用是提供了&lt;strong&gt;创建共享模型&lt;/strong&gt;和&lt;strong&gt;使用共享模型&lt;/strong&gt;的功能。&lt;/p&gt;
&lt;p&gt;最基本的对象是 &lt;code&gt;pipeline()&lt;/code&gt; 函数。它将模型与其必要的预处理和后处理步骤连接起来。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pipeline
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;classifier &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pipeline(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sentiment-analysis&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# 默认模型是 distilbert&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;classifier(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;I&amp;#39;ve been waiting for a HuggingFace course my whole life.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;POSITIVE&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;score&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;0.9598047137260437&lt;/span&gt;}]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上述，当创建 classifier 对象时，模型会被下载并缓存，没有指明模型则会 load 默认的模型。如果重新运行该命令，将使用缓存的模型，而无需再次下载。默认模型这里是 &lt;code&gt;distilbert/distilbert-base-uncased-finetuned-sst-2-english&lt;/code&gt;，&lt;strong&gt;不同的 pipline 有不同的 default 模型&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jetson Setup</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-setup/</link>
      <pubDate>Sun, 31 Aug 2025 12:47:02 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-setup/</guid>
      <description>&lt;p&gt;NVIDIA Orin 是一款专为&lt;strong&gt;自动驾驶汽车&lt;/strong&gt;和&lt;strong&gt;机器人&lt;/strong&gt;设计的高性能系统级芯片，包含新一代 Ampere GPU 架构和 Arm Hercules CPU 内核，以及深度学习加速器和计算机视觉加速器。&lt;/p&gt;
&lt;p&gt;应用领域：Orin 芯片不仅适用于自动驾驶汽车，还广泛应用于机器人、工业边缘计算等领域。&lt;/p&gt;
&lt;p&gt;支持C/C++, python, cuda, pytorch, ROS (Robot Operating System), JetPack SDK, DeepStream, VScode&lt;/p&gt;
&lt;p&gt;TensorRT 是 NVIDIA 开发的一个高性能深度学习推理 SDK。它不是完全开源的.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Linux for Tegra (L4T) &lt;/code&gt;是 NVIDIA 为其 Tegra 系列系统芯片 (SoC) 开发的嵌入式 Linux 发行版。它主要用于 NVIDIA Jetson 系列开发套件等嵌入式系统。L4T 提供了运行在 Tegra SoC 上的内核、驱动程序、库和工具，支持各种应用，包括机器人、人工智能、自动驾驶和媒体处理等。 它包含了 NVIDIA 专有的驱动程序，以充分利用 Tegra SoC 的硬件加速功能。不同的 L4T 版本支持不同的 Tegra 系列芯片和功能。 例如，较新的版本可能支持 Vulkan 和更新的 CUDA 版本。 开发者可以使用 L4T 来构建和部署各种嵌入式应用。&lt;/p&gt;
&lt;h1 id=&#34;配置jetson-orin-nano&#34;&gt;配置Jetson Orin Nano&lt;/h1&gt;
&lt;h2 id=&#34;记录命令&#34;&gt;记录命令&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;linux ip: &amp;lt;linux-ip&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;uname: junhui
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install python3-pip
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo pip3 install -U jetson-stats
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo jtop
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo poweroff
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;systemctl status bluetooth
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;systemctl start bluetooth
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;iwconfig  &lt;span style=&#34;color:#75715e&#34;&gt;# 看网速等网络状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-jetpack&#34;&gt;install Jetpack&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 找不到 nvcc 编译器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install nvidia-jetpack  &lt;span style=&#34;color:#75715e&#34;&gt;# 8GB 内容&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;find / -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nvcc&amp;#34;&lt;/span&gt; 2&amp;gt;/dev/null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export CUDA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/local/cuda-12.6
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$PATH:$CUDA_HOME/bin
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export LD_LIBRARY_PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$LD_LIBRARY_PATH:$CUDA_HOME/lib64
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 找到 sample code&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;find / -name &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vectorAdd.cu&amp;#34;&lt;/span&gt; 2&amp;gt;/dev/null 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bash /usr/local/cuda-11.4/bin/cuda-install-samples-11.4.sh ./  &lt;span style=&#34;color:#75715e&#34;&gt;#拷贝 samples 到指定路径&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 验证：(默认找不到头文件，只能指明-I)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvcc $CUDA_HOME/samples/0_Simple/vectorAdd/vectorAdd.cu -I/usr/local/cuda-11.4/samples/common/inc/ -o vectorAdd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvcc vectorAdd.cu -I/home/junhui/workspace/NVIDIA_CUDA-11.4_Samples/common/inc/ -o vectorAdd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nvcc deviceQuery.cpp -I/home/junhui/workspace/NVIDIA_CUDA-11.4_Samples/common/inc -o deviceQuery
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 检查&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dpkg -l | grep nvidia  &lt;span style=&#34;color:#75715e&#34;&gt;#这个命令会列出所有安装的与 &amp;#34;nvidia&amp;#34; 相关的软件包。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dpkg -l | grep nvidia 获取一个大致的组件列表，然后使用 apt-cache show 命令查看特定组件的详细信息
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;主机连接-orin-最佳实践&#34;&gt;主机连接 Orin 最佳实践&lt;/h1&gt;
&lt;p&gt;假如没有外接显示器和鼠标键盘。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jetson Ncu 解读</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-ncu-%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Sun, 31 Aug 2025 12:47:01 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-ncu-%E8%A7%A3%E8%AF%BB/</guid>
      <description>&lt;h2 id=&#34;常用命令&#34;&gt;常用命令&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;launch-and-attach：启动程序并附加分析。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--kernel &amp;lt;kernel_name&amp;gt;：指定要分析的 CUDA 内核（可选，正则表达式匹配）。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--set &amp;lt;set_name&amp;gt;：指定指标集（例如，full、detailed 或自定义集）。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - full: 收集所有可用指标，适合全面分析，但耗时较长。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - detailed: 收集详细指标，覆盖计算、内存、调度等，适合深入优化。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - speed-of-light: 聚焦高层次吞吐量指标（如你的 Speed Of Light Throughput 报告）。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - occupancy: 聚焦占用率指标（如你的 Occupancy 报告）。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - scheduler: 分析线程束调度状态。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - memory: 分析内存访问和缓存性能。
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--metric dram__cycles_active.avg
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;which ncu&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; --query-metrics  &lt;span style=&#34;color:#75715e&#34;&gt;# 输出所有支持的指标和描述&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;which ncu&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; --mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;launch-and-attach --kernel-name ComputeLogSoftmaxForwardInWarp --metric sm__warps_launched ./obj/softmax
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -f ./ncu/softmax-last.ncu-rep &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;which ncu&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; --mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;launch-and-attach  -o ./ncu/softmax-last.ncu-rep ./obj/softmax &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;which ncu&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; --import ./ncu/softmax-last.ncu-rep &amp;gt; ./ncu/softmax-last.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;ncu--o-softmax-lastncu-rep-softmax&#34;&gt;ncu -o ./softmax-last.ncu-rep ./softmax&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  void ComputeLogSoftmaxForwardInWarp&amp;lt;float, float, 4&amp;gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;T1 *, const T1 *, int, int&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1024, 1, 1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;4, 32, 1&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;, Context 1, Stream 7, Device 0, CC 8.7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Section: GPU Speed Of Light Throughput
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ----------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Metric Name             Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ----------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SM Frequency                    Mhz       305.41  &lt;span style=&#34;color:#75715e&#34;&gt;# SM的运行频率：表示处于低功耗模式或未满载运行，由于散热或功耗限制）导致频率降低，&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Elapsed Cycles                cycle       32,515  &lt;span style=&#34;color:#75715e&#34;&gt;# kernel 执行的总时钟周期数：越小越好，如果过高，优化 kernel 以减少指令数或提高并行性。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Memory Throughput                 %        27.33  &lt;span style=&#34;color:#75715e&#34;&gt;# 内存带宽利用率：内存访问的效率 / 硬件峰值。27.33% 远低于 60% 的推荐阈值，表明内存带宽利用率非常低。检查内存访问模式（使用 NCU 的内存统计部分，查看 Global Memory 访问的合并程度）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Duration                         us       106.46  &lt;span style=&#34;color:#75715e&#34;&gt;# kernel 执行的总时间（微秒）： 32,515 cycles ÷ 305.41 MHz&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    L1/TEX Cache Throughput           %        29.40  &lt;span style=&#34;color:#75715e&#34;&gt;# L1 缓存和纹理缓存的带宽利用率：低于 60%，即缓存利用率低。数据访问模式不佳，未充分利用 L1 缓存。缓存命中率低（需要检查 NCU 的缓存命中率统计）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    L2 Cache Throughput               %        22.36  &lt;span style=&#34;color:#75715e&#34;&gt;# 远低于预期，表明 L2 缓存未被有效利用。检查 L2 缓存的命中率（NCU 的缓存统计部分）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    SM Active Cycles              cycle    28,654.75  &lt;span style=&#34;color:#75715e&#34;&gt;# SM 在执行计算任务时的活跃周期数：活跃周期占总周期的比例为 28,654.75 ÷ 32,515 ≈ 88.1% 挺好，但是。查看 NCU 的 Scheduler Statistics，检查线程束调度效率。否存在指令依赖或分支发散。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Compute &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;SM&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; Throughput           %        57.48  &lt;span style=&#34;color:#75715e&#34;&gt;# SM 的计算吞吐量：57.48% 低于 60%，计算资源未被充分利用。可能线程块（Block）或网格（Grid）配置不足，导致 SM 未满载。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ----------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;## 优化建议：低计算吞吐量 (57.48%) 和低内存带宽利用率 (27.33%): 表明内核未充分利用 GPU 的计算和内存资源。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;## 延迟问题 (Latency Issues): 低吞吐量通常由以下原因导致。内存访问延迟（例如，非合并内存访问或缓存未命中）。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;## 建议分析方向：&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          latency issues. Look at Scheduler Statistics and Warp State Statistics &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; potential reasons.                 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;## fp32 的峰值性能是fp64的64倍，但是fp32 的吞吐只有16%，说明内核并未充分利用GPU的计算资源。与上述SM 吞吐 只有57.48% 一致 **&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Section: GPU Speed Of Light Roofline Chart
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    INF The ratio of peak float fp32 to double fp64 performance on this device is 64:1. 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          The kernel achieved 16% of this device&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt;s fp32 peak performance and 0% of its fp64 peak performance. 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结论：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jetson Orin Chip</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-orin-chip/</link>
      <pubDate>Sun, 31 Aug 2025 12:47:01 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/jetson/jetson-orin-chip/</guid>
      <description>&lt;p&gt;NVIDIA Jetson Orin Nano 4GB版本的芯片使用的是NVIDIA Ampere架构，配备512个CUDA核心和16个Tensor Cores。具体的芯片型号是 GA10B&lt;/p&gt;
&lt;h1 id=&#34;jetson-orin-nano-4gb&#34;&gt;Jetson Orin Nano 4GB&lt;/h1&gt;
&lt;p&gt;GPU name: GA10B&lt;/p&gt;
&lt;p&gt;Architechture: NVIDIA Ampere&lt;/p&gt;
&lt;p&gt;算力：34 TOPS&lt;/p&gt;
&lt;p&gt;GPU：NVIDIA Ampere architecture&lt;/p&gt;
&lt;p&gt;SM 个数：4&lt;/p&gt;
&lt;p&gt;Tensor cores/SM：4&lt;/p&gt;
&lt;p&gt;CUDA core/SM：128&lt;/p&gt;
&lt;p&gt;总 Tensor Cores：16&lt;/p&gt;
&lt;p&gt;总 CUDA core：512&lt;/p&gt;
&lt;p&gt;GPU 最大频率：1020MHz&lt;/p&gt;
&lt;p&gt;CPU：6-core Arm® Cortex®-A78AE v8.2 64-bit CPU 1.5MB L2 + 4MB L3&lt;/p&gt;
&lt;p&gt;CPU 最大频率：1.7 GHz&lt;/p&gt;
&lt;p&gt;内存：4GB 64-bit LPDDR5 51 GB/s&lt;/p&gt;
&lt;p&gt;功耗：7W - 10W - 25W&lt;/p&gt;
&lt;p&gt;吞吐：512 * 611.35 * 1000000 * 10^9 * 2(flops) = 34 TOPS&lt;/p&gt;</description>
    </item>
    <item>
      <title>通用硬件知识</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E9%80%9A%E7%94%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:58 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E9%80%9A%E7%94%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/</guid>
      <description>&lt;h1 id=&#34;硬件通用&#34;&gt;硬件通用&lt;/h1&gt;
&lt;h2 id=&#34;单核-cpu-实际是串行的&#34;&gt;单核 CPU 实际是串行的&lt;/h2&gt;
&lt;p&gt;在单核 CPU 上，多线程的并发执行是通过上下文切换实现的&lt;strong&gt;假象&lt;/strong&gt;。 实际上，任何一个时间点上，CPU 核心只执行一个线程的指令。 多线程的并行性是通过快速地在不同线程之间切换来实现的，切换速度快到足以让人感觉多个线程同时运行。&lt;/p&gt;
&lt;h2 id=&#34;compute-capability&#34;&gt;Compute Capability&lt;/h2&gt;
&lt;p&gt;Compute Capability 也称作 SM 版本。在应用中，通常会指定最低 Compute Capability 版本，告诉编译器，如果硬件支持的 Compute Capability 版本低于 6.0，那么将无法执行这个和函数。做法是使用 nvcc 时增加一个选项 &lt;code&gt;nvcc -arch=sm_60&lt;/code&gt;。A100 SM 版本是7.5， H100 的SM 版本是8.0。&lt;/p&gt;
&lt;p&gt;高版本的 Compute Capability 是低版本 Compute Capability 的超集。即高版本包含低版本所有性质和功能。&lt;/p&gt;
&lt;p&gt;这里官方给出不同 SM 版本的细节信息，包括 warp 调度器 个数，
&lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#architecture-7-x&#34;&gt;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#architecture-7-x&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;gpu-频率-和-传输带宽&#34;&gt;GPU 频率 和 传输带宽&lt;/h2&gt;
&lt;p&gt;处理器频率衡量的是处理器的速度，而带宽衡量的是数据传输速率。比喻：处理器频率快比作翻书的节奏快。存储器带宽大比作读完一页很快。两者需要匹配上，才能达到最佳效率。***&lt;/p&gt;
&lt;p&gt;即：CPU/GPU 频率和带宽之间的关系是间接的。更高的 CPU/GPU 频率意味着处理器可以更快地处理数据，但这并不直接决定数据传输速度。带宽限制了 CPU/GPU 可以从内存或存储设备中读取数据以及将数据写入内存或存储设备的速度。如果带宽不足，即使 CPU/GPU 频率很高，性能也会受到限制，因为处理器必须等待数据传输完成。 因此，为了获得最佳性能，需要 CPU/GPU 频率和足够的带宽共同作用。&lt;/p&gt;
&lt;h2 id=&#34;一个时钟周期-时钟频率&#34;&gt;一个时钟周期 时钟频率&lt;/h2&gt;
&lt;p&gt;晶体管电路中时钟信号的一个完整振荡周期。&lt;strong&gt;它是芯片执行操作的最小单位&lt;/strong&gt;。时钟周期的长度由时钟频率决定。比如翻书，一个时钟周期就是翻一页的时间。时钟周期越短，翻书的速度越快， 1 GHz 表示每秒 10 亿个时钟周期，每秒翻页10亿页书。&lt;/p&gt;</description>
    </item>
    <item>
      <title>概念 Stream</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-stream/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-stream/</guid>
      <description>&lt;h2 id=&#34;多-stream-用于-overlap-datatransfer&#34;&gt;多 stream 用于 overlap datatransfer&lt;/h2&gt;
&lt;p&gt;并发，隐藏延时要实现数据传输与其他操作的重叠，需要使用 CUDA 流.&lt;/p&gt;
&lt;p&gt;CUDA 中的流是一系列按主机代码发出的顺序在设备上执行的运算。虽然流内的运算保证按预定顺序执行，但不同流中的运算可以交错执行，并且在可能的情况下，它们甚至可以并行运行。***&lt;/p&gt;
&lt;p&gt;所有 CUDA 中在 device 中的操作（内核和数据传输）都在流中运行。当未指定流时，使用默认流（也称为“空流”）。默认流与其他流不同，因为它是一个与设备操作同步的流。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;a, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_a;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaMallocHost((&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;a, bytes);   &lt;span style=&#34;color:#75715e&#34;&gt;// 弃用的   // host pinned 更推荐使用 cudaHostAlloc
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaMalloc((&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_a, bytes);    &lt;span style=&#34;color:#75715e&#34;&gt;// device
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// create events and streams
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEvent_t startEvent, stopEvent, dummyEvent;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaStream_t stream[nStreams];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;startEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;stopEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;dummyEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; nStreams; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;i)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cudaStreamCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;stream[i]);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在默认流中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// baseline case - sequential transfer and execute
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  memset(a, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, bytes);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventRecord(startEvent,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaMemcpy(d_a, a, bytes, cudaMemcpyHostToDevice) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  kernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;blockSize, blockSize&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_a, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaMemcpy(a, d_a, bytes, cudaMemcpyDeviceToHost) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventRecord(stopEvent, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventSynchronize(stopEvent) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventElapsedTime(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;ms, startEvent, stopEvent) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time for sequential transfer and execute (ms): %f&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ms);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  max error: %e&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, maxError(a, n));
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;版本1：asynchronous version 1: loop over {copy, kernel-exe, copy-back}&lt;/p&gt;</description>
    </item>
    <item>
      <title>概念 Unified Memory</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-unified-memory/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-unified-memory/</guid>
      <description>&lt;h2 id=&#34;统一内存编程-unified-memory&#34;&gt;统一内存编程 Unified Memory&lt;/h2&gt;
&lt;p&gt;它允许开发者在编写并行计算程序时，不必显式地管理数据在 CPU 和 GPU 之间的传输。统一内存的引入旨在简化 CUDA 编程，提高开发效率，并通过自动将数据迁移到正在使用它的处理器上来优化数据访问速度。&lt;/p&gt;
&lt;p&gt;统一内存的工作原理是提供一个单一的、连续的虚拟地址空间，这个空间对系统中的所有处理器（包括 CPU 和 GPU ）都是可见的。底层的 CUDA 运行时系统负责管理数据的实际物理位置，并在必要时自动将数据迁移到适当的设备上。这意味着开发者可以使用&lt;strong&gt;单一的指针&lt;/strong&gt;来引用统一内存中的数据，而不需要担心数据实际上是存储在主机内存还是GPU显存中。&lt;/p&gt;
&lt;p&gt;统一内存提供了诸多便利，但它也可能引入一些问题，如内存抖动。&lt;/p&gt;</description>
    </item>
    <item>
      <title>概念 协作组</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-%E5%8D%8F%E4%BD%9C%E7%BB%84/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-%E5%8D%8F%E4%BD%9C%E7%BB%84/</guid>
      <description>&lt;h2 id=&#34;合作组cooperative-groups&#34;&gt;合作组（Cooperative Groups）&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;nvcc parallel_reduction.cu -o parallel_reduction&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;例子展示了如何使用 thread_block 来同步线程块内的线程，实现高效的并行规约。&lt;/p&gt;
&lt;p&gt;这个例子是一个简单的演示，实际应用中，合作组可以用于更复杂的并行算法，例如扫描 (scan) 和排序等。 更高级的用法可能涉及到跨块同步，这需要使用更复杂的 CUDA 原语。&lt;/p&gt;</description>
    </item>
    <item>
      <title>线程同步</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</guid>
      <description>&lt;h2 id=&#34;线程同步&#34;&gt;线程同步&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;同一个 warp 内的 threads 天然同步。（有硬件支持）&lt;/li&gt;
&lt;li&gt;block 与 block 之间是异步的，不存在相互等待。当前 kernel 执行结束后， block 之间自然同步了。&lt;/li&gt;
&lt;li&gt;CUDA 中没有全局同步，全局同步的系统开销会很大。&lt;/li&gt;
&lt;li&gt;一个 block 内的所有 threads 有时候是需要步的。当一个 thread 执行到 &lt;code&gt;__syncthreadas()&lt;/code&gt; 时，这个 thread 会看它所在的 block 内的其他所有 threads 情况，如果发现还有其他 threads 没有执行到这个位置，则这个 thread 等待其他 threads 。直到 block 中所有 active 的 threads 都执行到此，接着向下执行。避免相互等待进入死锁。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;同步异步&#34;&gt;同步异步&lt;/h2&gt;
&lt;p&gt;遇到 cudaMemcpy() 执行变成同步的，也就是说，所有指令必须等待其他指令执行到此，才可以一起向下继续执行。如果没有 cudaMemcpy()，可以使用 cudaDeviceSynchronize() 实现同步。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;t1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myCPUTimer();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;saxpy&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;(N&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(N, &lt;span style=&#34;color:#ae81ff&#34;&gt;2.0&lt;/span&gt;, d_x, d_y);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cudaDeviceSynchronize();   &lt;span style=&#34;color:#75715e&#34;&gt;// 没有只一句的话，得到的时间是 CPU 调用 kernel的时间，而不是GPU执行kernel的时间。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;t2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; myCPUTimer();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;CPU 与 GPU 是异步的，只有加上 &lt;code&gt;cudaDeviceSynchronize()&lt;/code&gt;，告诉 CPU 等待 GPU 把 kernel 执行完毕。&lt;/p&gt;</description>
    </item>
    <item>
      <title>工具箱</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%B7%A5%E5%85%B7%E7%AE%B1/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:56 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%B7%A5%E5%85%B7%E7%AE%B1/</guid>
      <description>&lt;h1 id=&#34;工具箱&#34;&gt;工具箱&lt;/h1&gt;
&lt;p&gt;通常情况下，开发者会结合使用这两个工具：Nsight Systems 用于识别性能瓶颈的区域，然后使用 Nsight Compute 对这些区域进行更深入的分析和优化。&lt;/p&gt;
&lt;h2 id=&#34;1-nsight-systems-整个系统的分析&#34;&gt;1. Nsight Systems [整个系统的分析]&lt;/h2&gt;
&lt;p&gt;提供系统范围的性能分析，关注应用程序在整个系统中的行为，包括 CPU、GPU、内存和网络。它更适合于整体性能调优和瓶颈识别。&lt;/p&gt;
&lt;h2 id=&#34;2-nsight-compute-kernel的深入分析&#34;&gt;2. Nsight Compute [kernel的深入分析]&lt;/h2&gt;
&lt;p&gt;提供对 CUDA 内核的深入分析，关注内核的性能，例如内存访问模式、分支预测和寄存器使用情况。它更适合于 CUDA 代码的微调和优化。其中也集成到了Occupancy Calculator 工具 (&lt;a href=&#34;https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator&#34;&gt;https://docs.nvidia.com/nsight-compute/NsightCompute/index.html#occupancy-calculator&lt;/a&gt;)&lt;/p&gt;
&lt;h2 id=&#34;3-occupancy-calculator&#34;&gt;3. Occupancy Calculator：&lt;/h2&gt;
&lt;p&gt;你可以改变5个数值：SM 版本，Shared memory 大小，Block大小，每个Thread的register个数，每个Block 的 Shared memory 大小。 然后系统会根据给出配置和硬件极限 计算出 GPU 的 占用率。即这个SM 中的 warp 占用百分比。&lt;/p&gt;
&lt;p&gt;还有信息包括 资源实际分配情况。&lt;/p&gt;
&lt;p&gt;调配置，使得 GPU 占用率尽量大到 100%。&lt;/p&gt;
&lt;h2 id=&#34;3-nvprof&#34;&gt;3. nvprof&lt;/h2&gt;
&lt;p&gt;nvprof ./a.out 返回每个操作的耗时。根据此，可以简历优化的优先级。&lt;/p&gt;
&lt;h2 id=&#34;初始化不一定在-host-端&#34;&gt;初始化不一定在 host 端&lt;/h2&gt;
&lt;p&gt;CUDA程序的一个基本规则是，尽可能减少 host 与 device 间的数据交换。比如 代操作数据为二维或三维点，一个技巧是，为了尽可能减少数据传输，线程 id 天然可以表示成数据点的坐标：(idx,idy)&amp;lt;=&amp;gt;(x,y).&lt;/p&gt;</description>
    </item>
    <item>
      <title>概念 CTA Block</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-cta-block/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:56 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-cta-block/</guid>
      <description>&lt;h2 id=&#34;cta-就是block&#34;&gt;CTA （就是Block）&lt;/h2&gt;
&lt;p&gt;cuda 中的 CTA 是什么概念？什么时候引入的？它的特点是什么？给是应用实例？&lt;/p&gt;
&lt;p&gt;CTA (Cooperative Thread Array) 是 CUDA 中的一个重要概念，它实际上就是CUDA编程模型中的线程块(Thread Block)，是逻辑上的概念。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CTA 概念在CUDA早期版本就已引入，是CUDA编程模型的核心概念之一。&lt;/li&gt;
&lt;li&gt;它代表了一组可以协同工作的线程，这些线程可以共享资源并进行同步。&lt;/li&gt;
&lt;li&gt;CTA 是 CUDA 程序的任务分发单位，与编程模型中的 block 是同一事物的不同表述&lt;/li&gt;
&lt;li&gt;一个 CTA 最多可以由16个 warp 组成，即最多包含512个线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CTA 特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;独立执行：每个CTA可以独立于其他CTA执行，没有固定的执行顺序。&lt;/li&gt;
&lt;li&gt;资源共享：CTA内的线程可以共享共享内存(Shared Memory)。&lt;/li&gt;
&lt;li&gt;同步能力：CTA内的线程可以使用同步原语（如__syncthreads()）进行同步。&lt;/li&gt;
&lt;li&gt;大小限制：一个CTA中的线程数量是有限的，通常不超过1024个。&lt;/li&gt;
&lt;li&gt;调度单位：GPU硬件调度器以CTA为单位进行调度。&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>概念 Event</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-event/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:56 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-event/</guid>
      <description>&lt;h2 id=&#34;cuda-event--stream&#34;&gt;CUDA event &amp;amp; stream&lt;/h2&gt;
&lt;p&gt;默认使用的 stream 0。CUDA 流简单来说是一系列&lt;strong&gt;按顺序&lt;/strong&gt;在设备上执行的运算。&lt;strong&gt;不同 Stream 中的运算可以交错进行&lt;/strong&gt;，在某些情况下还可以重叠——这一特性可以用来隐藏主机和设备之间的数据传输。&lt;/p&gt;
&lt;p&gt;这里是使用 event 的最佳实践：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 创建 CUDA 事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEvent_t start, stop;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;start);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;stop);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 记录开始事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEventRecord(start, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;// 0 代表默认流
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 启动内核
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  myKernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;(size &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;256&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_data, size);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 记录事件 stop。 这本身是一个异步操作；它不会阻塞 CPU。 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 记录事件只是在流中插入一个标记。在事件被记录后，GPU 仍然可能继续执行其他任务。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEventRecord(stop, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventSynchronize(stop); &lt;span style=&#34;color:#75715e&#34;&gt;// 阻塞 CPU 直到事件 stop 完成
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 计算经过的时间
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; milliseconds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventElapsedTime(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;milliseconds, start, stop);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 将数据从设备复制回主机
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaMemcpy(h_data, d_data, size &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;sizeof&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;), cudaMemcpyDeviceToHost);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 打印结果
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Kernel execution time: %.3f ms&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, milliseconds);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 销毁事件
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEventDestroy(start);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventDestroy(stop);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>内存模型</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:55 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;h2 id=&#34;内存模型&#34;&gt;内存模型&lt;/h2&gt;
&lt;h3 id=&#34;0-l1l2&#34;&gt;0. L1/L2&lt;/h3&gt;
&lt;p&gt;每个 SM 有自己独有的一片存储空间，这个空间被 Shared memory 和 L1 缓存公用。而 L2 缓存 被所有 SM 公用， L2 中缓存来自 Global Memory 中的数据。&lt;/p&gt;
&lt;p&gt;SP 访存时，访问数据时的确遵循一个层次结构。 首先尝试从寄存器 (Registers) 中获取数据，若没有找到则从 L1 中找数据，若没有则从 L2 中找，若仍没有，从 Global Memory 中找。&lt;/p&gt;
&lt;h3 id=&#34;1-寄存器-registers&#34;&gt;1. 寄存器 (Registers):&lt;/h3&gt;
&lt;p&gt;寄存器内存 Bank 冲突: CUDA 的多处理器 (SM) 中的寄存器被组织成多个 Bank。如果多个线程同时访问同一个 Bank 中的寄存器，就会发生 Bank 冲突。这会导致访问被串行化，而不是并行化，从而降低性能。 这与共享内存的 Bank 冲突类似，但发生在寄存器级别。应用程序无法直接控制 Bank 冲突。编译器和硬件会尝试优化以减少冲突，但无法完全避免。&lt;/p&gt;
&lt;p&gt;特性: 每个线程拥有私有的寄存器，速度最快，但数量有限。
最佳实践: 用于存储线程频繁访问的局部变量。如果寄存器数量不足（超过 SM 可用的寄存器数量时），编译器会将变量溢出到局部内存。&lt;/p&gt;
&lt;p&gt;寄存器是每个线程专用的高速片上存储。一个寄存器的标准大小是&lt;del&gt;32位。由于 float 数据类型通常也是 32 位，因此一个寄存器可以存储 一个 float 值。&lt;/del&gt; 大小不一定，不同的架构的寄存器的位数不一样。&lt;/p&gt;
&lt;h3 id=&#34;2-局部内存-local-memory&#34;&gt;2. 局部内存 (Local Memory):&lt;/h3&gt;
&lt;p&gt;特性:&lt;/p&gt;</description>
    </item>
    <item>
      <title>内存访问 对齐访存</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE-%E5%AF%B9%E9%BD%90%E8%AE%BF%E5%AD%98/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:55 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE-%E5%AF%B9%E9%BD%90%E8%AE%BF%E5%AD%98/</guid>
      <description>&lt;h2 id=&#34;coalesced-memory-access&#34;&gt;Coalesced Memory Access&lt;/h2&gt;
&lt;p&gt;要实现合并内存访问，需要满足以下条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;连续&lt;/strong&gt;内存地址: &lt;strong&gt;warp 中的相邻线程必须访问连续的全局内存地址&lt;/strong&gt;。这意味着线程 0 访问地址 A，线程 1 访问地址 A+B，线程 2 访问地址 A+2B，以此类推，其中 B 是每个线程访问的内存大小。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;对齐&lt;/strong&gt;: 访问的内存&lt;strong&gt;地址起始位置&lt;/strong&gt;必须按照一定大小对齐。对齐大小取决于每个线程访问的数据大小和 GPU 的计算能力。例如，对于 32 位数据，通常需要 128 字节对齐。上面的 A = 32.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据大小: 访问的数据大小也影响合并的效率。较大的数据访问（例如 128 位或 256 位）通常比较小的数据访问（例如 8 位或 16 位）更容易合并。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;合并访问的理想情况是一个 warp 中的 32 个线程应该能够在一个或少数几个&lt;strong&gt;内存事务&lt;/strong&gt;中完成所有数据的读取或写入。如果不是合并访存，GPU 可能需要多个内存事务才能完成所有数据的读取或写入。&lt;/p&gt;
&lt;p&gt;上述中的：“对于 32 位数据，通常需要 128 字节对齐”，如何理解：每个线程访问 32位 数据，就是 4 字节数据，一个 warp 32 线程，那么一个 warp 会访问 32 * 4 = 128 字节数据。如果这 128 字节的数据在内存中是 128 字节&lt;strong&gt;对齐的（起始地址是 128 的倍数&lt;/strong&gt;），那么 GPU 就可以在一个内存事务中完成所有数据的读取或写入，从而实现合并访问。&lt;/p&gt;</description>
    </item>
    <item>
      <title>内存访问模式</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:55 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E6%A8%A1%E5%BC%8F/</guid>
      <description>&lt;h2 id=&#34;线程访问内存&#34;&gt;线程访问内存&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;threadIdx.x、threadIdx.y、threadIdx.z、blockIdx.x、blockIdx.y、blockIdx.z、blockDim.x、blockDim.y 和 blockDim.z&lt;/code&gt; 等内置变量之间的计算得到的。&lt;/p&gt;
&lt;p&gt;使用全局线程 ID 或局部线程 ID（threadIdx）以及其他相关信息（例如，矩阵的行数、列数、leading dimension 等），可以计算出每个线程需要访问的内存地址。&lt;/p&gt;
&lt;p&gt;通过合理地组织线程块和线程，并使用适当的内存地址计算方式，可以实现不同的内存访问模式，例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;合并访问 (Coalesced Access)：&lt;/p&gt;
&lt;p&gt;当一个 warp 中的线程访问连续的内存地址时，可以实现合并访问，从而提高内存访问效率。
通常，可以&lt;strong&gt;通过确保线程 ID 与内存地址之间存在线性关系来实现合并访问&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;避免 Bank Conflict：&lt;/p&gt;
&lt;p&gt;在使用共享内存时，需要避免 bank conflict，可以通过调整线程块的大小和共享内存的布局来避免 bank conflict。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;自定义内存访问模式&#34;&gt;自定义内存访问模式&lt;/h2&gt;
&lt;p&gt;内存访问是由内核代码中的线程索引和内存访问&lt;strong&gt;指令隐式决定的&lt;/strong&gt;。然而，你可以通过&lt;strong&gt;巧妙地设计内核代码&lt;/strong&gt;来控制和优化内存访问模式，从而提高性能。这主要体现在如何组织数据和编写内核代码以最大限度地利用内存层次结构（例如共享内存和缓存）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;协同内存访问 (Coalesced Memory Access): 这是 CUDA 编程中最重要的优化策略之一。这允许GPU更有效地从全局内存中读取数据，因为每个&lt;strong&gt;内存事务&lt;/strong&gt;可以传输多个数据字。&lt;/li&gt;
&lt;li&gt;共享内存 (Shared Memory): 共享内存是每个线程块中快速、低延迟的内存。通过将经常访问的数据复制到共享内存中，可以减少对全局内存的访问次数，从而显著提高性能。&lt;/li&gt;
&lt;li&gt;循环展开 (Loop Unrolling): 循环展开可以减少循环开销，并允许编译器进行更好的优化。&lt;/li&gt;
&lt;li&gt;数据重排 (Data Reordering): 如果你的数据存储方式不适合你的访问模式，你可以重新排列数据以提高性能。例如，如果你的内核需要访问矩阵的列，而你的数据以行优先的方式存储，那么重新排列数据为列优先的方式可能会提高性能。&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Warp</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/warp/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:54 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/warp/</guid>
      <description>&lt;h2 id=&#34;warp--lane&#34;&gt;Warp &amp;amp; Lane&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Warp 是 GPU 中最基本的调度单位。&lt;/li&gt;
&lt;li&gt;Warp 是一个包含 32 个线程的执行单元。这些线程被称为 Lane。 Warp 中的所有 Lane 同时执行相同的指令。这被称为单指令多线程 (SIMT) 执行模型。&lt;/li&gt;
&lt;li&gt;每个 Lane 都是一个独立的线程，拥有自己的数据和状态。它们可以访问自己的寄存器、私有内存和全局内存。&lt;/li&gt;
&lt;li&gt;每个 Lane 都有一个唯一的 Lane ID，从 0 到 31 。可以使用内建函数 &lt;code&gt;__Laneid()&lt;/code&gt; 或 &lt;code&gt;threadIdx.x &amp;amp; 31&lt;/code&gt; 来获取 Lane ID。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUDA 提供了一组 Warp shuffle 指令，允许 Lane 之间进行数据交换&lt;/strong&gt;。这些指令包括 &lt;code&gt;__shfl_sync()&lt;/code&gt;、&lt;code&gt;__shfl_up_sync()&lt;/code&gt;、&lt;code&gt;__shfl_down_sync()&lt;/code&gt; 和 &lt;code&gt;__shfl_xor_sync()&lt;/code&gt;。 这些指令可以高效地进行 Warp 内部的数据通信，而无需访问共享内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以通过使用 Warp shuffle 指令和 Lane ID 来间接地控制 Lane 的行为。不能直接对 Lane 进行编程。&lt;/p&gt;
&lt;h2 id=&#34;warp-之间没有传统意义上的上下文切换&#34;&gt;Warp 之间没有（传统意义上的）上下文切换&lt;/h2&gt;
&lt;p&gt;有 Warp 调度器。所以 Warp 需要调度。&lt;/p&gt;
&lt;p&gt;CUDA 并非以传统操作系统意义上的“上下文切换”方式在线程之间切换。 GPU 的 SM 会同时执行多个 Warp，并通过调度器动态地选择哪个 Warp 执行下一条指令。&lt;strong&gt;这更像是一种指令级并行，而不是线程级上下文切换&lt;/strong&gt;。 没有显式的“切换”动作，而是并发执行。CUDA 利用 SIMT 架构，通过并发执行多个 Warp 来隐藏内存延迟和指令执行延迟，而不是通过频繁的线程上下文切换。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Warp 线程调度</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/warp-%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:54 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/warp-%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6/</guid>
      <description>&lt;h2 id=&#34;线程调度&#34;&gt;线程调度&lt;/h2&gt;
&lt;p&gt;为什么 GPU 的 threads 数量远远多于物理执行单元（SP）。主要原因在于线程的并发执行和多线程的掩盖。虽然 SM 也有上下文切换，但这不是主要原因。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;多线程掩盖&lt;/strong&gt; (Multithreading Masking): 当一个 Warp 中的线程遇到内存访问延迟或其他阻塞操作时，SM 会迅速（零开销）切换到另一个 Warp，继续执行其他线程。这被称为多线程掩盖。通过快速切换 Warp，SM 能够隐藏延迟，提高整体吞吐量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;非传统的上下文切换&lt;/strong&gt;: 虽然 SM 会进行上下文切换，但这主要用于在&lt;strong&gt;不同 Warp 之间切换&lt;/strong&gt;，以最大限度地利用资源，而不是像 CPU 一样频繁地进行线程上下文切换。 CPU 的上下文切换开销相对较大，而 GPU 的上下文切换开销相对较小，因为 &lt;strong&gt;Warp 的切换开销远小于线程的开销&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总而言之，GPU 的线程数量远大于物理执行单元，是其架构设计和并行计算策略的结果。&lt;/p&gt;
&lt;h2 id=&#34;warp-调度&#34;&gt;Warp 调度&lt;/h2&gt;
&lt;p&gt;当一个 Warp 因为内存访问或其他原因暂停执行时，&lt;strong&gt;Warp 调度器&lt;/strong&gt;会立即选择另一个准备就绪的 Warp 开始执行，从而最大限度地利用 SM 的计算资源，避免空闲。这个切换过程发生在硬件层面，速度极快，其开销被隐藏在硬件的流水线中。&lt;strong&gt;Warp 调度机制通过硬件层面的优化&lt;/strong&gt;，将上下文切换的开销降到极低。***&lt;/p&gt;
&lt;p&gt;Warp 调度时，究竟有没有上下文切换？ 答：没有！&lt;/p&gt;
&lt;p&gt;假设一个 CUDA 设备拥有 16 个 SM，每个 SM 包含 128 个SP。这些 SP 并非独立执行不同的指令，而是以 Warp 为单位协同工作。每个 Warp 包含 32 个线程，这些线程同时执行相同的指令。一个 SM 可以同时运行多个 Warp，并在它们之间快速切换，以&lt;strong&gt;最大限度地利用 SP 并隐藏延迟&lt;/strong&gt;。总共有 12288 个线程，这些线程被分配到不同的 Warp 和 SM 中执行。SM 通过调度这些 Warp 来实现高吞吐量和延迟隐藏。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why Cuda</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/why-cuda/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:54 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/why-cuda/</guid>
      <description>&lt;h2 id=&#34;-既然-nvidia-已经有不少高性能算子库了为什么提供-cuda-编程模型让用户重复造轮子吗&#34;&gt;@ 既然 Nvidia 已经有不少高性能算子库了，为什么提供 CUDA 编程模型？让用户重复造轮子吗？&lt;/h2&gt;
&lt;p&gt;虽然 NVIDIA 提供了许多高性能算子库，例如 cuDNN、cuBLAS 和 cuFFT 等。可以直接用于深度学习、线性代数和快速傅里叶变换等常见任务，但 CUDA 编程模型仍然至关重要&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;灵活性与定制化: 现成的算子库虽然高效，但它们的功能有限，无法涵盖所有可能的计算需求。CUDA 允许开发者针对特定算法或应用场景编写自定义内核，实现更高的性能和更精细的控制。&lt;/li&gt;
&lt;li&gt;性能优化: 即使对于可以使用现有库的任务，通过仔细设计&lt;strong&gt;内核&lt;/strong&gt;和&lt;strong&gt;内存访问模式&lt;/strong&gt;。进行更深入的优化。&lt;/li&gt;
&lt;li&gt;CUDA 提供了对 NVIDIA GPU 硬件的直接访问，允许开发者充分利用 GPU 的并行计算能力。这比使用更高层次的库更有效，因为后者可能需要进行额外的间接调用和数据转换。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CUDA 编程模型并非为了让用户重复造轮子，而是为了提供一种&lt;strong&gt;灵活、高效且可定制&lt;/strong&gt;的工具，用于开发各种高性能并行计算应用。&lt;strong&gt;现成的算子库和 CUDA 编程模型可以互补使用&lt;/strong&gt;，开发者可以根据实际需求选择最合适的方案。 对于需要高度定制化、极致性能或对底层硬件有精细控制需求的场景，CUDA 编程是不可或缺的。&lt;/p&gt;
&lt;h2 id=&#34;-为什么-pytorch-有自研算子的-cuda-实现而不是直接使用-nvidia-提供的高性能算字库&#34;&gt;@ 为什么 PyTorch 有自研算子的 CUDA 实现，而不是直接使用 Nvidia 提供的高性能算字库?&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;灵活性与控制: 直接使用 NVIDIA 的库虽然方便，但会&lt;strong&gt;牺牲一定的灵活性&lt;/strong&gt;。PyTorch 需要对算子的行为进行精细的控制，以适应其自动微分系统、各种优化策略（例如混合精度训练）以及不同的硬件平台。 自行实现允许 PyTorch 更紧密地集成算子到其框架中，并根据需要进行调整。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性能优化: 虽然 NVIDIA 的库通常性能很高，但&lt;strong&gt;它们并非针对所有情况都进行了最佳优化&lt;/strong&gt;。PyTorch 可以根据其自身的架构和使用模式，对算子进行针对性的优化，从而获得更高的性能。这尤其体现在一些新兴的算法或硬件架构上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可扩展性与定制化: PyTorch 的目标是支持广泛的硬件和算法。自行实现算子使得 PyTorch 能够更容易地扩展到新的硬件平台和算法，而无需依赖 NVIDIA 库的更新速度。 这对于 PyTorch 的长期发展和适应未来技术至关重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特定功能支持: 某些 PyTorch 的功能可能需要一些 NVIDIA 库不提供的特定算子实现。&lt;/p&gt;</description>
    </item>
    <item>
      <title>互操作性</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E4%BA%92%E6%93%8D%E4%BD%9C%E6%80%A7/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:54 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E4%BA%92%E6%93%8D%E4%BD%9C%E6%80%A7/</guid>
      <description>&lt;h2 id=&#34;互操作性&#34;&gt;互操作性&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;CUDA C&lt;/code&gt;、&lt;code&gt;Thrust&lt;/code&gt; 和 &lt;code&gt;CUTLASS&lt;/code&gt; 等都可以在同一个 CUDA 程序中协同工作，它们之间存在互操作性。这意味着它们可以共享数据和操作，并且可以组合使用以构建高性能的 GPU 应用程序。互操作性体现在以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据共享&lt;/li&gt;
&lt;li&gt;操作组合&lt;/li&gt;
&lt;li&gt;统一的编程模型&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如，Pytorch 源码中有些算子前半部分使用 cuda 构建计算过程，后半部分会用到 thrust 库 中的 线性组合 接口。&lt;/p&gt;</description>
    </item>
    <item>
      <title>从源码到可执行文件</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E4%BB%8E%E6%BA%90%E7%A0%81%E5%88%B0%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:54 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E4%BB%8E%E6%BA%90%E7%A0%81%E5%88%B0%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/</guid>
      <description>&lt;h2 id=&#34;nvcc-和-ptxas&#34;&gt;nvcc 和 ptxas&lt;/h2&gt;
&lt;h3 id=&#34;nvccnvidia-cuda-compiler-driver&#34;&gt;nvcc（NVIDIA CUDA Compiler Driver）&lt;/h3&gt;
&lt;p&gt;nvcc 是 NVIDIA CUDA &lt;strong&gt;编译器驱动程序&lt;/strong&gt;，它负责管理整个 CUDA 编译过程。它的主要职责包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;预处理&lt;/strong&gt;：处理宏定义、头文件包含等预处理步骤。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分离 Host 代码和 Device 代码&lt;/strong&gt;：将 CUDA 源代码分离成 Host 代码（Host Code）和 Device 代码（Device Code）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编译 Host 代码&lt;/strong&gt;：调用标准的 C++ 编译器（如 g++ 或 clang）来编译 Host 代码部分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;编译 Device 代码&lt;/strong&gt;：nvcc 将 device 代码编译成 PTX 代码，并传递给 ptxas 进行进一步编译。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;链接&lt;/strong&gt;：将 Host 代码和 Device 代码链接在一起，生成最终的可执行文件或库文件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;nvcc -ptx my_kernel.cu -o my_kernel.ptx&lt;/code&gt; 查看对应的 PTX 代码。&lt;/p&gt;
&lt;h3 id=&#34;ptxasparallel-thread-execution-assembler&#34;&gt;ptxas（Parallel Thread Execution Assembler）&lt;/h3&gt;
&lt;p&gt;ptxas 是 CUDA 工具链中的汇编器，它专门负责将 PTX（Parallel Thread Execution）代码编译成 GPU 可以执行的机器代码（SASS）。它的主要职责包括：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tensor Core</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:53 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core/</guid>
      <description></description>
    </item>
    <item>
      <title>Tensor Core Wmma</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core-wmma/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:53 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core-wmma/</guid>
      <description></description>
    </item>
    <item>
      <title>Tensor Core Wmma Detail</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core-wmma-detail/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:53 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/tensor-core-wmma-detail/</guid>
      <description></description>
    </item>
    <item>
      <title>Kernel 性能瓶颈</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;NVIDIA Nsight Systems: Nsight Systems 是一个系统范围的性能分析工具，可以可视化 CUDA kernel 的执行情况，包括 CPU 和 GPU 之间的交互、内存传输等。它可以帮助你识别 CPU 瓶颈、GPU 瓶颈以及内存瓶颈。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NVIDIA Nsight Compute: Nsight Compute 是一个 CUDA kernel 级别的性能分析器。它可以提供关于 kernel 执行的详细信息，例如指令吞吐量、内存访问模式、warp 发散等。使用 Nsight Compute 可以帮助你深入了解 kernel 的性能瓶颈，并指导你进行优化。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;常见的-cuda-kernel-性能瓶颈&#34;&gt;常见的 CUDA Kernel 性能瓶颈&lt;/h2&gt;
&lt;h3 id=&#34;1-全局内存访问瓶颈&#34;&gt;1. 全局内存访问瓶颈&lt;/h3&gt;
&lt;p&gt;全局内存访问延迟高，带宽有限，是 CUDA kernel 性能的常见瓶颈。解决方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;合并访问: 尽量让线程束（warp）中的线程访问连续的内存地址，以实现合并访问。合并访问可以显著提高内存带宽利用率。&lt;/li&gt;
&lt;li&gt;使用共享内存: 将全局内存中的数据加载到共享内存中，然后让线程从共享内存中读取数据。共享内存的访问速度比全局内存快得多。&lt;/li&gt;
&lt;li&gt;使用只读缓存: 对于只读数据，可以使用只读缓存来提高访问速度。&lt;/li&gt;
&lt;li&gt;数据对齐: 确保数据按照硬件要求的对齐方式存储，以避免额外的内存访问开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-线程束发散&#34;&gt;2. 线程束发散&lt;/h3&gt;
&lt;p&gt;当线程束中的线程执行不同的指令时，会导致线程束发散，降低 GPU 的利用率。解决方法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;避免条件分支: 尽量避免在 kernel 中使用条件分支，或者将条件分支的条件设置为线程束中的所有线程都相同。&lt;/li&gt;
&lt;li&gt;使用 warp shuffle 指令: warp shuffle 指令可以在线程束内的线程之间交换数据，避免线程束发散。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-同步开销&#34;&gt;3. 同步开销&lt;/h3&gt;
&lt;p&gt;在 CUDA kernel 中，线程之间的同步需要消耗时间。过多的同步操作会降低 kernel 的性能。解决方法:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernel 汇编</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E6%B1%87%E7%BC%96/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E6%B1%87%E7%BC%96/</guid>
      <description>&lt;h2 id=&#34;查看-kernel-汇编&#34;&gt;查看 kernel 汇编&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;cuobjdump -sass executable&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LD.E.64 R6, [R10]&lt;/code&gt;: 这是一个向量化加载指令，它从&lt;strong&gt;内存地址 [R10] 加载 64 位（8 字节）的数据到寄存器 R6&lt;/strong&gt;。 这意味着它一次性加载两个 32 位整数（或一个 64 位整数，或其他 64 位数据类型）。 这在处理大量数据时可以显著提高内存带宽利用率，因为减少了内存访问次数。 .64 后缀明确指定了加载 64 位数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LD.E R2, [R6]&lt;/code&gt;: 这是一个标量加载指令，它从&lt;strong&gt;内存地址 [R6] 加载 32 位（4 字节）的数据到寄存器 R2&lt;/strong&gt;。 它一次只加载一个 32 位整数（或其他 32 位数据类型）。 这比向量化加载指令效率低，因为需要更多次的内存访问来加载相同数量的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Memory Pinned</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-pinned/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-pinned/</guid>
      <description>&lt;h2 id=&#34;pinned-memory-aka-page-locked-memory&#34;&gt;Pinned Memory (AKA page-locked memory)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pinned Memory，也称为&lt;strong&gt;页锁定内存&lt;/strong&gt;，是一种特殊的内存分配方式，&lt;strong&gt;它确保内存始终驻留在物理内存中，不会被操作系统分页或交换到磁盘上&lt;/strong&gt;。这种内存分配方式对于需要&lt;strong&gt;频繁访问的内存区域&lt;/strong&gt;非常有用，因为它可以提高数据传输的速度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pageable Memory，也称为可分页内存，是由操作系统 API（如 &lt;code&gt;malloc()&lt;/code&gt; ）在主机上分配的内存。这种内存可以被操作系统分页和交换到磁盘上，以释放物理内存供其他程序使用。Pageable memory 的优点是可以更有效地利用物理内存，但在数据传输时可能会受到限制，因为数据可能需要先从磁盘加载到内存中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;pinned memory 和 pageable memory 主要关注的是 CPU 内存&lt;strong&gt;如何被操作系统管理以及是否可以被分页到磁盘&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当使用 pinned 内存时，操作系统会将内存块标记为“固定”，这意味着该内存块不会被分页或交换到磁盘上。这种固定的内存块可以被硬件设备（如 GPU）直接访问，从而实现更快的数据传输。&lt;/p&gt;
&lt;h2 id=&#34;异步实现-device-计算和数据传输时host-必须是-pinned-memory&#34;&gt;异步实现 device 计算和数据传输时，host 必须是 pinned memory.&lt;/h2&gt;
&lt;p&gt;CUDA 等 GPU 计算框架使用 DMA 来高效地将数据从主机内存传输到 Device 内存，DMA 是一种允许硬件直接访问内存的机制，无需 CPU 的干预，从而显著提高数据传输速度。然而，标准的系统内存（分页内存）可能会被操作系统分页到磁盘上。如果在 DMA 传输过程中，操作系统将主机内存页面交换到磁盘，DMA 就会失败，就是GPU直接访问不到了。&lt;/p&gt;
&lt;p&gt;Pinned memory，也称为固定内存或页面锁定内存，是一种特殊的内存区域，操作系统保证其始终驻留在物理内存中，不会被分页到磁盘。因此，使用 Pinned memory 进行异步数据传输可以确保 DMA 传输的可靠性和效率。&lt;/p&gt;
&lt;p&gt;当异步地将数据从主机复制到设备时，CUDA 运行时可以立即启动 DMA 传输，而无需等待 CPU 。在数据传输完成之前，CPU 可以继续执行其他任务，从而实现真正的异步操作。&lt;/p&gt;
&lt;p&gt;简而言之，Pinned memory 保证了&lt;strong&gt;内存的连续性和稳定性&lt;/strong&gt;，避免了异步 DMA 传输过程中可能出现的页面错误，从而确保了异步数据传输的可靠性和效率。&lt;/p&gt;
&lt;p&gt;C++ 中，直接使用 &lt;code&gt;new&lt;/code&gt; 或 &lt;code&gt;malloc&lt;/code&gt; 等标准库函数开辟内存空间时，不会自动区分 pinned 内存和 pageable 内存。 这些函数分配的是默认的可分页内存 (pageable memory)。***&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memory Shared 1</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-1/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-1/</guid>
      <description>&lt;h2 id=&#34;shared-memory&#34;&gt;Shared Memory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;片上内存，极低延迟&lt;/li&gt;
&lt;li&gt;是每个线程块 (Thread Block) 独有的；&lt;/li&gt;
&lt;li&gt;生命周期与创建它的线程块相同；当线程块执行完毕后，共享内存中的数据也会被释放。&lt;/li&gt;
&lt;li&gt;用于实现高性能的协作并行算法，例如并行归约。&lt;/li&gt;
&lt;li&gt;用于手动管理的数据缓存，减少对全局内存的访问。比如通过 Shared Mem 实现 reverse 一个数组。&lt;/li&gt;
&lt;li&gt;共享内存可以静态分配（在编译时指定大小）或动态分配（在运行时指定大小）；&lt;/li&gt;
&lt;li&gt;每个 SM 都有，且是有限的共享内存容量；&lt;/li&gt;
&lt;li&gt;注意 Bank conflict&lt;/li&gt;
&lt;li&gt;在共享内存中进行读写操作时，通常需要使用 &lt;code&gt;__syncthreads()&lt;/code&gt; 函数进行线程同步。&lt;/li&gt;
&lt;li&gt;每个线程块可用的共享内存量是有限的。可以使用 &lt;code&gt;cudaGetDeviceProperties&lt;/code&gt; 函数来查询设备的共享内存大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;分配-shared-memory&#34;&gt;分配 Shared Memory&lt;/h2&gt;
&lt;p&gt;静态分配：适用于共享内存大小在运行时保持不变的情况，在 kernel 中固定大小 &lt;code&gt;vectorAddStatic&amp;lt;&amp;lt;&amp;lt;blocksPerGrid, threadsPerBlock&amp;gt;&amp;gt;&amp;gt;()&lt;/code&gt; 。它更简单，并且编译器可以进行更好的优化。&lt;/p&gt;
&lt;p&gt;动态分配：适用于共享内存大小可能在运行时变化的情况，在启动 kernel 时 给出 &lt;code&gt;vectorAddDynamic&amp;lt;&amp;lt;&amp;lt;blocksPerGrid, threadsPerBlock, sharedMemSize&amp;gt;&amp;gt;&amp;gt;()&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;更多使用 Shared Memory 的实例：&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;bank&#34;&gt;Bank&lt;/h2&gt;
&lt;p&gt;CUDA 共享内存被划分为多个内存 Bank，&lt;strong&gt;每个 Bank 在一时钟周期内只能处理一个内存请求&lt;/strong&gt;。如果多个线程试图同时访问同一个 Bank 中的不同地址，就会发生 Bank 冲突 (Bank conflict)。这会导致内存访问串行化，降低性能。&lt;/p&gt;
&lt;p&gt;避免 Bank 冲突的策略:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;内存对齐: 确保线程访问的内存地址在不同的 Bank 中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;访问模式: 避免多个线程同时访问同一个 Bank 。 例如，如果共享内存是一个二维数组，则应避免所有线程同时访问同一列（或同一行，取决于内存布局）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memory Shared 2</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-2/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-2/</guid>
      <description>&lt;h2 id=&#34;为什么会冲突&#34;&gt;为什么会冲突&lt;/h2&gt;
&lt;p&gt;假设:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TILE_DIM = 32&lt;/li&gt;
&lt;li&gt;Shared Memory 有 32 个 Banks&lt;/li&gt;
&lt;li&gt;每个 Bank 宽度为 4 字节 (float)&lt;/li&gt;
&lt;li&gt;线程块维度为 (32, 32)，即每个线程块有 1024 个线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们声明一个共享内存数组：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__shared__ &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; tile[TILE_DIM][TILE_DIM]; &lt;span style=&#34;color:#75715e&#34;&gt;// __shared__ float tile[32][32];
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在，&lt;/p&gt;
&lt;h3 id=&#34;如果线程配置是-dim3-blockdim1-32&#34;&gt;如果线程配置是 &lt;code&gt;dim3 blockDim(1, 32)&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;这些线程的 &lt;code&gt;threadIdx.x&lt;/code&gt; 都为 0，而 &lt;code&gt;threadIdx.y&lt;/code&gt; 从 0 到 31，
通过 &lt;code&gt;int index = threadIdx.y + blockIdx.x * blockDim.y = threadIdx.y;&lt;/code&gt; 得到线程id和其对应的tile元素索引:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// tile[threadIdx.x][threadsIdx.y]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;Thread &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; tile[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Thread &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; tile[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Thread &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; tile[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Thread &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:&lt;/span&gt; tile[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于 tile 数组是按行存储的，并且每个 float 占用 4 bytes，根据行存储公式： &lt;code&gt;Address = base_address + (row * num_cols + col) * element_size&lt;/code&gt; 得到这些线程访问的地址如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Memory Shared 3</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-3/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:52 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/memory-shared-3/</guid>
      <description>&lt;h2 id=&#34;读代码&#34;&gt;读代码&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// 有 Bank Conflict 的 Kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kernelWithBankConflict&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;input, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;output) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __shared__ &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; tile[TILE_DIM][TILE_DIM];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.y;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tile[threadIdx.x][threadIdx.y] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; input[x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; TILE_DIM &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __syncthreads();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output[x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; TILE_DIM &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tile[threadIdx.x][threadIdx.y];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// 避免 Bank Conflict 的 Kernel
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;kernelWithoutBankConflict&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;input, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;output) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __shared__ &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; tile[TILE_DIM][TILE_DIM &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; threadIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; blockIdx.y &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.y;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tile[threadIdx.x][threadIdx.y] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; input[x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; TILE_DIM &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __syncthreads();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output[x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; TILE_DIM &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; y] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tile[threadIdx.x][threadIdx.y];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 blockDim(TILE_DIM, TILE_DIM);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dim3 gridDim(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 执行 Kernel (有 Bank Conflict)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    kernelWithBankConflict&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;gridDim, blockDim&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_input, d_output);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 执行 Kernel (避免 Bank Conflict)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    kernelWithoutBankConflict&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;gridDim, blockDim&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_input, d_output);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;input[x * TILE_DIM + y];&lt;/code&gt; : x，y 表示每个线程自己的全局索引，&lt;code&gt;x * TILE_DIM&lt;/code&gt; 表示目标位置所在的行，&lt;code&gt;+ y&lt;/code&gt; 表示目标位置所在的列，所以行偏移后，列偏移，就得到了目标位置index。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernel 向量化</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:51 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96/</guid>
      <description>&lt;h2 id=&#34;向量化数据类型--cuda-内置类型&#34;&gt;向量化数据类型  [cuda 内置类型]&lt;/h2&gt;
&lt;p&gt;CUDA 提供的向量类型，用于表示多个相同类型的值的集合。 它们允许你一次性操作多个数据元素，从而提高性能，特别是对于并行计算。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;int2&lt;/code&gt;: 包含两个 int 类型的值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;int4&lt;/code&gt;: 包含四个 int 类型的值。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;float2&lt;/code&gt;: 包含两个 float 类型的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些类型并非标准 C++ 的一部分，而是 CUDA 为了优化 GPU 计算而定义的。它们允许编译器生成更有效的指令，例如向量化加载和存储指令 (&lt;code&gt;LD.E.64&lt;/code&gt;, &lt;code&gt;ST.E.64&lt;/code&gt;, &lt;code&gt;LD.E.128&lt;/code&gt;, &lt;code&gt;ST.E.128&lt;/code&gt;)，从而提高内存带宽利用率并减少指令数量。&lt;/p&gt;
&lt;h2 id=&#34;向量化-kernel&#34;&gt;向量化 kernel&lt;/h2&gt;
&lt;p&gt;更充分利用带宽，减少指令数。向量化的实现需要数据对齐。&lt;/p&gt;
&lt;p&gt;本质上，它将两个 int 元素的加载和存储操作合并为一个操作，从而减少了指令的数量并提高了带宽利用率。&lt;/p&gt;
&lt;p&gt;非向量化：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device_copy_scalar_kernel&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d_in, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d_out, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) { 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; idx; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; N; i &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gridDim.x){ 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    d_out[i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d_in[i]; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  } 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;} 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;device_copy_scalar&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d_in, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d_out, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; N) { 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; threads &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; blocks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; min((N &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threads&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; threads, MAX_BLOCKS);  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  device_copy_scalar_kernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;blocks, threads&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_in, d_out, N); 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用 &lt;code&gt;int2&lt;/code&gt;：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernel 向量化 SIMD</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simd/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:51 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simd/</guid>
      <description>&lt;p&gt;向量化是利用 SIMD 指令的&lt;strong&gt;软件优化技术&lt;/strong&gt;，而 SIMD 是提供并行计算能力的硬件条件。&lt;/p&gt;
&lt;h2 id=&#34;什么是-simd-指令集&#34;&gt;什么是 SIMD 指令集&lt;/h2&gt;
&lt;p&gt;SIMD 指令集是一种在单个时钟周期内对多个数据执行相同操作的指令集。通过使用 SIMD 指令，CPU 可以并行处理多个数据，从而提高程序的性能。&lt;/p&gt;
&lt;p&gt;SIMD 指令的优势&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;提高性能：通过并行处理多个数据，SIMD 指令可以显著提高程序的性能。&lt;/li&gt;
&lt;li&gt;降低功耗：通过减少指令数量，SIMD 指令可以降低 CPU 的功耗。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例：比如 VNNI 指令是 SIMD 的，通过并行处理多个低精度数据（如 INT8）来提高计算效率。VNNI 指令集中的一个额具体指令 &lt;code&gt;VPDPBUSD&lt;/code&gt;（AVX-512 VNNI 指令）设计为每次计算 4 个 INT8 元素的点积，并将结果累加到 INT32 输出。对于 AVX-512 寄存器，存储 64 个 INT8 元素, 4 个 INT8 为一个向量，两个 input 点积得到 1 个输出，所以 &lt;code&gt;VPDPBUSD&lt;/code&gt; 得到 16 （64/4）个元素存在 INT32 输出。这个过程中，向量中的 4 个 int8 是同时计算的。体现了SIMD。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;immintrin.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;cstdint&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;dot_product_vnni&lt;/span&gt;() {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 输入向量：每个包含 64 个 INT8 元素（512 位寄存器）
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int8_t&lt;/span&gt; vec1[&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// 子向量 1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// 子向量 2
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 示例
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    };
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int8_t&lt;/span&gt; vec2[&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// 子向量 1
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;// 子向量 2
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 示例
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    };
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int32_t&lt;/span&gt; result[&lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;};  &lt;span style=&#34;color:#75715e&#34;&gt;// 存储 16 个点积结果 (INT32)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 加载到 AVX-512 寄存器 ‘u’ 表示
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    __m512i v1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _mm512_loadu_si512(vec1);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __m512i v2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _mm512_loadu_si512(vec2);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    __m512i res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _mm512_setzero_si512();  &lt;span style=&#34;color:#75715e&#34;&gt;// 初始化结果为 0
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 使用 VPDPBUSD 计算点积
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; _mm512_dpbusd_epi32(res, v1, v2);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 存储结果
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    _mm512_storeu_si512(result, res);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 输出前两个子向量的点积
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;cout &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Dot product 1: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; result[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;endl;  &lt;span style=&#34;color:#75715e&#34;&gt;// 1*2 + 2*3 + 3*4 + 4*5 = 2 + 6 + 12 + 20 = 40
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;cout &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Dot product 2: &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; result[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;endl;  &lt;span style=&#34;color:#75715e&#34;&gt;// 5*1 + 6*2 + 7*1 + 8*2 = 5 + 12 + 7 + 16 = 40
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;simd-指令的工作原理&#34;&gt;SIMD 指令的工作原理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;向量寄存器：SIMD 指令使用&lt;strong&gt;向量寄存器&lt;/strong&gt;来存储多个数据。例如，一个 128 位的向量寄存器可以存储 4 个 32 位的整数或浮点数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kernel 向量化 SIMT</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simt/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:51 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simt/</guid>
      <description>&lt;p&gt;NVIDIA GPU 架构是 SIMT，而编译器又会利用 SIMD 指令来优化 int4 类型的操作，这看起来似乎有些矛盾，但实际上它们并不冲突。&lt;/p&gt;
&lt;h2 id=&#34;simt-和-simd-的关系&#34;&gt;SIMT 和 SIMD 的关系&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SIMT 是&lt;strong&gt;架构层面&lt;/strong&gt;：SIMT 描述的是 NVIDIA GPU 的整体架构和执行模型。它指的是多个线程（以 warp 为单位）执行相同的指令，但处理不同的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SIMD 是&lt;strong&gt;指令层面&lt;/strong&gt;：SIMD 是一种指令集，它允许一条指令同时操作多个数据。编译器可以使用 SIMD 指令来优化代码，提高程序的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以 NV GPU 是 SIMT 架构的：决定了它的基本执行方式：多个线程（warp）执行相同的指令。同时又有 SIMD 优化的：在 SIMT 架构下，编译器仍然可以利用 SIMD 指令来优化代码。例如，对于 int4 类型的操作，编译器可以使用 SIMD 指令一次性加载、存储和计算 4 个整数。&lt;/p&gt;
&lt;p&gt;SIMT 是 NVIDIA GPU 的专有模型，依赖 SM 和 warp 调度。Multiple Thread 体现在Warp内线程异步执行相同指令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; a, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; b, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; c, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x;  &lt;span style=&#34;color:#75715e&#34;&gt;// 每个线程独立索引
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (idx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n) c[idx] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a[idx] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b[idx];  &lt;span style=&#34;color:#75715e&#34;&gt;// SIMT：warp 内线程并行执行加法
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Kernel-写kernel</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:51 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/</guid>
      <description>&lt;h2 id=&#34;线程配置配置-最佳实战&#34;&gt;线程配置配置 最佳实战&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当前的 GPU 上，一个 block 可能包含多达 1024 个线程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果每个 block 的 thread 数量为 &lt;code&gt;[64/128/256/512]&lt;/code&gt;，那么 CUDA 性能会更好。因为 Warp 大小是 32&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;激活线程数是 &lt;code&gt;SM * 2&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;硬件信息：SM 数， &lt;code&gt;GetComputeCapability&lt;/code&gt;， &lt;code&gt;GetMaxThreadsPerBlock&lt;/code&gt;, &lt;code&gt;GetMaxPhysicalThreadCount&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要激活的线程总数 active threads。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;通常是把经验配置作为配置的起点，作为 baseline&lt;/strong&gt;，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。&lt;/p&gt;
&lt;p&gt;Again，在 Profiling 时，收集关键性能指标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。&lt;/li&gt;
&lt;li&gt;并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。&lt;/li&gt;
&lt;li&gt;吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。&lt;/li&gt;
&lt;li&gt;带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。&lt;/li&gt;
&lt;li&gt;功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。&lt;/li&gt;
&lt;li&gt;延迟 (Latency): kernel 的执行时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述可以通过 &lt;strong&gt;Nsight Compute&lt;/strong&gt; 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cublas Mma</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/cublas-mma/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:50 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/cublas-mma/</guid>
      <description>&lt;p&gt;cuBLAS 也会利用 tensor core，其性能比简单的手工写的 wmma 更优。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://0mean1sigma.com/tgemm/&#34;&gt;https://0mean1sigma.com/tgemm/&lt;/a&gt;  这篇文章中的 benchmark 展示了不同方式的性能。可以把最高性能的作为标杆，自己动手优化，这里的性能指标是吞吐，还可以有其他指标 ***&lt;/p&gt;
&lt;h2 id=&#34;什么是-leading-demension&#34;&gt;什么是 leading demension&lt;/h2&gt;
&lt;p&gt;内存中连续存储元素的个数。&lt;/p&gt;
&lt;p&gt;给定一个形状为 MxN 的矩阵 ，如果它按 Row-major 存储，其 leading dimension 是 N，如果它按 Col-major 存储，其 leading dimention 是 M。&lt;/p&gt;
&lt;h2 id=&#34;什么是-row-major-和-col-major&#34;&gt;什么是 row-major 和 col-major&lt;/h2&gt;
&lt;p&gt;row-major 指的是按行存储，即每一行中元素是连续存储的。
col-major 指的是按列存储，即每一列中元素是连续存储的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;A = 1 2 3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    4 5 6
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 row-major order 中，内存中的存储顺序是：1 2 3 4 5 6, leading dimension 是 3.
在 col-major order 中，内存中的存储顺序是：1 4 2 5 3 6, leading dimension 是 2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Doc</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:50 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions&#34;&gt;https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;阅读学习策略：&lt;/p&gt;
&lt;p&gt;Doc 中内容太多，短时间内读不完，完全读完性价比太低。所以：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;快速浏览，快速了解每一章大概内容。（TODO）&lt;/li&gt;
&lt;li&gt;根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;cuda-最新-doc&#34;&gt;CUDA 最新 doc&lt;/h2&gt;
&lt;h3 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h3&gt;
&lt;p&gt;核心包含三个关键抽象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程组层次结构&lt;/li&gt;
&lt;li&gt;共享内存&lt;/li&gt;
&lt;li&gt;屏障&amp;amp;同步&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-programming-model&#34;&gt;2. Programming Model&lt;/h3&gt;
&lt;p&gt;内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。&lt;/p&gt;
&lt;p&gt;程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（&lt;code&gt;x + y*Dx&lt;/code&gt;）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（&lt;code&gt;x + y*Dx + z Dx*Dy&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;每个块中线程的数量是有限的，因为一个块中的所有线程都预期&lt;strong&gt;驻留&lt;/strong&gt;在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在&lt;strong&gt;当前的 GPU 上，一个线程块可能包含多达 1024 个线程&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。&lt;/p&gt;
&lt;p&gt;线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。&lt;code&gt;__syncthreads()&lt;/code&gt;, 此外，&lt;code&gt;Cooperative Groups API&lt;/code&gt; 还提供了一套丰富的线程同步原语。&lt;/p&gt;
&lt;p&gt;在一个 Block 内，为了高效协作，&lt;strong&gt;Shared Memory&lt;/strong&gt; 位于每个处理器核心附近（类似于 L1 缓存），并且 &lt;code&gt;__syncthreads()&lt;/code&gt; 相对是轻量级的。&lt;/p&gt;
&lt;h4 id=&#34;thread-block-clusterstbc&#34;&gt;Thread Block Clusters（TBC）：&lt;/h4&gt;
&lt;p&gt;计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为&lt;strong&gt;线程块集群&lt;/strong&gt;，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 &lt;code&gt;cudaOccupancyMaxPotentialClusterSize&lt;/code&gt; API 进行查询。&lt;code&gt;gridDim&lt;/code&gt; 变量仍然表示线程块的数量，以保持兼容性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Hopper</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-hopper/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:50 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-hopper/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html&#34;&gt;https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NVIDIA Hopper GPU 架构保留了并扩展了之前 NVIDIA GPU 架构（如 NVIDIA Ampere GPU 架构和 NVIDIA Turing）提供的相同的 CUDA 编程模型，遵循这些架构最佳实践的应程序通常在 NVIDIA H100 GPU 上看到速度提升，无需任何代码更改。&lt;/p&gt;
&lt;h2 id=&#34;高优先级建议如下&#34;&gt;高优先级建议如下&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;寻找并行化顺序代码的方法。&lt;/li&gt;
&lt;li&gt;最小化主机与设备之间的数据传输。&lt;/li&gt;
&lt;li&gt;调整内核启动配置以最大化设备利用率。&lt;/li&gt;
&lt;li&gt;确保全局内存访问是 coalesced 的。&lt;/li&gt;
&lt;li&gt;尽可能减少对全局内存的冗余访问。&lt;/li&gt;
&lt;li&gt;尽量量避免同一warp中线程执行路径出现长时间的分歧(sequences of diverged execution)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TODO：这个文档中还有更多的关于 Hopper 的参数。&lt;/p&gt;
&lt;h2 id=&#34;nvidia-hopper-流式多处理器sm在-turing-和-nvidia-ampere-gpu-架构的基础上提供了以下改进&#34;&gt;NVIDIA Hopper 流式多处理器（SM）在 Turing 和 NVIDIA Ampere GPU 架构的基础上提供了以下改进。&lt;/h2&gt;
&lt;p&gt;每个 SM 的最大并发 warp 数量与 NVIDIA Ampere GPU 架构相同（即 &lt;strong&gt;64&lt;/strong&gt;），每个 warp 需要占用一定的寄存器和共享内存等资源。SM 的资源是有限的，因此能够同时支持的 warp 数量也是有限的。如果一个 SM 上只有少数几个 warp，那么 SM 的资源可能无法充分利用，导致性能下降。资源占用率要高，并行程度也要高。&lt;/p&gt;
&lt;p&gt;影响 warp 占用的其他因素包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;寄存器文件大小为每个 SM 64K 个 32 位寄存器。（register个数 64x1024=&lt;strong&gt;65536&lt;/strong&gt;个，每个register大小 32bit/8=4Byte, register总大小是 256 KB）&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Triton</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-triton/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:50 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-triton/</guid>
      <description>&lt;h1 id=&#34;tritonnvidiagpu-的-3-个pass&#34;&gt;TritonNvidiaGPU 的 3 个pass&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;triton-nvidia-gpu-plan-cta&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;triton-nvidia-gpu-fence-insertion&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;triton-nvidia-tma-lowering&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;triton-nvidia-gpu-plan-cta&#34;&gt;triton-nvidia-gpu-plan-cta&lt;/h2&gt;
&lt;p&gt;这个 pass 为 &lt;code&gt;DotOp&lt;/code&gt;、&lt;code&gt;ReudceOp&lt;/code&gt;、&lt;code&gt;StoreLikeOps&lt;/code&gt; 计算并应用优化过的 CTA。&lt;/p&gt;
&lt;p&gt;以 &lt;code&gt;DotOp&lt;/code&gt; 为例，逻辑是：遍历 funcOp 中所有的的 DotOp，获取类型和操作数，计算 Block 分块大小，应用这个分块，并且更新输入输出的 Layout。源码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;bool&lt;/span&gt; CTAPlanner&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;processDot(triton&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;FuncOp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;funcOp) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// TODO: This is a naive implementation and should be refactored
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 这个lambda函数根据 MNK和CTA个数 来确定分块大小 splitM，splitN
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; getCTATiling &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [](&lt;span style=&#34;color:#66d9ef&#34;&gt;int64_t&lt;/span&gt; M, &lt;span style=&#34;color:#66d9ef&#34;&gt;int64_t&lt;/span&gt; N, &lt;span style=&#34;color:#66d9ef&#34;&gt;int64_t&lt;/span&gt; K,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                         &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; numCTAs) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;pair&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// prefer a larger chunk size, at most 128; first assign splitM.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; chunk_m &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; isLegal &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [](&lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; chunk) { &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; chunk &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;; };
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; splitM, splitN;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (; isLegal(chunk_m); chunk_m &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      splitM &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;clamp&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(M &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; chunk_m, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, numCTAs);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      splitN &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; numCTAs &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; splitM;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (isLegal(N &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; splitN)) &lt;span style=&#34;color:#75715e&#34;&gt;// chunk_n;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;break&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; {splitM, splitN};
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  };
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// 使用Walk 遍历funcOp 中的所有DotOp
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  funcOp.walk([&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;](triton&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOp dot) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    MLIRContext &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;ctx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dot.getContext();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 获取类型
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; aTy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;RankedTensorType&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(dot.getA().getType());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; bTy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;RankedTensorType&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(dot.getB().getType());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; dTy &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;RankedTensorType&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(dot.getD().getType());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    assert(isa&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(aTy.getEncoding()) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           isa&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(bTy.getEncoding()) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           isa&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;BlockedEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(dTy.getEncoding()) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PlanCTAPass should follow immediately after CoalescePass&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 获取编码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; aLayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(aTy.getEncoding());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; bLayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(bTy.getEncoding());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; dLayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cast&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;BlockedEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(dTy.getEncoding());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 获取shape
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; M &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dTy.getShape()[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; N &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dTy.getShape()[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; K &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; aTy.getShape()[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;unsigned&lt;/span&gt; splitM, splitN;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 根据lambda函数计算 splitM，splitN
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;tie(splitM, splitN) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; getCTATiling(M, N, K, ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;getNumCTAs(dLayout));
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 设置分块
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    setTiling({splitM, splitN, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 创建新的Layout属性
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; newCTALayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;CTALayoutAttr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;get(ctx, {splitM, splitN},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                {splitM, splitN}, {&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; newDLayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;BlockedEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;get(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ctx, dTy.getShape(), dLayout.getSizePerThread(), dLayout.getOrder(),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;getNumWarpsPerCTA(dLayout), &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, newCTALayout);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; newALayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;get(ctx, aLayout.getOpIdx(),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                       newDLayout, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; newBLayout &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ttg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;DotOperandEncodingAttr&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;get(ctx, bLayout.getOpIdx(),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                                       newDLayout, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 更新操作数和结果的 Layout
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    insertCasts(dot.getOperation(), {newALayout, newBLayout, newDLayout},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                {newDLayout});
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  });
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; true;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 insertCasts 表达如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>PTX Intrinsics</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/ptx-intrinsics/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:49 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/ptx-intrinsics/</guid>
      <description>&lt;h2 id=&#34;intrinsic&#34;&gt;Intrinsic&lt;/h2&gt;
&lt;p&gt;NVIDIA GPU intrinsics 提供了一种在 CUDA 或其他支持的编程模型中直接访问底层 GPU 硬件功能的方式.&lt;/p&gt;
&lt;p&gt;Intrinsics 是&lt;strong&gt;更高级的抽象&lt;/strong&gt;，允许开发者在 C/C++ 代码中使用类似函数调用的方式来访问 GPU 指令.&lt;/p&gt;
&lt;h2 id=&#34;ptx&#34;&gt;PTX&lt;/h2&gt;
&lt;p&gt;PTX (Parallel Thread Execution) 是一种低级并行线程执行的虚拟指令集架构，作为 CUDA 程序的中间表示。CUDA 编译器将 CUDA 代码编译成 PTX 代码，然后 PTX 代码再由驱动程序即时编译 (JIT) 成目标 GPU 的机器码。&lt;/p&gt;
&lt;p&gt;PTX 是一种汇编级别的指令集，更接近底层硬件。所以手写 PTX 是复杂，&lt;/p&gt;
&lt;p&gt;DeepSeek 项目展示了如何使用 PTX 绕过 CUDA 的限制，从而实现更高效的 GPU 编程。这种方法不仅提升了性能，还展示了在有限算力资源下如何进行创新和突破.&lt;/p&gt;
&lt;p&gt;实际应用中，需要根据具体的&lt;strong&gt;算法和硬件特性&lt;/strong&gt;进行更深入的优化。&lt;/p&gt;
&lt;p&gt;直接编写 PTX 代码通常只在对&lt;strong&gt;性能有极致要求&lt;/strong&gt;的场景下使用。在大多数情况下，使用高级CUDA C/C++代码，并结合NVIDIA提供的性能分析工具（如Nsight Systems和Nsight Compute）进行优化，可以获得更好的开发效率和可维护性。&lt;/p&gt;
&lt;h2 id=&#34;关系&#34;&gt;关系&lt;/h2&gt;
&lt;p&gt;当在 CUDA 代码中使用 intrinsics 时，CUDA 编译器会将这些 intrinsics 转换为相应的 PTX 指令。如，一个 &lt;code&gt;warp shuffle&lt;/code&gt; intrinsic 可能会被编译成 &lt;code&gt;shfl&lt;/code&gt; PTX 指令。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SM</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/sm/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:49 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/sm/</guid>
      <description>&lt;h2 id=&#34;sm&#34;&gt;SM&lt;/h2&gt;
&lt;p&gt;Streaming Multiprocessor（SM）。SM 是 GPU 上的一个&lt;strong&gt;硬件单元&lt;/strong&gt;，负责执行 CUDA 核函数（kernels）中的&lt;strong&gt;线程块&lt;/strong&gt;（blocks of threads）。每个 SM 能够同时处理多个线程块，这些线程块中的线程并行执行相同的指令，这种执行模式被称为 SIMD（单指令多数据流）。&lt;/p&gt;
&lt;p&gt;SM 是 GPU 上的一个&lt;strong&gt;硬件单元&lt;/strong&gt;，程序被组织成网格（grid），每个网格由多个线程块（block）组成，而每个线程块又由多个线程（thread）组成。这些线程以 warp为单位被分配到 SM 上执行。&lt;/p&gt;
&lt;h2 id=&#34;sm--sp&#34;&gt;SM &amp;amp; SP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SM 是核心计算单元，能够并行执行多个线程，它包含多个 SP、指令单元、共享内存、L1缓存、寄存器和其他资源。&lt;/li&gt;
&lt;li&gt;SM 使用 Warp 调度器来管理线程的执行。&lt;/li&gt;
&lt;li&gt;SP（也称为 CUDA 核心）: SP 是 SM 中最基本的处理单元，负责执行单个指令。&lt;/li&gt;
&lt;li&gt;协作关系： SM 负责调度和管理线程的执行，而 SP 负责实际的计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sm-中-register-资源分配&#34;&gt;SM 中 register 资源分配&lt;/h2&gt;
&lt;p&gt;硬件条件：一个 SM 中有 768 个 threads，含有 8000 个registers。假设我配置 block 为256个 threads。如何最大化资源占用率？&lt;/p&gt;
&lt;p&gt;当每个 thread 占用 10 个 registers，那么一个 SM 共占用 （768*10=）7680 个register，没有超过 registers 总个数 8000。SM 驻扎 （768/256=）3 个block，(768/32=) 24 个 warp。这是最理想的情况，最大化资源占用率。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mlir Basis</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/compiler/mlir-basis/</link>
      <pubDate>Sun, 31 Aug 2025 12:15:30 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/compiler/mlir-basis/</guid>
      <description>&lt;p&gt;:sweat_drops: :sweat_drops: :sweat_drops: :sweat_drops: :sweat_drops:&lt;/p&gt;
&lt;h1 id=&#34;learn--reflect&#34;&gt;Learn &amp;amp; reflect&lt;/h1&gt;
&lt;p&gt;部分来自：https://github.com/KEKE046/mlir-tutorial&lt;/p&gt;
&lt;h2 id=&#34;1-多层dialect-理解到了什么&#34;&gt;1. 多层Dialect 理解到了什么？&lt;/h2&gt;
&lt;p&gt;MLIR 编译从高层 的IR到底层的IR，每个阶段都是多个Dialect的混合。
每次Lowering 都往往针对一个dialect 进行。&lt;/p&gt;
&lt;p&gt;Dialect是独立的。例如，在做循环展开等优化的时候，我不需要关心加法和减法可以合并；而在做算数表达式优化的时候，也不需要关心当前在哪个函数里边。&lt;/p&gt;
&lt;p&gt;MLIR 可以从各个层次优化 IR：例如：&lt;/p&gt;
&lt;p&gt;在 affine 层面，可以根据循环大小做展开，向量化；&lt;/p&gt;
&lt;p&gt;在 scf 层面，可以发现循环不变量；&lt;/p&gt;
&lt;p&gt;在 arith 层面，可以用算数恒等式优化代码。&lt;/p&gt;
&lt;p&gt;比如在 linalg 层，我们很容易发现矩阵被转置了两次，但一旦 lower 到 scf，所有转置操作都变成循环，优化就很难进行了。所以从high level IR 到 low level IR 要及时做优化。&lt;/p&gt;
&lt;p&gt;MLIR用处是：&lt;/p&gt;
&lt;p&gt;复用已有的 Dialect；扩展已有的 Dialect；复用已有的 Pass。常见 Pass 直接复用（CSE DCE）&lt;/p&gt;
&lt;p&gt;一般讲 high level 的 IR 是与硬件无关的，low level 的 IR是与硬件有关的。&lt;/p&gt;
&lt;h2 id=&#34;2-mlir的结构&#34;&gt;2. MLIR的结构&lt;/h2&gt;
&lt;p&gt;MLIR 结构是树形的，Region 包含Block，Block 包含 Operation，Operation 包含其他的 Region，&amp;hellip;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pass Collection</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/compiler/pass-collection/</link>
      <pubDate>Sun, 31 Aug 2025 12:15:30 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/compiler/pass-collection/</guid>
      <description></description>
    </item>
    <item>
      <title>Compiler Basis</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/compiler/compiler-basis/</link>
      <pubDate>Sun, 31 Aug 2025 12:15:29 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/compiler/compiler-basis/</guid>
      <description>&lt;p&gt;:brain: :brain: :brain: :brain: :brain:&lt;/p&gt;
&lt;h1 id=&#34;ai-编译器原理汇总&#34;&gt;AI 编译器原理汇总&lt;/h1&gt;
&lt;p&gt;很大程度上讲 AI compiler 其实就是把手动优化的经验和成果 拿过来变成自动化的过程。&lt;/p&gt;
&lt;p&gt;block_ptr 的提出是想 lowering 的时候，丢掉了这个计算的类型，即它是 FlexAttention 还是 GEMM，需要这个信息来决定如何优化。言外之意，不同的程序有各自最优的优化方式。 所以单单问我的一个 dot 如何优化，这是不合理的。dot 如何优化取决于 dot 所在的程序时什么样的。什么样的程序有什么样的优化方式。&lt;/p&gt;
&lt;p&gt;再扩展一下就是说，要做优化，你需要了解你的优化对象, 以及对象所执行的平台。&lt;/p&gt;
&lt;h2 id=&#34;pass-的执行顺序-如何决定先做什么后做什么&#34;&gt;Pass 的执行顺序 如何决定先做什么后做什么？&lt;/h2&gt;
&lt;p&gt;某些 Pass 可能依赖于其他 Pass 的结果；某些 Pass 可能会为后续的 Pass 创建更多的优化机会；编译器开发者通常会根据经验和启发式规则来安排 Pass 的顺序。这可能涉及到大量的实验和性能测试，以找到最佳的顺序。&lt;/p&gt;
&lt;h2 id=&#34;函数内联&#34;&gt;函数内联&lt;/h2&gt;
&lt;p&gt;函数内联（Inlining）是一种编译器优化技术，它将函数调用替换为函数体本身的内容。这样做的好处是可以消除函数调用的开销，并且在某些情况下，允许编译器进行更进一步的优化，因为它可以看到函数调用的上下文。&lt;/p&gt;
&lt;h2 id=&#34;intra-procedural&#34;&gt;Intra-procedural&lt;/h2&gt;
&lt;p&gt;（函数内部的）指的是在单个函数或过程的范围内进行的分析或优化，而不跨越函数边界。属于编译器设计和程序分析。&lt;/p&gt;
&lt;h2 id=&#34;inter-procedural&#34;&gt;Inter-procedural&lt;/h2&gt;
&lt;p&gt;（函数间的）分析或优化会考虑多个函数之间的相互作用。属于编译器设计和程序分析。&lt;/p&gt;
&lt;h2 id=&#34;transitive-lowering&#34;&gt;transitive lowering&lt;/h2&gt;
&lt;p&gt;是指将操作从一个高级别方言&lt;strong&gt;逐步降低&lt;/strong&gt;到一个低级别方言的过程，而不是直接从高级别方言生成目标方言（如LLVM方言）的操作。这种逐步降低的方法允许开发者将复杂的降低过程分解成一系列更简单、更可管理的步骤。&amp;ldquo;transitive lowering&amp;rdquo; 的关键思想是，你可以将一个操作先降低到一个中间方言，然后再从这个中间方言降低到最终的目标方言。这样做的好处是&lt;strong&gt;每个降低步骤可以专注于处理一小部分转换逻辑&lt;/strong&gt;，这使得整个降低过程更加模块化和可维护。它是 mlir 中的编程模型。&lt;/p&gt;
&lt;h2 id=&#34;为什么-mlir-的-ssa-对于生成正确和高效的代码至关重要&#34;&gt;为什么 MLIR 的 SSA 对于生成正确和高效的代码至关重要&lt;/h2&gt;
&lt;p&gt;在编译器设计中，SSA（Static Single Assignment）形式是一种中间表示（IR），其中每个变量只被赋值一次，并且每个变量都是局部定义的。这种形式有几个关键优势，使其在 MLIR 中特别重要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简化数据流分析：在 SSA 形式中，每个变量的定义点只有一个， 这使得编译器能够更容易地进行数据流分析，例如确定变量的生命周期、寻找变量的使用点、进行死代码消除等。&lt;/li&gt;
&lt;li&gt;便于优化： SSA 形式简化了许多优化技术的实现，如常量传播、公共子表达式消除、循环不变代码外提等。由于每个变量只有一个定义点，优化算法可以更直接地推断出变量的值和它们之间的关系。&lt;/li&gt;
&lt;li&gt;消除别名问题：在非 SSA 形式中，由于变量可以在多个地方被赋值，编译器必须处理复杂的别名分析问题，以确定不同的变量名是否引用相同的内存位置。SSA 通过确保每个变量只被赋值一次，减少了这种复杂性。&lt;/li&gt;
&lt;li&gt;提高代码生成质量： SSA 形式有助于生成更高效的机器代码，因为它提供了更清晰的信息来&lt;strong&gt;指导寄存器分配&lt;/strong&gt;【见：编译器是如何根据代码-进行-寄存器分配的】和&lt;strong&gt;指令调度&lt;/strong&gt;等底层代码生成阶段。【编译器通过分析代码的控制流和数据流，构建依赖图，然后使用各种算法在满足依赖关系和资源约束的条件下，重新排序指令，以最大化指令级并行性，最终生成更高效的目标代码。 】&lt;/li&gt;
&lt;li&gt;便于并行化： SSA 形式明确了变量的定义和使用，这有助于识别可以并行执行的操作，从而为自动并行化提供了基础。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;编译器是如何根据代码进行寄存器分配的-&#34;&gt;编译器是如何根据代码进行寄存器分配的 ？&lt;/h2&gt;
&lt;p&gt;编译器进行寄存器分配是一个复杂的过程，目标是将程序中的变量尽可能地存储在CPU寄存器中，以提高程序执行速度。因为寄存器的访问速度远快于内存。 这通常涉及多个步骤和不同的算法，具体方法取决于编译器的设计和优化级别。 以下是一些关键步骤和常用的算法：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cost Model</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/compiler/cost_model/</link>
      <pubDate>Sun, 31 Aug 2025 12:15:29 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/compiler/cost_model/</guid>
      <description>&lt;h1 id=&#34;计算各个角度的cost&#34;&gt;计算各个角度的cost&lt;/h1&gt;
&lt;p&gt;thread utilization 【done】
computation intensity
cache locality 【done】
memory requirements
computation unit efficiency
padding/pack cost 【done】
workload balance 【done】
communication
previous matmul&lt;/p&gt;
&lt;h2 id=&#34;vector-register&#34;&gt;vector register&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// calculate the cost of the hardware efficiency(whether the vector register is
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// fully utilized)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;vectorRegEfficiencyCost&lt;/span&gt;(linalg&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;LinalgOp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;linalgOp,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               ArrayRef&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;uint32_t&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; shape,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#66d9ef&#34;&gt;const&lt;/span&gt; MatmulConfig &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;config,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               CPUTargetDescriptionAnalysis &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;sysDesc) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  size_t dtypeSize &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; DataLayout().getTypeSizeInBits(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      ShapeAdaptor(linalgOp.getDpsInputs()[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;].getType()).getElementType());
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  size_t maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sysDesc.getMaxVectorWidth() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; dtypeSize;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// TODO: take matrix register like amx into account
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;double&lt;/span&gt; cost &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; config.innerMostMBlock &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; maxVectorWidth) &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; config.innerMostMBlock &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                (maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; config.innerMostKBlock &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; maxVectorWidth) &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; config.innerMostKBlock &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                (maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; config.innerMostNBlock &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt; maxVectorWidth) &lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                    maxVectorWidth &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; config.innerMostNBlock;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cost;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;这个计算cost的原理是什么？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;计算向量寄存器的利用效率。向量寄存器是CPU中用于存储多个数据元素以供SIMD指令并行处理的寄存器。理想情况下，为了最大化性能，你希望在每个SIMD指令中完全填满向量寄存器，没有浪费的空间。这个函数通过计算在矩阵乘法的&lt;strong&gt;最内层循环&lt;/strong&gt;中，向量寄存器未被完全利用的程度来估算代价。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2.2.LlamaIndex中使用Agents</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/</link>
      <pubDate>Sun, 31 Aug 2025 12:14:13 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/</guid>
      <description>&lt;h2 id=&#34;llamaindex-支持的-agents&#34;&gt;LlamaIndex 支持的 Agents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Advanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;初始化-agents&#34;&gt;初始化 Agents&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用 &lt;code&gt;AgentWorkflow&lt;/code&gt; 初始化一个 Agent。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 登陆使用serverless API&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; huggingface_hub &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; login
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;login()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; llama_index.llms.huggingface_api &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HuggingFaceInferenceAPI
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; llama_index.core.agent.workflow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AgentWorkflow, ToolCallResult, AgentStream
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;(a: int, b: int) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; int:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Add two numbers&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;subtract&lt;/span&gt;(a: int, b: int) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; int:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Subtract two numbers&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; b
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;multiply&lt;/span&gt;(a: int, b: int) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; int:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Multiply two numbers&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; b
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;divide&lt;/span&gt;(a: int, b: int) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; int:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Divide two numbers&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; a &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; b
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;llm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HuggingFaceInferenceAPI(model_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Qwen/Qwen2.5-Coder-32B-Instruct&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AgentWorkflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_tools_or_functions(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools_or_functions&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[subtract, multiply, divide, add],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    llm&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;llm,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    system_prompt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后就可以执行推理了：&lt;/p&gt;</description>
    </item>
    <item>
      <title>我的</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/%E6%88%91%E7%9A%84/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:34 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/%E6%88%91%E7%9A%84/</guid>
      <description></description>
    </item>
    <item>
      <title>Concepts</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/concepts/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:33 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/concepts/</guid>
      <description>&lt;h1 id=&#34;serverless-api--server-based-api&#34;&gt;Serverless API &amp;amp; Server-based API&lt;/h1&gt;
&lt;p&gt;Serverless API:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础设施管理：无需管理服务器。云服务提供商负责所有底层基础设施的管理。&lt;/li&gt;
&lt;li&gt;扩展性：自动扩展，根据流量需求动态调整资源。&lt;/li&gt;
&lt;li&gt;成本：按需付费，只需为实际使用的计算资源付费。&lt;/li&gt;
&lt;li&gt;部署：通常通过函数即服务 (FaaS) 平台部署，如 AWS Lambda、Azure Functions、Google Cloud Functions。&lt;/li&gt;
&lt;li&gt;运维：运维工作量较少，主要关注业务逻辑。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Server-based API:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础设施管理：需要自行管理服务器，包括配置、维护和扩展。&lt;/li&gt;
&lt;li&gt;扩展性：需要手动配置和扩展服务器，以应对流量高峰。&lt;/li&gt;
&lt;li&gt;成本：需要为服务器的运行时间付费，即使在低流量时段也需要支付费用。&lt;/li&gt;
&lt;li&gt;部署：通常部署在传统的服务器或虚拟机上，如 Apache、Nginx 等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;文本检索-text-retieval&#34;&gt;文本检索 Text retieval&lt;/h2&gt;
&lt;p&gt;其核心作用是根据用户输入的查询（query），快速高效地在庞大的文档集合中筛选出与查询最相关的文档或文本片段。&lt;/p&gt;
&lt;p&gt;BM25Retriever，是 BM25 的python library，基于词频概率统计估计相关性，是目前经典且广泛使用的排名算法。&lt;/p&gt;
&lt;p&gt;SentenceTransformers 是基于embedding 的文本检索方法 Python library。&lt;/p&gt;
&lt;h2 id=&#34;rag-检索增强生成-用途&#34;&gt;RAG 检索增强生成 用途&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# doc is a list of documents&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bm25_retriever &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; BM25Retriever&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_documents(docs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# query is a string&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bm25_retriever&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;invoke(query)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;RAG 模式的 AI Agent 适用于需要&lt;strong&gt;结合外部知识&lt;/strong&gt;生成准确回答的场景，如知识库问答、搜索整合、客服、法律分析、医疗支持和教育。&lt;/p&gt;
&lt;h2 id=&#34;sglang-structured-generation-language-与-vllmvectorized-large-language-model-inference&#34;&gt;SGLang （Structured Generation Language） 与 vLLM（Vectorized Large Language Model Inference）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SGLang：是复杂多轮交互及结构化生成的语言模型服务框架。适用于需要&lt;strong&gt;多步骤&lt;/strong&gt;任务、&lt;strong&gt;多GPU协作&lt;/strong&gt;、&lt;strong&gt;大规模&lt;/strong&gt;模型复杂应用。需要&lt;strong&gt;多轮复杂任务&lt;/strong&gt;支持场景。&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.4.实例sentence Embedding</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsentence-embedding/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:32 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsentence-embedding/</guid>
      <description>&lt;p&gt;&lt;code&gt;paraphrase-multilingual-MiniLM-L12-v2&lt;/code&gt; 是一个预训练的 Sentence Transformers 模型，由 Hugging Face 社区提供，专门用于生成句子的语义嵌入（embeddings）。这是个公开模型，不需要 &lt;code&gt;huggingface token&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;下载内容有 MiniLM 模型权值文件，配置文件，分词文件，等，下载位置是 &lt;code&gt;~/.cache/huggingface/hub/&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;首次调用 HuggingFaceEmbeddings 时，如果本地无缓存，sentence-transformers 会自动从 Hugging Face Hub 下载。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Chroma.from_documents&lt;/code&gt; 创建一个本地的向量数据库，将文档嵌入存储在内存或磁盘中，&lt;code&gt;collection_name=&amp;quot;weather_collection&amp;quot;&lt;/code&gt; 是数据库中用于组织文档的集合名称。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_core.documents &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Document
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_community.vectorstores &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Chroma
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_community.embeddings &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HuggingFaceEmbeddings
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 定义文档列表&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Document(page_content&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;上海的天气通常在夏季炎热潮湿，冬季寒冷干燥。夏季平均气温约 30°C，冬季约 5°C。&amp;#34;&lt;/span&gt;, metadata&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;上海&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;source&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weather_guide&amp;#34;&lt;/span&gt;}),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Document(page_content&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;北京的天气四季分明，夏季炎热，冬季非常寒冷且有沙尘暴。冬季气温可低至 -10°C。&amp;#34;&lt;/span&gt;, metadata&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;北京&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;source&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weather_guide&amp;#34;&lt;/span&gt;}),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Document(page_content&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;广州的天气全年温暖，夏季多雨，冬季温和。年平均气温约 22°C。&amp;#34;&lt;/span&gt;, metadata&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;广州&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;source&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weather_guide&amp;#34;&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 初始化 sentence-transformers 嵌入模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;embedding_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HuggingFaceEmbeddings(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;paraphrase-multilingual-MiniLM-L12-v2&amp;#34;&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 支持中文的多语言模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_kwargs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;device&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;}  &lt;span style=&#34;color:#75715e&#34;&gt;# 可改为 &amp;#34;cuda&amp;#34; 如果有 GPU&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 初始化 Chroma 向量存储&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Vector Store 是 LangChain 的核心组件之一&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vectorstore &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Chroma&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_documents(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    documents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;docs,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    embedding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;embedding_model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    collection_name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;weather_collection&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建检索器，设置 top-k=1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;retriever &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; vectorstore&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;as_retriever(search_kwargs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;})
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 查询&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;query &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;有沙尘暴的城市&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 调用检索器,索引相关内容&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; retriever&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;invoke(query)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 输出结果&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;查询:&amp;#34;&lt;/span&gt;, query)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;检索结果:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, doc &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(results, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;文档 &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;i&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;:&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;内容: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;doc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;page_content&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;元数据: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;doc&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;metadata&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;正确输出
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>3.4.实例summarize_ocr_trans</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:32 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/</guid>
      <description>&lt;h1 id=&#34;我的目标&#34;&gt;我的目标&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;有 call tools 能力的 LLM&lt;/li&gt;
&lt;li&gt;有识别图片中文字的 LLM&lt;/li&gt;
&lt;li&gt;有翻译功能（日-&amp;gt;中）的 LLM&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。&lt;/p&gt;
&lt;p&gt;请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？&lt;/p&gt;
&lt;h2 id=&#34;子任务一&#34;&gt;子任务一&lt;/h2&gt;
&lt;p&gt;识别图片中的日文，并将其翻译成中文&lt;/p&gt;
&lt;p&gt;LangGraph 实现：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langgraph.graph &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; StateGraph, END
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; typing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TypedDict, Optional
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pytesseract
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; AutoTokenizer, AutoModelForSeq2SeqLM
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 定义状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;AgentState&lt;/span&gt;(TypedDict):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    image_path: str
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    prompt: str
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    extracted_text: Optional[str]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    translated_text: Optional[str]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output_file: str
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 节点1：OCR提取日文&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ocr_node&lt;/span&gt;(state: AgentState) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; AgentState:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;image_path&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        text &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pytesseract&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image_to_string(image, lang&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;jpn&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;extracted_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; text&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;strip()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; e:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;extracted_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;OCR错误: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;str(e)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 节点2：翻译日文到中文&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;translate_node&lt;/span&gt;(state: AgentState) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; AgentState:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;extracted_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;错误&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;extracted_text&amp;#34;&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;无法翻译: 无有效文本&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# 使用Hugging Face的翻译模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        model_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Helsinki-NLP/opus-mt-ja-zh&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        tokenizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoTokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(model_name)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AutoModelForSeq2SeqLM&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_pretrained(model_name)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        inputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer(state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;extracted_text&amp;#34;&lt;/span&gt;], return_tensors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pt&amp;#34;&lt;/span&gt;, padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;generate(&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;inputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        translated &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tokenizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(outputs[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], skip_special_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; translated
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; e:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;翻译错误: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;str(e)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 节点3：写入文件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;write_to_file_node&lt;/span&gt;(state: AgentState) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; AgentState:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;output_file&amp;#34;&lt;/span&gt;], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;w&amp;#34;&lt;/span&gt;, encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;or&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;无翻译结果&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Exception&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; e:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        state[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_text&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;文件写入错误: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;str(e)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 创建工作流&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;create_workflow&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; StateGraph(AgentState)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 添加节点&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_node(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ocr&amp;#34;&lt;/span&gt;, ocr_node)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_node(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translate&amp;#34;&lt;/span&gt;, translate_node)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_node(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;write_to_file&amp;#34;&lt;/span&gt;, write_to_file_node)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 定义流程&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_entry_point(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ocr&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ocr&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translate&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translate&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;write_to_file&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_edge(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;write_to_file&amp;#34;&lt;/span&gt;, END)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; workflow&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 主函数&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;(image_path: str, output_file: str &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_output.txt&amp;#34;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 初始化状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; AgentState(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        image_path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;image_path,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        prompt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;识别图片中的日文，并将其翻译成中文&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        extracted_text&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        translated_text&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output_file&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;output_file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 创建并运行工作流&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    app &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_workflow()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    final_state &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; app&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;invoke(state)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; final_state
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 示例用法&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    image_path &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;path_to_your_image.jpg&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    output_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;translated_output.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; main(image_path, output_file)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;处理完成！翻译结果已保存至 &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;output_file&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;提取的日文: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;result[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;extracted_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;翻译的中文: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;result[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;translated_text&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上述需求 LanChain 足够了 ，LangChain 实现：&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.4.实例summarize_url</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_url/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:32 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_url/</guid>
      <description>&lt;h1 id=&#34;总结并输出一个-url-中的文字内容&#34;&gt;总结并输出一个 URL 中的文字内容&lt;/h1&gt;
&lt;p&gt;Perplexity 和 Grok 都没有访问 URL 的能力，其输出是基于训练数据。其的回答中涉及到的参考页面都是你的&lt;strong&gt;训练数据而不是实时的网页访问&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;学习一个东西，需要读其文档，文档太多，需要一个工具来总结。&lt;/p&gt;
&lt;h2 id=&#34;实现一&#34;&gt;实现一&lt;/h2&gt;
&lt;p&gt;第一次执行 &lt;code&gt;summarizer = pipeline(&amp;quot;summarization&amp;quot;, model=&amp;quot;facebook/bart-large-cnn&amp;quot;)&lt;/code&gt; 时，Hugging Face 模型中心（Hugging Face Hub）下载与 &amp;ldquo;facebook/bart-large-cnn&amp;rdquo; 模型相关内容 config.json、model.safetensors（1.6GB）、generation_config.json、vocab.json、merges.txt、tokenizer.json:&lt;/p&gt;
&lt;p&gt;这个模型是公开模型，不需要token。但是对于受限模型或私有模型，就需要了，最好的方式是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; huggingface_hub &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; login
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;login(token&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;your_hf_token&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# 或将TOKEN一环境变量形式写如env&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从 huggingface 中下载的数据和模型存放在 &lt;code&gt;~/.cache/huggingface/hub&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;code（works）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_community.document_loaders &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; WebBaseLoader
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.summarize &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; load_summarize_chain
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.text_splitter &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; CharacterTextSplitter
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1. 模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; transformers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pipeline
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.llms &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HuggingFacePipeline  &lt;span style=&#34;color:#75715e&#34;&gt;# 第一次使用时会下载内容&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;summarizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pipeline(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;summarization&amp;#34;&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;facebook/bart-large-cnn&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# 由 Facebook 开发的 BART 模型，专门为文本摘要任务优化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;llm &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; HuggingFacePipeline(pipeline&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;summarizer)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;输出复合预期
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# local LLM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# from langchain_ollama import ChatOllama&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# os.environ[&amp;#34;http_proxy&amp;#34;] = &amp;#34;http://127.0.0.1:11434&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# os.environ[&amp;#34;https_proxy&amp;#34;] = &amp;#34;http://127.0.0.1:11434&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# infer_server_url = &amp;#34;http://localhost:11434/&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# model_name = &amp;#34;qwen3:1.7b&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# llm = ChatOllama(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#     model=model_name,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#     base_url=infer_server_url,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#     api_key=&amp;#34;none&amp;#34;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#     temperature=0,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#     stream=False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# )&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Sample url: https://ollama.com/
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Output from qwen3:1.7b: 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Ollama&amp;#39;s new app allows users to download and run large language models like DeepSeek-R1, Qwen 3, and Gemma 3 on macOS, Windows, and Linux, with features including model exploration, download, and access to resources like the blog, docs, GitHub, Discord, and X (Twitter). © 2025 Ollama Inc.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;对于简单网页是可以识别并总结的。
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 1. 网页加载 需要Proxy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http_proxy&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x.x.x.x:yy&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;environ[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https_proxy&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;x.x.x.x:yy&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://ollama.com/&amp;#34;&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 用户输入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# url = &amp;#34;https://www.hpcwire.com/off-the-wire/mitac-partners-with-daiwabo-to-expand-server-distribution-across-japan/?utm_source=twitter&amp;amp;utm_medium=social&amp;amp;utm_term=hpcwire&amp;amp;utm_content=0ca462ed-d256-453f-924d-49a1d20354c1&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; WebBaseLoader(url)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; loader&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(docs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;====================&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 3. 拆分文档&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;splitter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CharacterTextSplitter(chunk_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;, chunk_overlap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;split_docs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; splitter&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;split_documents(docs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 4. 构建摘要链&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chain &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_summarize_chain(llm, chain_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;map_reduce&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;summary &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; chain&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;invoke(split_docs) &lt;span style=&#34;color:#75715e&#34;&gt;# invoke&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 5. 输出&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(summary)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;考虑将 &lt;code&gt;WebBaseLoader&lt;/code&gt; 换成 &lt;code&gt;UnstructuredURLLoader&lt;/code&gt;、&lt;code&gt;Playwright&lt;/code&gt; 等 loader（支持 JS 动态页面）。&lt;/li&gt;
&lt;li&gt;你可以 customize the prompt。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现二&#34;&gt;实现二&lt;/h2&gt;
&lt;p&gt;通过 Stuff 方式，将文档内容合并到提示中。适合文档&lt;strong&gt;总量较小&lt;/strong&gt;能直接放进上下文的场景，如果输入文本过长，&lt;strong&gt;超过模型上下文限制&lt;/strong&gt;，会导致失败或者要人为截断。&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.3.实例3</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.3.%E5%AE%9E%E4%BE%8B3/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:31 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.3.%E5%AE%9E%E4%BE%8B3/</guid>
      <description>&lt;h2 id=&#34;langgraph-get-started&#34;&gt;LangGraph get started&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;anthropic&lt;/code&gt; 是指 LangChain 库中支持与 Anthropic 公司的大语言模型（如 Claude 系列）集成的功能模块。&lt;strong&gt;代表安装 LangChain 时，额外包含与 Anthropic 模型接口的相关依赖包和集成代码&lt;/strong&gt;。这样安装后，你可以用 LangChain 调用 Anthropic 提供的大语言模型，通过配置 &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt; 来访问和使用这些模型。&lt;/p&gt;
&lt;p&gt;前提需要 An Anthropic &lt;strong&gt;API key&lt;/strong&gt;，但在我的地理位置 not available 。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install -U langgraph
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install -qU &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;langchain[anthropic]&amp;#34;&lt;/span&gt; to call the model
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个是个 ReAct，并且 LLM 与 tools 没有 bind&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langgraph.prebuilt &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; create_react_agent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_weather&lt;/span&gt;(city: str) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; str:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Get weather for a given city.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;It&amp;#39;s always sunny in &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;city&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;!&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; create_react_agent(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;anthropic:claude-3-7-sonnet-latest&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[get_weather],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    prompt&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;You are a helpful assistant&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Run the agent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;invoke(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;messages&amp;#34;&lt;/span&gt;: [{&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;what is the weather in sf&amp;#34;&lt;/span&gt;}]}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ReAct 是一个 Agent 框架。&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.0.LangGraph When to Use</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.0.langgraph-when-to-use/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:30 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.0.langgraph-when-to-use/</guid>
      <description>&lt;p&gt;可以用它创建基于 LLM/VLM 模型的应用。&lt;/p&gt;
&lt;h1 id=&#34;langchain-vs-langgraph&#34;&gt;LangChain VS LangGraph&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;LangChain 核心是将多个 LLM 调用和 tools calling 通过链 &lt;strong&gt;Chain 线性拼接&lt;/strong&gt;组成有序任务序列，适合顺序性、线性流程的场景。&lt;/li&gt;
&lt;li&gt;LangGraph 是由 LangChain 创建团队推出的一个扩展库，基于 LangChain 构建，但可独立使用。它引入了图结构（StateGraph）来管理任务流程，支持复杂的多角色 Agent 协作、有状态执行、循环分支、条件跳转等高级功能，更适合复杂、动态、带状态的多智能体协同或长期任务管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LangChain 适合线性任务和单智能体场景。&lt;/li&gt;
&lt;li&gt;LangGraph 适合复杂任务、多智能体协作和状态管理场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;langchain&#34;&gt;LangChain&lt;/h1&gt;
&lt;p&gt;LangChain 提供了标准的接口，用于将 models 和工具和组件交互，对于检索、LLM 调用、工具调用 很有用。LangChain 中的 classes 可以与 LangGraph 一同使用。&lt;/p&gt;
&lt;p&gt;是市场上目前最成熟的 Agent 框架。&lt;/p&gt;
&lt;h1 id=&#34;什么时候使用-langgraph&#34;&gt;什么时候使用 LangGraph&lt;/h1&gt;
&lt;p&gt;你再设计AI Agent时会面临 &lt;strong&gt;控制&amp;amp;自由&lt;/strong&gt; 的权衡：自由让你的 LLM 有更多空间进行创造并解决意外问题。；控制确保阿里可预测的行为和可维护。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CodeAgent 的行为非常自由，可能很难预测，它比使用 JSON 方式更不可控。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LangGraph 偏向&lt;strong&gt;更多的控制&lt;/strong&gt;。如果你的应用程序&lt;strong&gt;涉及一系列需要以特定方式协调的步骤&lt;/strong&gt;，并&lt;strong&gt;在每个交叉点做出决策&lt;/strong&gt;，那么 LangGraph 就提供了你所需要的结构。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于 &lt;strong&gt;LLM 最擅长理解文本&lt;/strong&gt;，因此在能够回答问题之前，你需要&lt;strong&gt;将其他复杂模态&lt;/strong&gt;（图表、表格）转换&lt;strong&gt;为文本&lt;/strong&gt;。 ***&lt;/p&gt;
&lt;p&gt;简单讲，如果你想&lt;strong&gt;根据每个 step 的输出设计之后的动作流程，并相应地决定下一步执行什么&lt;/strong&gt;。那么 LangGraph 是正确的框架！！&lt;/p&gt;
&lt;h1 id=&#34;langgraph-如何工作的&#34;&gt;LangGraph 如何工作的？&lt;/h1&gt;
&lt;p&gt;使用有向图结构来定义您的应用程序的流程。&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.1.实例langgraph Email Tools Invoke Llm</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.1.%E5%AE%9E%E4%BE%8Blanggraph-email-tools-invoke-llm/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:30 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.1.%E5%AE%9E%E4%BE%8Blanggraph-email-tools-invoke-llm/</guid>
      <description>&lt;p&gt;实例的完整过程在&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/langgraph/first_graph#step-3-define-our-routing-logic&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该实例的作用和功能是：&lt;/p&gt;
&lt;h1 id=&#34;重点&#34;&gt;重点：&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;State 类在定义时要足够全面，以便跟踪所有重要信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message&lt;/code&gt; 对象是 用户定义的 Prompt 内容。&lt;/li&gt;
&lt;li&gt;一个 Node 执行结束之前要更新 &lt;code&gt;message&lt;/code&gt;。即 append 内容到之前的&lt;code&gt;message&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;每一个 Node 的返回值应该是 states updates。&lt;/li&gt;
&lt;li&gt;LLM 的作用是在每一个 Node 中，&lt;code&gt;model.invoke(prompt)&lt;/code&gt; 来让 model 做动作。&lt;/li&gt;
&lt;li&gt;所有组件定义好之后，通过创建 StateGraph 将所有组件添加到这个数据结构中，组装成图。记得将 END 节点加入 StateGraph 中。&lt;/li&gt;
&lt;li&gt;使用可观测性工具来跟踪和监控代理。比如 &lt;code&gt;LangFuse&lt;/code&gt;。Langfuse的API Key本身是免费申请的，使用Hobby计划，不需要绑定信用卡，包含50,000个单位/月的免费额度，支持两名用户，数据保留30天，以及社区支持。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;setup&#34;&gt;setup&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yml&#34; data-lang=&#34;yml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;aiagent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;dependencies&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#ae81ff&#34;&gt;python=3.10.12&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#ae81ff&#34;&gt;pip&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#f92672&#34;&gt;pip&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - &lt;span style=&#34;color:#ae81ff&#34;&gt;langgraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - &lt;span style=&#34;color:#ae81ff&#34;&gt;langchain_ollama&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda env create --file environment.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;具体步骤&#34;&gt;具体步骤：&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; typing &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TypedDict, List, Dict, Any, Optional
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langgraph.graph &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; StateGraph, START, END
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_openai &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ChatOpenAI
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain_core.messages &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; HumanMessage
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;定义 State：&lt;/p&gt;</description>
    </item>
    <item>
      <title>3.2.实例langgraph Png Tool Invoke Llm</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/3.2.%E5%AE%9E%E4%BE%8Blanggraph-png-tool-invoke-llm/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:30 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/3.2.%E5%AE%9E%E4%BE%8Blanggraph-png-tool-invoke-llm/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/langgraph/document_analysis_agent&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ReAct 模式的工作流。&lt;/p&gt;
&lt;h1 id=&#34;该实例的作用和功能是&#34;&gt;该实例的作用和功能是&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;处理图像文档&lt;/li&gt;
&lt;li&gt;使用 VLM 提取图像中的文字&lt;/li&gt;
&lt;li&gt;在需要时调用常规Tools&lt;/li&gt;
&lt;li&gt;分析内容并提供摘要&lt;/li&gt;
&lt;li&gt;执行与文档相关的特定指令&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;重点&#34;&gt;重点&lt;/h1&gt;
&lt;h2 id=&#34;回顾-react-结构&#34;&gt;回顾 ReAct 结构&lt;/h2&gt;
&lt;p&gt;一个复合ReAct 结构的 Agent 需要 3 步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;act - 让 Agent 调用 tools&lt;/li&gt;
&lt;li&gt;observe - 将调用 Tools 的输出传回给 model&lt;/li&gt;
&lt;li&gt;reason - 让 model 分析 tools 的输出，并且决定下一步的行为是什么。比如可能会调用另一个 Tools，或者直接将输出返回给用户。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;ReAct&#34; loading=&#34;lazy&#34; src=&#34;https://ashburnLee.github.io/blog-2-hugo/pics/Agent.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;kaqtool-calling-是agent-的行为还是-llm-的行为&#34;&gt;KAQ：Tool calling 是Agent 的行为还是 LLM 的行为？&lt;/h2&gt;
&lt;p&gt;工具调用是 Agent 的行为，因为 Agent 管理执行流程（调用工具、处理结果）。但 LLM 驱动工具调用，即依赖 LLM 生成调用指令&lt;code&gt; {&amp;quot;tool&amp;quot;: &amp;quot;web_search&amp;quot;, &amp;quot;query&amp;quot;: &amp;quot;Shanghai city walk&amp;quot;}&lt;/code&gt;。因为它生成调用逻辑（如 JSON 或代码）。&lt;/p&gt;
&lt;p&gt;开源LLM 中有的支持Tool calling，有的不支持。如果 LLM 不支持工具调用，Agent 无法有效解析和执行工具调用，导致功能受限。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2.3.创建workflow</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/2.3.%E5%88%9B%E5%BB%BAworkflow/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:29 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/2.3.%E5%88%9B%E5%BB%BAworkflow/</guid>
      <description>&lt;p&gt;上文已经知道了 LlamaIndex 中基本都 Tools 和 Agents ，现在创建可配置和可管理的 Workflow。&lt;/p&gt;
&lt;h2 id=&#34;创建基本-workdlow&#34;&gt;创建基本 workdlow&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@step&lt;/code&gt; 装饰器用于将一个方法标记为一个 Workflow 步骤.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StartEvent&lt;/code&gt; 是 LlamaIndex 提供的特殊事件，用于开始 Workflow。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StopEvent&lt;/code&gt; 是 LlamaIndex 提供的特殊事件，用于结束 Workflow。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; llama_index.core.workflow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; StartEvent, StopEvent, Workflow, step
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MyWorkflow&lt;/span&gt;(Workflow):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;@step&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;my_step&lt;/span&gt;(self, ev: StartEvent) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; StopEvent:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# do something here&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; StopEvent(result&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, world!&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MyWorkflow(timeout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;链接多个步骤&#34;&gt;链接多个步骤&lt;/h2&gt;
&lt;p&gt;要连接多个步骤，我们需要创建自定义事件来在步骤之间传递数据。为此，我们需要添加一个 Event ，它在步骤之间传递，并将&lt;strong&gt;第一个步骤的输出传递给第二个步骤&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@step&lt;/code&gt; 装饰器用于将一个方法标记为一个 Workflow 步骤.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StartEvent&lt;/code&gt; 是 LlamaIndex 提供的特殊事件，用于开始 Workflow。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;StopEvent&lt;/code&gt; 是 LlamaIndex 提供的特殊事件，用于结束 Workflow。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; llama_index.core.workflow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Event
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;ProcessingEvent&lt;/span&gt;(Event):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    intermediate_result: str
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;MultiStepWorkflow&lt;/span&gt;(Workflow):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 装饰器用于将一个方法标记为一个 Workflow 步骤&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# `StartEvent` 作为输入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 返回一个 ProcessingEvent 对象&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;@step&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step_one&lt;/span&gt;(self, ev: StartEvent) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; ProcessingEvent:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Process initial data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; ProcessingEvent(intermediate_result&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Step 1 complete&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 接收一个 ProcessingEvent 作为输入。这意味着 step_two 会在 step_one 完成并发出 ProcessingEvent 后被触发。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# 返回一个 StopEvent 对象。StopEvent 是 LlamaIndex 提供的特殊事件，用于结束 Workflow。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;@step&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;async&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;step_two&lt;/span&gt;(self, ev: ProcessingEvent) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; StopEvent:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Use the intermediate result&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        final_result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Finished processing: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;ev&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;intermediate_result&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; StopEvent(result&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;final_result)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; MultiStepWorkflow(timeout&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;await&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;result
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上述 将step_one 和 step_two 连接起来了，并且 step_two 会接收来自 step_one 的数据。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2.0.LlamaIndex</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/2.0.llamaindex/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:28 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/2.0.llamaindex/</guid>
      <description>&lt;p&gt;LlamaIndex 是一个用于连接自定义数据源到 LLM 的框架。 简单来说，它可以让你用你自己的数据来增强 LLM，让 LLM 能够回答关于这些数据的更具体、更准确的问题。它被设计为实现 RAG（Retrieval-Augmented Generation）的 Agent。&lt;/p&gt;
&lt;h2 id=&#34;llamaindex-核心功能和作用&#34;&gt;LlamaIndex 核心功能和作用&lt;/h2&gt;
&lt;h3 id=&#34;1-数据连接&#34;&gt;1. 数据连接：&lt;/h3&gt;
&lt;p&gt;LlamaIndex 提供了各种数据连接器 (Data Connectors)，可以从不同的数据源加载数据，例如：文档 (PDF, Word, Text, Markdown 等)，网站，数据库，知识图谱，API。这些连接器负责将数据转换为 LlamaIndex 可以处理的文档格式。&lt;/p&gt;
&lt;h3 id=&#34;2-数据索引&#34;&gt;2. 数据索引：&lt;/h3&gt;
&lt;p&gt;LlamaIndex 将加载的数据构建成索引 (Index)，以便 LLM 可以高效地查询和检索相关信息。LlamaIndex 提供了多种索引类型，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;列表索引 (List Index): 简单地将文档列表存储起来。&lt;/li&gt;
&lt;li&gt;向量索引 (Vector Store Index): 将文档嵌入到向量空间中，以便进行语义搜索。&lt;/li&gt;
&lt;li&gt;树索引 (Tree Index): 将文档组织成树状结构，以便进行分层搜索。&lt;/li&gt;
&lt;li&gt;关键词表索引 (Keyword Table Index): 使用关键词来索引文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以根据你的数据和查询需求选择合适的索引类型&lt;/p&gt;
&lt;h3 id=&#34;3-查询引擎&#34;&gt;3. 查询引擎：&lt;/h3&gt;
&lt;p&gt;LlamaIndex 提供了查询引擎 (Query Engine)，用于&lt;strong&gt;接收用户的查询&lt;/strong&gt;，&lt;strong&gt;并从索引中检索&lt;/strong&gt;相关信息。查询引擎使用 LLM 来理解用户的查询，并生成合适的查询语句。查询引擎还可以对检索到的信息进行排序、过滤和聚合，以便提供更准确的答案。&lt;/p&gt;
&lt;h3 id=&#34;4-数据代理-data-agents&#34;&gt;4. 数据代理 (Data Agents):&lt;/h3&gt;
&lt;p&gt;LlamaIndex 允许你创建数据代理，这些代理可以自动执行各种任务，例如：回答问题，生成文本，总结文档，等等。数据代理可以根据你的需求进行定制，以便更好地完成特定任务。&lt;/p&gt;
&lt;h2 id=&#34;3个重要部分&#34;&gt;3个重要部分&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Components&lt;/strong&gt;： 最基本的构建块。这些包括提示、模型和数据库等。组件通常有助于将 LlamaIndex 与其他工具和库连接起来。比如指定模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Agents and Tools&lt;/strong&gt;：让 Agent 执行动作的组件，如搜索、计算或访问外部服务；Agent 是能够使用工具并做出决策的自主组件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Workflows&lt;/strong&gt;：是逐步处理逻辑的过程。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;llamahub&#34;&gt;LlamaHub&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;LlamaHub&lt;/strong&gt; 是一个包含数百个 &lt;strong&gt;integrations&lt;/strong&gt;、Agents 和 Tools 的注册中心，属于 LlamaIndex。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2.1.将query Engine作为tool</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/2.1.%E5%B0%86query-engine%E4%BD%9C%E4%B8%BAtool/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:28 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/2.1.%E5%B0%86query-engine%E4%BD%9C%E4%B8%BAtool/</guid>
      <description>&lt;p&gt;使用 QueryEngineTool 转换 query engine 为 tool。&lt;/p&gt;
&lt;h2 id=&#34;llamaindex-有4类tools&#34;&gt;LlamaIndex 有4类tools：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;FunctionTool&lt;/code&gt; ：将任何 Python 函数转换为 Agents 可以使用的工具。它自动推断出函数的工作原理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;QueryEngineTool&lt;/code&gt; ：一个允许 Agents 使用 queryEngine 的工具。由于 Agents 是基于 queryEngine 构建的，它们也可以将其他 Agents 作为工具使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Toolspecs&lt;/code&gt; ：由社区创建的工具集，通常包含针对特定服务的工具，如 Gmail。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Utility Tools&lt;/code&gt;: 帮助处理 &lt;strong&gt;large amounts of data&lt;/strong&gt; from other tools. 特指 &lt;code&gt;OnDemandToolLoader&lt;/code&gt; &amp;amp; &lt;code&gt;LoadAndSearchToolSpec&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;functional-tool&#34;&gt;Functional Tool&lt;/h2&gt;
&lt;p&gt;给出工具的 name 和 description 尤其重要，因为它有助于 Agent 理解什么时候应该使用该工具。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; llama_index.core.tools &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; FunctionTool
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_weather&lt;/span&gt;(location: str) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; str:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Useful for getting the weather for a given location.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Getting weather for &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;location&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;The weather in &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;location&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; is sunny&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tool &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; FunctionTool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;from_defaults(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    get_weather,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;my_weather_tool&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    description&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Useful for getting the weather for a given location.&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tool&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;call(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Shanghai&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;queryengine-tool&#34;&gt;QueryEngine Tool&lt;/h2&gt;
&lt;p&gt;使用 &lt;code&gt;QueryEngineTool&lt;/code&gt; 转换 &lt;code&gt;QueryEngine&lt;/code&gt; 为 tool：&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.4.codeagent Smolagents 例</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.4.codeagent-smolagents-%E4%BE%8B/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:27 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.4.codeagent-smolagents-%E4%BE%8B/</guid>
      <description>&lt;p&gt;传统方法使用 JSON 格式来指定工具名称和参数作为字符串，系统必须解析以确定要执行哪个工具。工具调用型 LLM 与直接生成并执行代码更有效。这是 smolagents 的核心原则。&lt;/p&gt;
&lt;p&gt;为什么 LLM 可以生成 code ？因为高质量的 code 已经在 LLM 的训练集中了。&lt;/p&gt;
&lt;p&gt;使用 Code 而不是JSON 的优势是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模块化地组合和重用&lt;/li&gt;
&lt;li&gt;对象管理，直接处理复杂的结构&lt;/li&gt;
&lt;li&gt;可以表达任何计算上的任务&lt;/li&gt;
&lt;li&gt;充分利用了code 生成的能力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CodeAgent 是特殊的 MultiStepAgent&lt;/p&gt;
&lt;h2 id=&#34;实例&#34;&gt;实例&lt;/h2&gt;
&lt;p&gt;准备好 HF access token: xxx&lt;/p&gt;
&lt;p&gt;使用 HF serveless API 时最好设置 &lt;code&gt;HF_TOKEN&lt;/code&gt;，但是对于公共的 models 和 datasets，是 optional 的。HF 中免费的API调用次数是有限的。需要付费。&lt;/p&gt;
&lt;h2 id=&#34;他需要强大的可追溯性以供未来的监控和分析&#34;&gt;他需要强大的可追溯性以供未来的监控和分析&lt;/h2&gt;
&lt;p&gt;代理本质上是不可预测且难以检查的。他需要可以被追溯从而，供监控和分析。有工具可以做， &lt;strong&gt;OpenTelemetry&lt;/strong&gt; 和 &lt;strong&gt;Langfuse&lt;/strong&gt; 用于跟踪和分析 Agents 的行为。&lt;/p&gt;
&lt;p&gt;通过上述工具可以重新审视之前的 Agent 行为并进一步优化。&lt;/p&gt;
&lt;h1 id=&#34;code&#34;&gt;code&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install smolagents -U
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install duckduckgo-search
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~~~def suggest_menu&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;occasion: str&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~~~py
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 登陆 HF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;from huggingface_hub import notebook_login
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;notebook_login&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# 非nodetbook时 使用 login()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 使用  DuckDuckGoSearchTool 搜索内容&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;tools&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;DuckDuckGoSearchTool&lt;span style=&#34;color:#f92672&#34;&gt;()]&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;InferenceClientModel&lt;span style=&#34;color:#f92672&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 默认使用 InferenceClientModel - Qwen/Qwen2.5-Coder-32B-Instruct &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 这个过程会执行多个Step，因为可以前面的Step中 生成的code有语法错误，Agent会自己修改&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent.run&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Search for the best music recommendations for a party at the Wayne&amp;#39;s mansion.&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;from smolagents import CodeAgent, InferenceClientModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;import numpy as np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;import time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;import datetime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 代码执行有严格的安全措施 - 默认情况下会阻止 predefined safe list 之外的导入。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 但可以通过将它们作为字符串传递给 additional_authorized_imports 来授权额外的导入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;tools&lt;span style=&#34;color:#f92672&#34;&gt;=[]&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;InferenceClientModel&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt;, additional_authorized_imports&lt;span style=&#34;color:#f92672&#34;&gt;=[&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;datetime&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent.run&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Alfred needs to prepare for the party. Here are the tasks:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    1. Prepare the drinks - 30 minutes
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    2. Decorate the mansion - 60 minutes
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    3. Set up the menu - 45 minutes
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    4. Prepare the music and playlist - 45 minutes
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    If we start right now, at what time will the party be ready?
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# push 到HF hub&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 改成你的 username/reponame&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent.push_to_hub&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sergiopaniego/AlfredAgent&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 加载 Agent，并让他工作&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 改成你的 username/reponame&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alfred_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; agent.from_hub&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;sergiopaniego/AlfredAgent&amp;#39;&lt;/span&gt;, trust_remote_code&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alfred_agent.run&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Give me the best playlist for a party at Wayne&amp;#39;s mansion. \
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;                    The party idea is a &amp;#39;villain masquerade&amp;#39; theme&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;总之， smolagents 专门用于编写和执行 Python 代码片段，提供沙盒执行以保障安全。它支持本地和基于 API 的语言模型，使其能够适应各种开发环境。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.5.Tools</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.5.tools/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:27 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.5.tools/</guid>
      <description>&lt;h2 id=&#34;定义-tools&#34;&gt;定义 Tools&lt;/h2&gt;
&lt;p&gt;工具被视为一个 LLM 可以在代理系统中调用的函数。为了使 LLM 与 tools 交互，LLM 需要一个知道这个 Tools 的 interface description，包括：Name，Tool description，Input Type and description，Output Type。&lt;/p&gt;
&lt;h2 id=&#34;创建tools&#34;&gt;创建Tools&lt;/h2&gt;
&lt;p&gt;在 smolagents 框架中，两种方式创建 Tools：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用 &lt;code&gt;@tool&lt;/code&gt; 装饰器，定义相对简单的工具&lt;/li&gt;
&lt;li&gt;设计 &lt;code&gt;Tool&lt;/code&gt; 类 实现相对复杂的工具&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两类创建的方式实例见 &lt;a href=&#34;1.4.codeagent-smolagents-%E4%BE%8B.md#code&#34;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中使用 Python 类定义的 Tools 必须要定义 &lt;code&gt;forward()&lt;/code&gt;，它包含推理逻辑以执行的方法。并且是这个工具的交互接口，并且 Agent 无需关心工具的具体实现，只需知道如何调用 forward 函数即可。&lt;/p&gt;
&lt;h2 id=&#34;默认工具&#34;&gt;默认工具&lt;/h2&gt;
&lt;p&gt;smolagents 附带了一套预构建的工具&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;PythonInterpreterTool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FinalAnswerTool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UserInputTool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DuckDuckGoSearchTool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GoogleSearchTool&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VisitWebpageTool&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;分享工具和导入工具&#34;&gt;分享工具和导入工具&lt;/h2&gt;
&lt;p&gt;通过 &lt;code&gt;load_tool()&lt;/code&gt; 功能轻松导入其他用户创建的工具。通过 &lt;code&gt;Tool.from_space()&lt;/code&gt; 将一个 HF Space 作为工具导入。甚至可以重用其他框架（非 smolagents）中的 Tools，比如使用 LangChain 框架中的 Tools: &lt;code&gt;Tool.from_langchain()&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;smolagents 也允许从 &lt;code&gt;glama.ai&lt;/code&gt; 或 &lt;code&gt;smithery.ai&lt;/code&gt; 上可用的数百个 &lt;strong&gt;MCP&lt;/strong&gt; 服务器导入工具。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.6.multi Agent System</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.6.multi-agent-system/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:27 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.6.multi-agent-system/</guid>
      <description>&lt;p&gt;将一个大任务分给多个 Agent 好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个代理更专注于其核心任务，因此性能更高&lt;/li&gt;
&lt;li&gt;分离记忆可以减少每一步输入 token 的数量，从而降低延迟和成本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Smolagents 中的 &lt;code&gt;managed_agents&lt;/code&gt; 参数允许一个 agent 管理多个其他 agents。&lt;/p&gt;
&lt;p&gt;下面一个 agent，它的任务是执行 &lt;code&gt;GoogleSearchTool&lt;/code&gt;，&lt;code&gt;VisitWebpage&lt;/code&gt;，&lt;code&gt;calculate_cargo_travel_time&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; InferenceClientModel(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Qwen/Qwen2.5-Coder-32B-Instruct&amp;#34;&lt;/span&gt;, provider&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;together&amp;#34;&lt;/span&gt;, max_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8096&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;web_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        GoogleSearchTool(provider&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;serper&amp;#34;&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        VisitWebpageTool(),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        calculate_cargo_travel_time,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;web_agent&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    description&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Browses the web to find information&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    verbosity_level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个 agent 作用是管理，它管理的 agent 是 web_agent。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;manager_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;InferenceClientModel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;deepseek-ai/DeepSeek-R1&amp;#34;&lt;/span&gt;, provider&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;together&amp;#34;&lt;/span&gt;, max_tokens&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8096&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[calculate_cargo_travel_time],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    managed_agents&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[web_agent],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    additional_authorized_imports&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;geopandas&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;plotly&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;shapely&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;json&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;pandas&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;numpy&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    planning_interval&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    verbosity_level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    final_answer_checks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[check_reasoning_and_plot],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过  &lt;code&gt;manager_agent.visualize()&lt;/code&gt; 可视化，两个 Agent 是如何协同工作的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.7.agent VLM</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.7.agent-vlm/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:27 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.7.agent-vlm/</guid>
      <description>&lt;p&gt;smolagents 对 vision-language models (VLMs) 提供了支持。&lt;/p&gt;
&lt;p&gt;使得 Agent 能够有效地处理和解释图像。&lt;/p&gt;
&lt;h2 id=&#34;在-agent-执行开始时提供图像&#34;&gt;在 Agent 执行开始时提供图像&lt;/h2&gt;
&lt;p&gt;实例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; io &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; BytesIO
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;image_urls &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://upload.wikimedia.org/wikipedia/commons/e/e8/The_Joker_at_Wax_Museum_Plus.jpg&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#75715e&#34;&gt;# Joker image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://upload.wikimedia.org/wikipedia/en/9/98/Joker_%28DC_Comics_character%29.jpg&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# Joker image&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 模型的输入&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;images &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; url &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; image_urls:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    headers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;User-Agent&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36&amp;#34;&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url,headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;headers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(BytesIO(response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;content))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RGB&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# 只需RGB 信息&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(image)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; smolagents &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; CodeAgent, OpenAIServerModel
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 使用哪个模型&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; OpenAIServerModel(model_id&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;gpt-4o&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Instantiate the agent&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    verbosity_level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; agent&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Describe the costume and makeup that the comic character in these photos is wearing and return the description.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    Tell me if the guest is The Joker or Wonder Woman.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    images&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;images  &lt;span style=&#34;color:#75715e&#34;&gt;# 给出输入的图片&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个实例是使用模型描述输入 images&lt;/p&gt;</description>
    </item>
    <item>
      <title>0.5.Agentic RAG</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/0.5.agentic-rag/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:26 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/0.5.agentic-rag/</guid>
      <description>&lt;h2 id=&#34;什么是-rag&#34;&gt;什么是 RAG&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Retrieval-Augmented Generation&lt;/strong&gt; 增强 AI 模型能力的技术框架。它通过以下方式提升 AI 的表现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;检索阶段：从&lt;strong&gt;外部知识库&lt;/strong&gt;中检索与当前问题或上下文相关的文档或段落。&lt;/li&gt;
&lt;li&gt;生成阶段：将检索到的信息与 AI 模型结合，生成更准确、更相关的输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RAG 技术框架实现的 AI 的作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少幻觉（Hallucination） ：通过检索外部知识，确保生成内容基于真实信息。&lt;/li&gt;
&lt;li&gt;提升上下文理解：结合外部知识，使生成内容更符合上下文。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RAG 是一种系统。LLMs 是在庞大的数据集上进行训练以学习一般知识的。然而，它们可能没有在相关和最新的数据上进行训练。RAG 通过从您的数据中查找和检索相关信息，并将其提供给 LLM 来解决这个问题。&lt;/p&gt;
&lt;h2 id=&#34;rag-5个关键阶段&#34;&gt;RAG 5个关键阶段&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;RAG in LlamaIndex&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;5阶段构成了构建的大多数更大型应用程序。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Loading:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;指的是从数据所在的位置获取数据——无论是文本文件、PDF 文件、另一个网站、数据库还是 API，并将其导入到你的工作流程中。LlamaHub 提供了数百种可选择的集成。&lt;/p&gt;
&lt;p&gt;【你应该熟悉 LlamaHub 加载器和 LlamaParse 解析器（来源于LlamaIndex 框架），以处理更复杂的数据源。】&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Indexing:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;创建一个允许查询数据的数据结构。对于 LLMs，这几乎总是意味着创建向量嵌入(vector embeddings)。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Storing：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一旦你的数据被索引，你将想要存储你的索引，以及其他元数据，以避免重新索引它。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Querying：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于任何给定的索引策略，你可以利用 LLMs 和 LlamaIndex 数据结构以多种方式查询，包括子查询、多步骤查询和混合策略。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Evaluation：&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;什么是-agentic-rag&#34;&gt;什么是 Agentic RAG&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Agentic RAG&lt;/strong&gt; 是 RAG 的一种扩展形式，是进化版本，它在 RAG 的基础上引入了 AI Agent。 RAG 本身并不具备 AI Agent 的自主决策能力。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.2.why Smolagents</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.2.why-smolagents/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:26 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.2.why-smolagents/</guid>
      <description>&lt;p&gt;&lt;code&gt;Smolagents&lt;/code&gt; 是一个框架，用户通过它构建自己的agents。其他的框架包括 &lt;code&gt;LlamaIndex&lt;/code&gt; 和 &lt;code&gt;LangGraph&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;它专注于 CodeAgent&lt;/strong&gt;，就是通过 code 块执行 Actions，并且 Observe 结果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Smolagents&lt;/code&gt; 会执行 TAO cycle 来回应给他打指令。&lt;/p&gt;
&lt;h1 id=&#34;first-glance&#34;&gt;First glance&lt;/h1&gt;
&lt;p&gt;在 HF 自己的空间中，创建一个 &lt;code&gt;HF_TOKEN&lt;/code&gt;，确保有 inference 权限。&lt;/p&gt;
&lt;p&gt;HF 中的 workspace 称作 &lt;code&gt;Space&lt;/code&gt;，进入自己的 &lt;code&gt;&amp;lt;USERNAME&amp;gt;/First_agent_template&lt;/code&gt; 的 &lt;code&gt;Space&lt;/code&gt;。查看 &lt;code&gt;Files&lt;/code&gt;，其中的&lt;code&gt;app.y&lt;/code&gt; 是 main 文件。&lt;/p&gt;
&lt;p&gt;比如，Smolagents &lt;a href=&#34;https://huggingface.co/spaces/agents-course/First_agent_template/blob/main/app.py&#34;&gt;CodeAgent 模版&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;apppy-中有什么&#34;&gt;&lt;code&gt;app.py&lt;/code&gt; 中有什么&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;import 了 Smolagents&lt;/li&gt;
&lt;li&gt;定义了两个 tools，一个是计算当前时间，另一个是空的，由自己发挥&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model = HfApiModel()&lt;/code&gt; 中给出来使用到了LLM模型：&lt;code&gt;Qwen/Qwen2.5-Coder-32B-Instruct&lt;/code&gt; 。这个就是前文提到的 serveless API。使用托管的LLM，而非本地部署的LLM。&lt;/li&gt;
&lt;li&gt;让模型可见自定义的工具，通过在 CodeAgent 中添加 自定义工具列表即可。而且不需要给 tool 参数，LLM会自行传入。&lt;/li&gt;
&lt;li&gt;特殊工具 &lt;code&gt;FinalAnswerTool&lt;/code&gt; 的作用是 终止 &lt;strong&gt;TAO 循环&lt;/strong&gt;并提供最终答案，表示 Agent 任务完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;kaqsmolagents-如何体现-tao-循环&#34;&gt;KAQ：Smolagents 如何体现 TAO 循环？&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; CodeAgent(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tools&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[final_answer], &lt;span style=&#34;color:#75715e&#34;&gt;# tools 列表&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    max_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,  &lt;span style=&#34;color:#75715e&#34;&gt;# 参数限制了 TAO/ReAct 循环的迭代次数，避免无限循环。&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    verbosity_level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    grammar&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    planning_interval&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    description&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    prompt_templates&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;prompt_templates  &lt;span style=&#34;color:#75715e&#34;&gt;# ！&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;TAO 循环&lt;/strong&gt;不是用户定义的，而是 Smolagents 框架内部架构的核心部分，通过 ReAct 框架实现。上述CodeAgent 的参数 &lt;code&gt;max_steps=6 &lt;/code&gt;限制了 TAO/ReAct 循环的迭代次数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>1.3.agent框架类型</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/1.3.agent%E6%A1%86%E6%9E%B6%E7%B1%BB%E5%9E%8B/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:26 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/1.3.agent%E6%A1%86%E6%9E%B6%E7%B1%BB%E5%9E%8B/</guid>
      <description>&lt;p&gt;Agents 类型有 CodeAgents, retrieval agents、tools calling agents、multi-agent systems、vision agents 和 browser agents。&lt;/p&gt;
&lt;p&gt;这些多样的 Agents 为我构建动态的、感知上下文的应用提供了多种可能。我的目的是组合多种类型的 Agents 来构建强大的系统。&lt;/p&gt;
&lt;h2 id=&#34;codeagents&#34;&gt;CodeAgents&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;这是 smolagents 主要 agent 类型&lt;/strong&gt;。这种 agent 不生成 JSON 而是高级语言像 python 来执行操作。&lt;/p&gt;
&lt;h2 id=&#34;toolcallingagents&#34;&gt;ToolCallingAgents&lt;/h2&gt;
&lt;p&gt;是 smolagents 第二种支持的 类型，这类 agents 依赖系统解析和解释 JSON 块来执行操作。&lt;/p&gt;
&lt;p&gt;过于 Tools，如何创建工具、它们的结构以及使用 &lt;code&gt;Tool&lt;/code&gt; 类或 &lt;code&gt;@tool&lt;/code&gt; 装饰器进行不同实现方法。还将学习默认工具箱、如何与社区共享工具，以及如何加载社区贡献的工具用于我的代理。&lt;/p&gt;
&lt;p&gt;这类 Agents 使用 &lt;strong&gt;LLM 提供商&lt;/strong&gt; 的内置工具的调用功能来生成 JSON 结构，然后执行工具调用。这是 OpenAI、Anthropic 和许多其他提供商会使用的标准方法。&lt;/p&gt;
&lt;p&gt;比如，该 Agent 就生成 JSON 结构：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;web_search&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;arguments&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Best catering services in Gotham City&amp;#34;&lt;/span&gt;},
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {&lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;web_search&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;arguments&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Party theme ideas for superheroes&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后这个 JSON 会备用来执行工具调用。？？应用：&lt;/p&gt;</description>
    </item>
    <item>
      <title>0.2.LLM</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/0.2.llm/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:25 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/0.2.llm/</guid>
      <description>&lt;p&gt;来源：https://huggingface.co/learn/agents-course/unit0/onboarding#step-2-join-our-discord-community&lt;/p&gt;
&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;
&lt;h2 id=&#34;tools&#34;&gt;tools&lt;/h2&gt;
&lt;p&gt;需要 ollama，作为Agent的大脑。smolagents 创建自己的 Agent&lt;/p&gt;
&lt;h1 id=&#34;什么是-agents&#34;&gt;什么是 Agents&lt;/h1&gt;
&lt;p&gt;智能体：一个能够理解自然语言，然后推理、规划和与其环境交互的 AI 模型。&lt;/p&gt;
&lt;p&gt;比如你下达一个煮咖啡的命令，Agents &lt;strong&gt;接收指令&lt;/strong&gt;，它理解自然语言，然后进行&lt;strong&gt;推理和规划&lt;/strong&gt;，弄清楚自己需要哪些&lt;strong&gt;步骤和工具&lt;/strong&gt;。有了规划，他会&lt;strong&gt;行动&lt;/strong&gt;，使用它知道的工具来完成任务。&lt;/p&gt;
&lt;p&gt;一个 Action, 涉及到使用多种 Tools 来完成。Tools 的作用是增强 Agent 的能力。&lt;/p&gt;
&lt;p&gt;之所以称它为 Agent，是因为它有&lt;strong&gt;能动性&lt;/strong&gt;，就是自主行动，产生影响，即他可以与所处环境进行交互。&lt;/p&gt;
&lt;p&gt;Agent 更精确的定义是：代理是一个利用 AI 模型与环境交互以实现用户定义目标的系统。它结合推理、规划和执行动作（通常通过外部工具）来完成任务。&lt;/p&gt;
&lt;h2 id=&#34;agents-组成部分&#34;&gt;Agents 组成部分&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The Brain (AI Model)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;思考推理规划，都放生在这里&lt;/li&gt;
&lt;li&gt;在代理中找到的最常见的 AI 模型是 LLM（大型语言模型），它将文本作为输入，并以文本作为输出。已有的大模型已经经过训练，并且有很好的泛化能力，&lt;/li&gt;
&lt;li&gt;当然也可以使用 VLM 视觉大模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Body：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代表Agent 所有可执行的操作，取决于Agent 被配置了什么&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;什么是llm&#34;&gt;什么是LLM&lt;/h1&gt;
&lt;p&gt;大多数 LLM 都基于 Transformer 架构构建——这是一种基于“注意力”算法的深度学习架构。有三种类型的 Transformer：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Encoders&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;情感人类，识别文本中的实体，理解上下文提取答案&lt;/li&gt;
&lt;li&gt;代表模型：BERT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Decoders&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如文本生成，文本摘要，翻译，聊天机器人，代码生成&lt;/li&gt;
&lt;li&gt;代表模型：GPT，Llama&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encoder-decoders (Seq2Seq)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;处理序列到序列到问题&lt;/li&gt;
&lt;li&gt;代表模型：原始Transformer，T5， BART&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然，但是&lt;strong&gt;LLMs 通常是基于解码器的模型&lt;/strong&gt;，LLM 的基本原理简单而高效：其目标是根据先前Token的序列预测下一个Token。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Token&lt;/strong&gt;：LLM 处理文本的基本单元，可以是单词、子词或字符。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;：将文本分割成 Token 的过程，是 LLM 处理文本的第一步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Special tokens&lt;/strong&gt;：是语言模型词汇表中的预定义符号，用于指导模型的处理，而不是表示实际的词。例如：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;bos&amp;gt;&lt;/code&gt; (Beginning of Sequence)：表示序列的开始。用于指示模型开始生成文本。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; (End of Sequence)：表示序列的结束。用于指示模型停止生成文本。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; (Padding Token)：用于填充较短序列，以使所有输入序列具有相同的长度。这在批量处理数据时是必需的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;unk&amp;gt;&lt;/code&gt; (Unknown Token)：表示词汇表中不存在的词。当模型遇到词汇表外的词时，会用 &lt;code&gt;&amp;lt;unk&amp;gt;&lt;/code&gt; 替换它们。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;什么是-next-token-prediction&#34;&gt;什么是 next token prediction&lt;/h2&gt;
&lt;p&gt;LLMs 被认为具有自回归性，这意味着一次输出的内容成为下一次输入的内容。这个循环会持续进行，直到模型预测下一个标记是 &lt;code&gt;EOS&lt;/code&gt; 标记，此时模型可以停止。&lt;/p&gt;</description>
    </item>
    <item>
      <title>0.3.Thought Action Observation</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/agent/0.3.thought-action-observation/</link>
      <pubDate>Sun, 31 Aug 2025 12:13:25 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/agent/0.3.thought-action-observation/</guid>
      <description>&lt;h1 id=&#34;三步循环&#34;&gt;三步循环&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Thought-Action-Observation (TAO)&lt;/strong&gt; 是 AI Agent 的完整的工作流程。在许多 Agent 框架中，规则和指示是被直接&lt;strong&gt;嵌入到&lt;/strong&gt; System prompt 中的，确保每个循环都遵循定义的逻辑。就是说，在后端，输入给 LLM 的 prompt 总是会有一些预设的信息，比如，有哪些 Tools 可以使用，等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三步循环&lt;/strong&gt;中可以看出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代理会不断循环上述三步骤，直到目标较好地达成。&lt;/li&gt;
&lt;li&gt;第三步 Observation 其实是将上一部 Action 的结果拿到。在下一次循环中使用。&lt;/li&gt;
&lt;li&gt;动态适应：每个循环都允许代理将最新的信息（Observation 结果）&lt;strong&gt;纳入其推理&lt;/strong&gt;（Thought）中，从而确保最终的答案是信息充分且准确的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述循环称作 &lt;strong&gt;ReAct&lt;/strong&gt;（Resoning &amp;amp; Acting） cycle。&lt;/p&gt;
&lt;h1 id=&#34;thought&#34;&gt;Thought&lt;/h1&gt;
&lt;p&gt;ReAct 是一种简单的 Prompting 技术，在让 LLM 解码下一个标记之前，他会添加 “让我们一步一步地思考”。“一步一步地思考”会鼓励模型解码过程朝着&lt;strong&gt;生成计划而不是最终解决方案&lt;/strong&gt;的方向发展，因为模型被鼓励&lt;strong&gt;将问题分解为子任务&lt;/strong&gt;。分解成子步骤，就是 Deepseek R1 或 OpenAI 的 o1 这类模型背后的原理，它们被微调成 “在回答之前思考”。&lt;/p&gt;
&lt;p&gt;这些训练好的模型包含特定的思考部分（在&lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;和&lt;code&gt;&amp;lt;/think&amp;gt;&lt;/code&gt; special token 之间）。这不仅仅是一种像 ReAct 这样的提示技术，而是一种训练方法。&lt;/p&gt;
&lt;p&gt;这一步是由 LLM 完成的。&lt;/p&gt;
&lt;h2 id=&#34;kaqtao-cycle-和-react-的区别&#34;&gt;KAQ：TAO-cycle 和 ReAct 的区别&lt;/h2&gt;
&lt;p&gt;TAO 是一个更通用的概念，描述了 AI Agent 与环境交互的基本循环过程 。它强调了 Agent 需要思考、行动、并观察行动的结果，然后根据观察到的结果进行下一步的思考和行动。这是一个&lt;strong&gt;基础模型&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;ReAct 是一个更具体的框架，它在 TAO 循环的基础上，特别强调了推理 (Reasoning) 的重要性 。ReAct Agent 不仅仅是简单地思考和行动，而是会生成详细的推理轨迹，用于指导行动，并处理异常情况。这是个&lt;strong&gt;具体实现&lt;/strong&gt;。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
