<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>From Doc | Junhui&#39;s Journal 2</title>
<meta name="keywords" content="CUDA">
<meta name="description" content="https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions
阅读学习策略：
Doc 中内容太多，短时间内读不完，完全读完性价比太低。所以：

快速浏览，快速了解每一章大概内容。（TODO）
根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT）

CUDA 最新 doc
1. Introduction
核心包含三个关键抽象：

线程组层次结构
共享内存
屏障&amp;同步

2. Programming Model
内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。
程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（x &#43; y*Dx）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（x &#43; y*Dx &#43; z Dx*Dy）。
每个块中线程的数量是有限的，因为一个块中的所有线程都预期驻留在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在当前的 GPU 上，一个线程块可能包含多达 1024 个线程。
线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。
线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。__syncthreads(), 此外，Cooperative Groups API 还提供了一套丰富的线程同步原语。
在一个 Block 内，为了高效协作，Shared Memory 位于每个处理器核心附近（类似于 L1 缓存），并且 __syncthreads() 相对是轻量级的。
Thread Block Clusters（TBC）：
计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为线程块集群，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 cudaOccupancyMaxPotentialClusterSize API 进行查询。gridDim 变量仍然表示线程块的数量，以保持兼容性。">
<meta name="author" content="">
<link rel="canonical" href="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/">
<link crossorigin="anonymous" href="/blog-2-hugo/assets/css/stylesheet.bdaf5941cb3c05e36e857d9e2953ba0c4485ba7bc2da15db169d66a77cbc7a87.css" integrity="sha256-va9ZQcs8BeNuhX2eKVO6DESFunvC2hXbFp1mp3y8eoc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ashburnLee.github.io/blog-2-hugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ashburnLee.github.io/blog-2-hugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ashburnLee.github.io/blog-2-hugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ashburnLee.github.io/blog-2-hugo/apple-touch-icon.png">
<link rel="mask-icon" href="https://ashburnLee.github.io/blog-2-hugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" id="MathJax-script" async></script>


<meta property="og:url" content="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/">
  <meta property="og:site_name" content="Junhui&#39;s Journal 2">
  <meta property="og:title" content="From Doc">
  <meta property="og:description" content="https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions
阅读学习策略：
Doc 中内容太多，短时间内读不完，完全读完性价比太低。所以：
快速浏览，快速了解每一章大概内容。（TODO） 根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT） CUDA 最新 doc 1. Introduction 核心包含三个关键抽象：
线程组层次结构 共享内存 屏障&amp;同步 2. Programming Model 内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。
程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（x &#43; y*Dx）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（x &#43; y*Dx &#43; z Dx*Dy）。
每个块中线程的数量是有限的，因为一个块中的所有线程都预期驻留在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在当前的 GPU 上，一个线程块可能包含多达 1024 个线程。
线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。
线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。__syncthreads(), 此外，Cooperative Groups API 还提供了一套丰富的线程同步原语。
在一个 Block 内，为了高效协作，Shared Memory 位于每个处理器核心附近（类似于 L1 缓存），并且 __syncthreads() 相对是轻量级的。
Thread Block Clusters（TBC）： 计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为线程块集群，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 cudaOccupancyMaxPotentialClusterSize API 进行查询。gridDim 变量仍然表示线程块的数量，以保持兼容性。">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="cuda-notes">
    <meta property="article:published_time" content="2025-08-31T12:45:50+08:00">
    <meta property="article:modified_time" content="2025-08-31T12:45:50+08:00">
    <meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="From Doc">
<meta name="twitter:description" content="https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions
阅读学习策略：
Doc 中内容太多，短时间内读不完，完全读完性价比太低。所以：

快速浏览，快速了解每一章大概内容。（TODO）
根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT）

CUDA 最新 doc
1. Introduction
核心包含三个关键抽象：

线程组层次结构
共享内存
屏障&amp;同步

2. Programming Model
内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。
程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（x &#43; y*Dx）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（x &#43; y*Dx &#43; z Dx*Dy）。
每个块中线程的数量是有限的，因为一个块中的所有线程都预期驻留在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在当前的 GPU 上，一个线程块可能包含多达 1024 个线程。
线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。
线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。__syncthreads(), 此外，Cooperative Groups API 还提供了一套丰富的线程同步原语。
在一个 Block 内，为了高效协作，Shared Memory 位于每个处理器核心附近（类似于 L1 缓存），并且 __syncthreads() 相对是轻量级的。
Thread Block Clusters（TBC）：
计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为线程块集群，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 cudaOccupancyMaxPotentialClusterSize API 进行查询。gridDim 变量仍然表示线程块的数量，以保持兼容性。">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "CUDA Notes",
      "item": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "From Doc",
      "item": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "From Doc",
  "name": "From Doc",
  "description": "https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions\n阅读学习策略：\nDoc 中内容太多，短时间内读不完，完全读完性价比太低。所以：\n快速浏览，快速了解每一章大概内容。（TODO） 根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT） CUDA 最新 doc 1. Introduction 核心包含三个关键抽象：\n线程组层次结构 共享内存 屏障\u0026amp;同步 2. Programming Model 内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。\n程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（x + y*Dx）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（x + y*Dx + z Dx*Dy）。\n每个块中线程的数量是有限的，因为一个块中的所有线程都预期驻留在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在当前的 GPU 上，一个线程块可能包含多达 1024 个线程。\n线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。\n线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。__syncthreads(), 此外，Cooperative Groups API 还提供了一套丰富的线程同步原语。\n在一个 Block 内，为了高效协作，Shared Memory 位于每个处理器核心附近（类似于 L1 缓存），并且 __syncthreads() 相对是轻量级的。\nThread Block Clusters（TBC）： 计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为线程块集群，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 cudaOccupancyMaxPotentialClusterSize API 进行查询。gridDim 变量仍然表示线程块的数量，以保持兼容性。\n",
  "keywords": [
    "CUDA"
  ],
  "articleBody": "https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions\n阅读学习策略：\nDoc 中内容太多，短时间内读不完，完全读完性价比太低。所以：\n快速浏览，快速了解每一章大概内容。（TODO） 根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT） CUDA 最新 doc 1. Introduction 核心包含三个关键抽象：\n线程组层次结构 共享内存 屏障\u0026同步 2. Programming Model 内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。\n程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（x + y*Dx）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（x + y*Dx + z Dx*Dy）。\n每个块中线程的数量是有限的，因为一个块中的所有线程都预期驻留在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在当前的 GPU 上，一个线程块可能包含多达 1024 个线程。\n线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。\n线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。__syncthreads(), 此外，Cooperative Groups API 还提供了一套丰富的线程同步原语。\n在一个 Block 内，为了高效协作，Shared Memory 位于每个处理器核心附近（类似于 L1 缓存），并且 __syncthreads() 相对是轻量级的。\nThread Block Clusters（TBC）： 计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为线程块集群，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 cudaOccupancyMaxPotentialClusterSize API 进行查询。gridDim 变量仍然表示线程块的数量，以保持兼容性。\n在内核中，可以通过编译时内核属性使用 __cluster_dims__(X,Y,Z) 或者使用 CUDA 内核启动 API cudaLaunchKernelEx 来启用线程块集群。\n前者在 launch kernel 时，需要给出\u003c\u003c\u003c \u003e\u003e\u003e 给出线程配置。无法更改 cluster 的配置。 后者在运行时决定 cluster 配置，然后通过调用 cudaLaunchKernelEx，启动kernel。 9.0 计算能力的 GPU 中，集群中的所有线程块都保证在单个 GPU 处理集群（GPC？）上协同调度，并允许集群中的线程块使用 Cluster Group API cluster.sync() 进行硬件支持的同步。集群组还提供了成员函数，分别使用 num_threads() 和 num_blocks() API 查询集群组的大小。\n线程块属于同一集群时，可以访问分布式共享内存（Distributed Shared Memory, DSM），仅适用于 Hopper 架构。\n存储层次结构： 有4个层次，见图：\nhttps://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/memory-hierarchy.png\nTBC中有多个线程块，每个线程块有自己的Shared Memory。多个线程块自己的Shared Memory是独立的。这些Shared Memory 一同构成了 分布式共享内存。\nHeterogeneous Programming host 串行 + Device 并行。这里提到 Unified Memory？\nAsynchronous SIMT Programming Model NVIDIA Ampere GPU 架构的设备开始，CUDA 编程模型通过异步编程模型 为内存操作提供加速。\n异步编程模型定义了 Asynchronous Barrier？，用于 CUDA 线程之间的同步。The model also explains and defines how cuda::memcpy_async can be used to move data asynchronously from global memory while computing in the GPU.\nCompute Capability SM 版本表达了计算能力\n设备具有相同的重大版本号，则属于相同的核心架构:\n基于 Hopper GPU 架构的设备的重大版本号为 9， 基于 Ampere GPU 架构的设备的重大版本号为 8， Turing 是基于 Volta 的升级版，其 SM 版本是7.5 基于 Volta 架构的设备的重大版本号为 7， 基于 Pascal 架构的设备的重大版本号为 6， 基于 Maxwell 架构的设备的重大版本号为 5， 基于 Kepler 架构的设备的重大版本号为 3。 3. 编程接口 它包含了对 C++ 语言的少量扩展 \u0026 一个运行时库。\n核心 c++ 语言扩展已在编程模型中引入。它们允许程序员将内核定义为 C++ 函数，并在每次调用该函数时使用一些新的语法来指定网格和块维度。所有扩展的完整描述可以在 C++语言扩展中找到。所有含有 C++ 扩展的文件都需要通过 nvcc 编译。 CUDA 运行时在 CUDA 运行时库中引入。它提供了在主机上执行的 C 和 C++ 函数，用于分配和释放设备内存、在主机内存和设备内存之间传输数据、管理多设备系统等。 使用 nvcc 编译 内核可以使用 CUDA 指令集架构编写，该架构称为 PTX。但，通常使用 CUDA C++ 更有效（编译器会将 CUDA C++ 转换为 PTX 中间表示）。在这两种情况下，内核都必须通过 nvcc 编译成二进制代码，\n这一节解释了 nvcc 作为一个编译器驱动程序 的工作。包括\n离线编译 即时编译 二进制兼容性：二进制代码是针对特定架构的。使用编译器选项 -code 生成 cubin 对象，该选项指定了目标架构：例如，使用 -code=sm_80 编译将生成适用于计算能力 8.0 的设备的二进制代码。 PTX 兼容性：某些 PTX 指令仅支持更高计算能力的设备。例如，Warp Shuffle 函数仅支持计算能力 5.0 及以上的设备。 -arch 编译器选项指定了将 C++编译为 PTX 代码时假设的计算能力。因此，包含 warp shuffle 的代码必须使用 -arch=compute_50 （或更高版本）进行编译。 runtime library【包含了很多重点】 运行时由 cudart 库实现，该库与应用程序链接. 就是这个文件了：libcudart.so\n",
  "wordCount" : "293",
  "inLanguage": "en",
  "datePublished": "2025-08-31T12:45:50+08:00",
  "dateModified": "2025-08-31T12:45:50+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/from-doc/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Junhui's Journal 2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ashburnLee.github.io/blog-2-hugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ashburnLee.github.io/blog-2-hugo/" accesskey="h" title="Junhui&#39;s Journal 2 (Alt + H)">Junhui&#39;s Journal 2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      From Doc
    </h1>
    <div class="post-meta"><span title='2025-08-31 12:45:50 +0800 CST'>August 31, 2025</span>

</div>
  </header> 
  <div class="post-content"><p><a href="https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions">https://docs.nvidia.com/cuda/archive/12.0.1/cuda-c-programming-guide/#warp-matrix-functions</a></p>
<p>阅读学习策略：</p>
<p>Doc 中内容太多，短时间内读不完，完全读完性价比太低。所以：</p>
<ol>
<li>快速浏览，快速了解每一章大概内容。（TODO）</li>
<li>根据各个框架中的 Op 中 CUDA 实际实现和场景，选择 doc 中的重点内容理解。（NEW DOIT）</li>
</ol>
<h2 id="cuda-最新-doc">CUDA 最新 doc<a hidden class="anchor" aria-hidden="true" href="#cuda-最新-doc">#</a></h2>
<h3 id="1-introduction">1. Introduction<a hidden class="anchor" aria-hidden="true" href="#1-introduction">#</a></h3>
<p>核心包含三个关键抽象：</p>
<ul>
<li>线程组层次结构</li>
<li>共享内存</li>
<li>屏障&amp;同步</li>
</ul>
<h3 id="2-programming-model">2. Programming Model<a hidden class="anchor" aria-hidden="true" href="#2-programming-model">#</a></h3>
<p>内核函数在被调用时，将由 N 个不同的 CUDA 线程并行执行 N 次。</p>
<p>程索引与其线程 ID 之间的关系非常直接：对于一维块，它们是相同的；对于大小为（Dx，Dy）的二维块，索引为（x，y）的线程的线程 ID 是（<code>x + y*Dx</code>）；对于大小为（Dx，Dy，Dz）的三维块，索引为（x，y，z）的线程的线程 ID 是（<code>x + y*Dx + z Dx*Dy</code>）。</p>
<p>每个块中线程的数量是有限的，因为一个块中的所有线程都预期<strong>驻留</strong>在同一个流式多处理器核心上，并且必须共享该核心有限的内存资源。在<strong>当前的 GPU 上，一个线程块可能包含多达 1024 个线程</strong>。</p>
<p>线程块必须能够独立执行。这意味着，如果一个线程块中的所有线程都执行相同的代码，那么它们将按照相同的顺序执行该代码。</p>
<p>线程块内的线程可以通过共享内存和同步执行来协作，以协调内存访问。<code>__syncthreads()</code>, 此外，<code>Cooperative Groups API</code> 还提供了一套丰富的线程同步原语。</p>
<p>在一个 Block 内，为了高效协作，<strong>Shared Memory</strong> 位于每个处理器核心附近（类似于 L1 缓存），并且 <code>__syncthreads()</code> 相对是轻量级的。</p>
<h4 id="thread-block-clusterstbc">Thread Block Clusters（TBC）：<a hidden class="anchor" aria-hidden="true" href="#thread-block-clusterstbc">#</a></h4>
<p>计算能力 9.0 中，CUDA 编程模型引入了一个可选的层次结构，称为<strong>线程块集群</strong>，它由线程块组成（类似之前的 Grid）。大小由架构决定，可以使用 <code>cudaOccupancyMaxPotentialClusterSize</code> API 进行查询。<code>gridDim</code> 变量仍然表示线程块的数量，以保持兼容性。</p>
<p>在内核中，可以通过<strong>编译时</strong>内核属性使用 <code>__cluster_dims__(X,Y,Z)</code> 或者使用 CUDA 内核启动 API <code>cudaLaunchKernelEx</code> 来启用线程块集群。</p>
<ul>
<li>前者在 launch kernel 时，需要给出<code>&lt;&lt;&lt; &gt;&gt;&gt;</code> 给出线程配置。无法更改 cluster 的配置。</li>
<li>后者在运行时决定 cluster 配置，然后通过调用 <code>cudaLaunchKernelEx</code>，启动kernel。</li>
</ul>
<p>9.0 计算能力的 GPU 中，集群中的所有线程块都保证在单个 GPU 处理集群（<strong>GPC</strong>？）上协同调度，并允许集群中的线程块使用 Cluster Group API <code>cluster.sync()</code> 进行硬件支持的同步。集群组还提供了成员函数，分别使用 <code>num_threads()</code> 和 <code>num_blocks()</code> API 查询集群组的大小。</p>
<p>线程块属于同一集群时，可以访问<strong>分布式共享内存（Distributed Shared Memory, DSM）</strong>，仅适用于 Hopper 架构。</p>
<h4 id="存储层次结构">存储层次结构：<a hidden class="anchor" aria-hidden="true" href="#存储层次结构">#</a></h4>
<p>有4个层次，见图：</p>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/memory-hierarchy.png">https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/memory-hierarchy.png</a></p>
<p>TBC中有多个线程块，每个线程块有自己的Shared Memory。多个线程块自己的Shared Memory是独立的。这些Shared Memory 一同构成了 <strong>分布式共享内存</strong>。</p>
<h4 id="heterogeneous-programming">Heterogeneous Programming<a hidden class="anchor" aria-hidden="true" href="#heterogeneous-programming">#</a></h4>
<p>host 串行 + Device 并行。这里提到 <strong>Unified Memory</strong>？</p>
<h4 id="asynchronous-simt-programming-model">Asynchronous SIMT Programming Model<a hidden class="anchor" aria-hidden="true" href="#asynchronous-simt-programming-model">#</a></h4>
<p>NVIDIA Ampere GPU 架构的设备开始，CUDA 编程模型通过<strong>异步编程模型</strong> 为内存操作提供加速。</p>
<p><strong>异步编程模型</strong>定义了 Asynchronous Barrier？，用于 CUDA 线程之间的同步。The model also explains and defines how <code>cuda::memcpy_async</code> can be used to move data asynchronously from global memory while computing in the GPU.</p>
<h4 id="compute-capability">Compute Capability<a hidden class="anchor" aria-hidden="true" href="#compute-capability">#</a></h4>
<p>SM 版本表达了计算能力</p>
<p>设备具有相同的重大版本号，则属于相同的核心架构:</p>
<ul>
<li>基于 Hopper GPU 架构的设备的重大版本号为 9，</li>
<li>基于 Ampere GPU 架构的设备的重大版本号为 8，</li>
<li>
<pre><code>Turing 是基于 Volta 的升级版，其 SM 版本是7.5
</code></pre>
</li>
<li>基于 Volta 架构的设备的重大版本号为 7，</li>
<li>基于 Pascal 架构的设备的重大版本号为 6，</li>
<li>基于 Maxwell 架构的设备的重大版本号为 5，</li>
<li>基于 Kepler 架构的设备的重大版本号为 3。</li>
</ul>
<h3 id="3-编程接口">3. 编程接口<a hidden class="anchor" aria-hidden="true" href="#3-编程接口">#</a></h3>
<p>它包含了对 C++ 语言的少量扩展 &amp; 一个运行时库。</p>
<ul>
<li>核心 c++ 语言扩展已在编程模型中引入。它们允许程序员将内核定义为 C++ 函数，并在每次调用该函数时使用一些新的语法来指定网格和块维度。所有扩展的完整描述可以在 C++语言扩展中找到。所有含有 C++ 扩展的文件都需要通过 nvcc 编译。</li>
<li>CUDA 运行时在 CUDA 运行时库中引入。它提供了在主机上执行的 C 和 C++ 函数，用于分配和释放设备内存、在主机内存和设备内存之间传输数据、管理多设备系统等。</li>
</ul>
<h4 id="使用-nvcc-编译">使用 nvcc 编译<a hidden class="anchor" aria-hidden="true" href="#使用-nvcc-编译">#</a></h4>
<p>内核可以使用 CUDA 指令集架构编写，该架构称为 PTX。但，通常使用 CUDA C++ 更有效（编译器会将 CUDA C++ 转换为 PTX 中间表示）。在这两种情况下，内核都必须通过 nvcc 编译成二进制代码，</p>
<p>这一节解释了 nvcc 作为一个编译器驱动程序 的工作。包括</p>
<ul>
<li>离线编译</li>
<li>即时编译</li>
<li>二进制兼容性：二进制代码是针对特定架构的。使用编译器选项 <code>-code</code> 生成 cubin 对象，该选项指定了目标架构：例如，使用<code> -code=sm_80</code> 编译将生成适用于计算能力 8.0 的设备的二进制代码。</li>
<li>PTX 兼容性：某些 PTX 指令仅支持更高计算能力的设备。例如，<strong>Warp Shuffle</strong> 函数仅支持计算能力 5.0 及以上的设备。 <code>-arch</code> 编译器选项指定了将 C++编译为 PTX 代码时假设的计算能力。因此，包含 warp shuffle 的代码必须使用 <code>-arch=compute_50</code> （或更高版本）进行编译。</li>
</ul>
<h4 id="runtime-library包含了很多重点">runtime library【包含了很多重点】<a hidden class="anchor" aria-hidden="true" href="#runtime-library包含了很多重点">#</a></h4>
<p>运行时由 cudart 库实现，该库与应用程序链接. 就是这个文件了：<code>libcudart.so</code></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/cuda/">CUDA</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://ashburnLee.github.io/blog-2-hugo/">Junhui&#39;s Journal 2</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
