<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Kernel-写kernel | Junhui&#39;s Journal 2</title>
<meta name="keywords" content="CUDA">
<meta name="description" content="线程配置配置 最佳实战


当前的 GPU 上，一个 block 可能包含多达 1024 个线程。


如果每个 block 的 thread 数量为 [64/128/256/512]，那么 CUDA 性能会更好。因为 Warp 大小是 32


并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。


激活线程数是 SM * 2


硬件信息：SM 数， GetComputeCapability， GetMaxThreadsPerBlock, GetMaxPhysicalThreadCount


需要激活的线程总数 active threads。


得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置


通常是把经验配置作为配置的起点，作为 baseline，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。
Again，在 Profiling 时，收集关键性能指标：

资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。
并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。
吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。
带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。
功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。
延迟 (Latency): kernel 的执行时间。

上述可以通过 Nsight Compute 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。">
<meta name="author" content="">
<link rel="canonical" href="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/">
<link crossorigin="anonymous" href="/blog-2-hugo/assets/css/stylesheet.bdaf5941cb3c05e36e857d9e2953ba0c4485ba7bc2da15db169d66a77cbc7a87.css" integrity="sha256-va9ZQcs8BeNuhX2eKVO6DESFunvC2hXbFp1mp3y8eoc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ashburnLee.github.io/blog-2-hugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ashburnLee.github.io/blog-2-hugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ashburnLee.github.io/blog-2-hugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ashburnLee.github.io/blog-2-hugo/apple-touch-icon.png">
<link rel="mask-icon" href="https://ashburnLee.github.io/blog-2-hugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" id="MathJax-script" async></script>


<meta property="og:url" content="https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/">
  <meta property="og:site_name" content="Junhui&#39;s Journal 2">
  <meta property="og:title" content="Kernel-写kernel">
  <meta property="og:description" content="线程配置配置 最佳实战 当前的 GPU 上，一个 block 可能包含多达 1024 个线程。
如果每个 block 的 thread 数量为 [64/128/256/512]，那么 CUDA 性能会更好。因为 Warp 大小是 32
并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。
激活线程数是 SM * 2
硬件信息：SM 数， GetComputeCapability， GetMaxThreadsPerBlock, GetMaxPhysicalThreadCount
需要激活的线程总数 active threads。
得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置
通常是把经验配置作为配置的起点，作为 baseline，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。
Again，在 Profiling 时，收集关键性能指标：
资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。 并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。 吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。 带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。 功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。 延迟 (Latency): kernel 的执行时间。 上述可以通过 Nsight Compute 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="cuda-notes">
    <meta property="article:published_time" content="2025-08-31T12:45:51+08:00">
    <meta property="article:modified_time" content="2025-08-31T12:45:51+08:00">
    <meta property="article:tag" content="CUDA">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kernel-写kernel">
<meta name="twitter:description" content="线程配置配置 最佳实战


当前的 GPU 上，一个 block 可能包含多达 1024 个线程。


如果每个 block 的 thread 数量为 [64/128/256/512]，那么 CUDA 性能会更好。因为 Warp 大小是 32


并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。


激活线程数是 SM * 2


硬件信息：SM 数， GetComputeCapability， GetMaxThreadsPerBlock, GetMaxPhysicalThreadCount


需要激活的线程总数 active threads。


得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置


通常是把经验配置作为配置的起点，作为 baseline，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。
Again，在 Profiling 时，收集关键性能指标：

资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。
并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。
吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。
带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。
功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。
延迟 (Latency): kernel 的执行时间。

上述可以通过 Nsight Compute 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "CUDA Notes",
      "item": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Kernel-写kernel",
      "item": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kernel-写kernel",
  "name": "Kernel-写kernel",
  "description": "线程配置配置 最佳实战 当前的 GPU 上，一个 block 可能包含多达 1024 个线程。\n如果每个 block 的 thread 数量为 [64/128/256/512]，那么 CUDA 性能会更好。因为 Warp 大小是 32\n并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。\n激活线程数是 SM * 2\n硬件信息：SM 数， GetComputeCapability， GetMaxThreadsPerBlock, GetMaxPhysicalThreadCount\n需要激活的线程总数 active threads。\n得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置\n通常是把经验配置作为配置的起点，作为 baseline，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。\nAgain，在 Profiling 时，收集关键性能指标：\n资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。 并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。 吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。 带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。 功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。 延迟 (Latency): kernel 的执行时间。 上述可以通过 Nsight Compute 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。\n",
  "keywords": [
    "CUDA"
  ],
  "articleBody": "线程配置配置 最佳实战 当前的 GPU 上，一个 block 可能包含多达 1024 个线程。\n如果每个 block 的 thread 数量为 [64/128/256/512]，那么 CUDA 性能会更好。因为 Warp 大小是 32\n并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。\n激活线程数是 SM * 2\n硬件信息：SM 数， GetComputeCapability， GetMaxThreadsPerBlock, GetMaxPhysicalThreadCount\n需要激活的线程总数 active threads。\n得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置\n通常是把经验配置作为配置的起点，作为 baseline，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。\nAgain，在 Profiling 时，收集关键性能指标：\n资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。 并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。 吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。 带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。 功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。 延迟 (Latency): kernel 的执行时间。 上述可以通过 Nsight Compute 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。\nActive block/thread 一个 “active block” 是指当前正在 SM 上执行的线程块。“active threads” 是指当前正在执行的线程。 Active block 的数量直接影响 GPU 的占用率 (occupancy)。 较高的 active block 数量通常意味着更高的 GPU 占用率和更好的性能。\n驻留 VS 活跃 maxThreadsPerMultiprocessor 限制的是驻留线程数，实际的活跃线程数会更少。\n驻留表示线程已经获得了资源，但没有在执行。驻留线程可以有以下状态：\nActive：正在执行指令。 Ready：准备好了指令，等待 Warp 调度器分配资源。 Blocked：等待其他某件事情发生。 驻留线程的数量影响 GPU 的占用率 (occupancy)。 活跃线程的数量影响 GPU 的利用率 (utilization)。 优化 CUDA 程序的目标之一是最大化占用率和利用率。\n有了配置如何执行 kernel，grid-stride-loop func\u003c\u003c\u003c4, 8\u003e\u003e\u003e()：配置启动 32个 threads， 每一个线程执行一个 func() 的副本。唯一不同的是每一个 thread 的 ID 。也就是每一个线程有唯一的 ID ，那么线程的 ID 需要更新吗？看情况：\n给出更新线程ID 的方法：\nint id = threadIdx.x + blockDim.x * blockIdx.x; while(id \u003c N){ // TODO excute operation id += blockDIm.x * gridDim.x; // ID 更新的步长是总线程数 } 其中 while() 判断当前 thread 的 id 需要更新多少次。\n1. 不需要更新的情况：就是线程配置能够覆盖所有数据： 对于 «\u003c1, 2048»\u003e 的 kernel，处理 2024 个数据（N=2024）。假如其中一个 thread 的起始 id 为 0，干完活后，判断 0＜2024，所以这个 thread 的 id 会被跟新为 2048，此时再判断 2048＜2024，返回 false，这个 thread 的工作结束。thread 的 id 未被更新。\n当一个CUDA grid 能够一次性处理所有输入数据时，这种 kernel 被称为 monolithic kernel\n2. 需要更新的情况：线程配置中的线程数小于数据个数： 比如 «\u003c1, 512»\u003e 的 kernel config，处理 2024 个数据（N=2024）\n仍假如有一个 thread 是起始 id 为 0，判断 0＜2024 ，执行操作。所以跟新 id 为 512； 判断 512＜2024，执行操作，再更新 id 为 1024； 判断 1024＜2024，执行操作，再更新 id 为 1536； 判断 1536＜2024，执行操作，再更新 id 为 2048； 判断 2048＜2024，返回false。该 thread 的工作结束。 关于更新ID， 注意：\n不管你的数据是一维的二维的还是更高维度的，在 GPU 端，高维被扁平化，都将被看成一维的，所以没有必要在 Device 上开辟一个二维数组。 CUDA code 需要你并行地思考：Think parallel. 当你在写 CUDA code， 实际上你是在为一个 thread 写串行 code，而每一个 thread 都执行这个段相同的串行 code 。唯一区别是每个线程的 ID 各不相同 可以这样理解，对于简单问题，把 CPU code 的 for 循环去掉，其实就得到了 GPU code。每个 thread 有自己唯一的 ID，其他都一样。 线程配置和 kernel 实现 CUDA kernel 函数的编写主要取决于你的算法，而线程配置则决定了如何将线程映射到数据上以及如何管理线程间的协作。 所以不同的线程配置（网格维度 gridDim 和块维度 blockDim）不会改变 kernel 函数的编写方式本身，但会影响你如何使用 threadIdx 和 blockIdx 等内置变量来访问数据和控制线程行为。\n高效的内存访问是 CUDA 编程的关键，而 threadIdx 和 blockIdx 变量是实现这一目标的核心。\nGlobal 内存访问在多个线程同时访问连续内存块时效率最高。 这意味着，如果你的线程块中的线程以某种方式访问内存，使得每个线程访问的内存地址在内存中是连续的，那么你就能实现合并内存访问。\nsoftmax kernel (last axis) 配置设计 给出 input，dims，axis，计算是 softmax，根据什么得到 kernel 的配置？\n输入参数：\n维度：dims = {n=32, c=4, h=256, w=256} 轴：axis = 3（w 维度） dim_size：w = 256（softmax 归一化的维度大小） outer_size：外层维度大小，n * c * h = 32 * 4 * 256 = 32,768\nKernel 配置设计原则： warp：线程分配应尽量对齐 warp 大小32，避免线程浪费。\nblock：数通常为 32 的倍数。最大是1024（from device property）。\n占用率\u0026并行性：确保 SM 上驻留多个block，充分并行一个SM 并行性分配：softmax 的并行性主要来自 outer_size（32,768 个独立的 softmax 计算）和 dim_size（每个 softmax 的 256 个元素）。outer 和 dim_size 是解耦的，独立并行。 外层并行：将 outer_size 分配到多个线程块或 warp； 内层并行：将 dim_size 分配到线程或 warp 内的协作。 合并内存访问：连续线程访问连续内存，对于softmax，w 维度的访问应尽量连续。 合并访问是指一个 warp（32 个线程）在一次内存事务中访问连续的内存地址，从而最大化全局内存带宽利用率。 要确定内存访问是否合并，我们需要验证每个 warp（32 个线程）的访问模式。当 threadIdx.x 从 0 到 31 递增，地址 w_idx = threadIdx.x 也从 0 到 31 递增。故是合并访问。 内存事务大小：访问的数据量匹配 GPU 内存事务（通常 32、64 或 128 字节） 一致性：warp 内线程的访问模式一致，无分支导致的分散访问。 内存对齐：访问的起始地址应对齐到 128 字节（32 个 float）。input 数组由 cudaMalloc 分配，基地址通常是 128 字节对齐的。\n规约优化:使用共享内存或 warp shuffle 指令可以加速归约。\n配置 Kernel 配置 确定线程块大小 选择一个合适的 block 大小，既能高效处理 dim_size=256 的归约，又能支持 outer_size=32,768 的并行性。 dim_size = 256 表示每个 softmax 需要处理 256 个元素。但一个 warp（32 线程）不足以覆盖 256 个元素，所以可以一个 warp 通过循环8次处理 256 个元素。或者多个线程协作: dim3 threads(32, 4, 1) 且 每个 warp（threadIdx.y）处理一个 softmax，网格大小：(32,768 + 4 - 1) / 4 = 8,192。\n选择 256 个线程，与 dim_size 一致，每个线程对应一个元素。【如何做256 个元素的reduce？】并且 256 线程（8 个 warp）可以高效利用 SM，提供足够的并行性。所以得到了： threads_per_block = 256。\n确定线程块内的线程组织 将 256 个线程组织为 dim3 threads(x, y, z)，以高效映射到数据。故配置 dim3 threads(256, 1, 1)：线程id和元素一一对应，适合逐元素操作。归约操作（max, sum）可以通过线程块内的协作完成（例如共享内存或 warp shuffle）\n直接用一维线程索引更简单，避免复杂索引计算。所以得到：dim3 threads(256, 1, 1)。\n确定网格大小 目标：分配足够的线程块以覆盖 outer_size = 32,768 个 softmax 计算。\n假设每个线程块处理 1 个 softmax（256 线程正好覆盖 w=256），需要 outer_size = 32,768 个线程块。所以网格大小为 dim3 blocks(32,768, 1, 1)。\n或者，每个线程块处理多个 softmax（例如 4 个）：配置 dim3 threads(256, 4, 1)，每个 threadIdx.y 对应一个 softmax。每个线程块处理 4 个 softmax，网格大小为 (32,768 + 4 - 1) / 4 = 8,192。\n选择 dim3 blocks(32,768, 1, 1) 原因：32768 没有超过硬件限制，blockIdx.x 直接映射到外层索引 i。\n数据到线程的映射 为什么这样配置 kernel 高效：规约256 线程适合树形归约（每次折半），配合共享内存或 warp shuffle 加速。 合并访问：线程按 w 维度连续访问数据，保证内存访问合并。 并行性: block 内部并行；block 之间并行 替代配置 配置 dim3 threads(32, 4, 1)，\n优点：更低的寄存器压力，可能提高占用率。 缺点：需要更多线程块，增加调度开销。 ",
  "wordCount" : "579",
  "inLanguage": "en",
  "datePublished": "2025-08-31T12:45:51+08:00",
  "dateModified": "2025-08-31T12:45:51+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%86%99kernel%E7%9A%84%E5%A5%97%E8%B7%AF/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Junhui's Journal 2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ashburnLee.github.io/blog-2-hugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ashburnLee.github.io/blog-2-hugo/" accesskey="h" title="Junhui&#39;s Journal 2 (Alt + H)">Junhui&#39;s Journal 2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Kernel-写kernel
    </h1>
    <div class="post-meta"><span title='2025-08-31 12:45:51 +0800 CST'>August 31, 2025</span>

</div>
  </header> 
  <div class="post-content"><h2 id="线程配置配置-最佳实战">线程配置配置 最佳实战<a hidden class="anchor" aria-hidden="true" href="#线程配置配置-最佳实战">#</a></h2>
<ul>
<li>
<p>当前的 GPU 上，一个 block 可能包含多达 1024 个线程。</p>
</li>
<li>
<p>如果每个 block 的 thread 数量为 <code>[64/128/256/512]</code>，那么 CUDA 性能会更好。因为 Warp 大小是 32</p>
</li>
<li>
<p>并且 block 数量应该比 SM 的数量多（至少是2到4倍）。因此，要考虑流 SM 的数量，以确定每个块正确的线程数量。</p>
</li>
<li>
<p>激活线程数是 <code>SM * 2</code></p>
</li>
<li>
<p>硬件信息：SM 数， <code>GetComputeCapability</code>， <code>GetMaxThreadsPerBlock</code>, <code>GetMaxPhysicalThreadCount</code></p>
</li>
<li>
<p>需要激活的线程总数 active threads。</p>
</li>
<li>
<p>得到配置：1.获取硬件信息。2.估计线程数。3.计算block数。4.创建配置</p>
</li>
</ul>
<p><strong>通常是把经验配置作为配置的起点，作为 baseline</strong>，分析资源占用率，并行程度，吞吐，带宽，甚至功耗，然后通过 Profiling 工具在此基础上进行优化。</p>
<p>Again，在 Profiling 时，收集关键性能指标：</p>
<ul>
<li>资源占用率 (Occupancy)： GPU 的计算资源利用率，越高越好。</li>
<li>并行程度： 活跃线程块和 warp 的数量，反映了程序的并行性。</li>
<li>吞吐量 (Throughput)： 单位时间内处理的数据量，例如每秒处理的元素数量。</li>
<li>带宽 (Bandwidth)： 内存读写速度，包括全局内存、共享内存和常量内存。</li>
<li>功耗 (Power Consumption)： GPU 的功耗，在某些情况下需要考虑。</li>
<li>延迟 (Latency): kernel 的执行时间。</li>
</ul>
<p>上述可以通过 <strong>Nsight Compute</strong> 获得。除此之外还有其他工具可以用来分析 CUDA 程序的性能：CUDA API，CUDA 提供的一些环境变量。</p>
<h2 id="active-blockthread">Active block/thread<a hidden class="anchor" aria-hidden="true" href="#active-blockthread">#</a></h2>
<p>一个 &ldquo;active block&rdquo; 是指<strong>当前正在</strong> SM 上执行的线程块。&ldquo;active threads&rdquo; 是指<strong>当前正在</strong>执行的线程。
Active block 的数量直接影响 GPU 的占用率 (occupancy)。 较高的 active block 数量通常意味着更高的 GPU 占用率和更好的性能。</p>
<h2 id="驻留-vs-活跃">驻留 VS 活跃<a hidden class="anchor" aria-hidden="true" href="#驻留-vs-活跃">#</a></h2>
<p><code>maxThreadsPerMultiprocessor</code> 限制的是驻留线程数，实际的活跃线程数会更少。</p>
<p>驻留表示线程已经获得了资源，但没有在执行。驻留线程可以有以下状态：</p>
<ol>
<li>Active：正在执行指令。</li>
<li>Ready：准备好了指令，等待 Warp 调度器分配资源。</li>
<li>Blocked：等待其他某件事情发生。</li>
</ol>
<p><strong>驻留线程的数量影响 GPU 的占用率 (occupancy)</strong>。 <strong>活跃线程的数量影响 GPU 的利用率 (utilization)</strong>。 优化 CUDA 程序的目标之一是最大化占用率和利用率。</p>
<h2 id="有了配置如何执行-kernelgrid-stride-loop">有了配置如何执行 kernel，<code>grid-stride-loop</code><a hidden class="anchor" aria-hidden="true" href="#有了配置如何执行-kernelgrid-stride-loop">#</a></h2>
<p><code>func&lt;&lt;&lt;4, 8&gt;&gt;&gt;()</code>：配置启动 32个 threads， 每一个线程执行一个 <code>func()</code> 的副本。唯一不同的是每一个 thread 的 ID 。也就是每一个线程有唯一的 ID ，那么线程的 ID 需要更新吗？看情况：</p>
<p>给出更新线程ID 的方法：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> id <span style="color:#f92672">=</span> threadIdx.x <span style="color:#f92672">+</span> blockDim.x <span style="color:#f92672">*</span> blockIdx.x;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span>(id <span style="color:#f92672">&lt;</span> N){
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// TODO excute operation
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    id <span style="color:#f92672">+=</span> blockDIm.x <span style="color:#f92672">*</span> gridDim.x;  <span style="color:#75715e">// ID 更新的步长是总线程数
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>其中 <code>while()</code> 判断当前 thread 的 id 需要更新多少次。</p>
<h3 id="1-不需要更新的情况就是线程配置能够覆盖所有数据">1. 不需要更新的情况：就是线程配置能够覆盖所有数据：<a hidden class="anchor" aria-hidden="true" href="#1-不需要更新的情况就是线程配置能够覆盖所有数据">#</a></h3>
<p>对于 &laquo;&lt;1, 2048&raquo;&gt; 的 kernel，处理 2024 个数据（N=2024）。假如其中一个 thread 的起始 id 为 0，干完活后，判断 0＜2024，所以这个 thread 的 id 会被跟新为 2048，此时再判断 2048＜2024，返回 false，这个 thread 的工作结束。thread 的 id 未被更新。</p>
<p>当一个CUDA grid 能够一次性处理所有输入数据时，这种 kernel 被称为 <code>monolithic kernel</code></p>
<h3 id="2-需要更新的情况线程配置中的线程数小于数据个数">2. 需要更新的情况：线程配置中的线程数小于数据个数：<a hidden class="anchor" aria-hidden="true" href="#2-需要更新的情况线程配置中的线程数小于数据个数">#</a></h3>
<p>比如 &laquo;&lt;1, 512&raquo;&gt; 的 kernel config，处理 2024 个数据（N=2024）</p>
<ul>
<li>仍假如有一个 thread 是起始 id 为 0，判断 0＜2024 ，执行操作。所以跟新 id 为 512；</li>
<li>判断 512＜2024，执行操作，再更新 id 为 1024；</li>
<li>判断 1024＜2024，执行操作，再更新 id 为 1536；</li>
<li>判断 1536＜2024，执行操作，再更新 id 为 2048；</li>
<li>判断 2048＜2024，返回false。该 thread 的工作结束。</li>
</ul>
<p>关于更新ID， 注意：</p>
<ul>
<li>不管你的数据是一维的二维的还是更高维度的，<strong>在 GPU 端，高维被扁平化，都将被看成一维的</strong>，所以没有必要在 Device 上开辟一个二维数组。</li>
<li>CUDA code 需要你<strong>并行地思考</strong>：Think parallel.</li>
<li>当你在写 CUDA code， 实际上你是在<strong>为一个 thread 写串行 code</strong>，而每一个 thread 都执行这个段相同的串行 code 。唯一区别是每个线程的 ID 各不相同</li>
<li>可以这样理解，对于简单问题，把 CPU code 的 for 循环去掉，其实就得到了 GPU code。每个 thread 有自己唯一的 ID，其他都一样。</li>
</ul>
<h2 id="线程配置和-kernel-实现">线程配置和 kernel 实现<a hidden class="anchor" aria-hidden="true" href="#线程配置和-kernel-实现">#</a></h2>
<p>CUDA kernel 函数的编写主要取决于你的算法，而线程配置则决定了如何将线程映射到数据上以及如何管理线程间的协作。 <strong>所以不同的线程配置（网格维度 gridDim 和块维度 blockDim）不会改变 kernel 函数的编写方式本身，但会影响你如何使用 threadIdx 和 blockIdx 等内置变量来访问数据和控制线程行为</strong>。</p>
<p>高效的内存访问是 CUDA 编程的关键，而 <code>threadIdx</code> 和 <code>blockIdx</code> 变量是实现这一目标的核心。</p>
<p><strong>Global 内存访问在多个线程同时访问连续内存块</strong>时效率最高。 这意味着，如果你的线程块中的线程以某种方式访问内存，使得每个线程访问的内存地址在内存中是连续的，那么你就能实现合并内存访问。</p>
<h1 id="softmax-kernel-last-axis-配置设计">softmax kernel (last axis) 配置设计<a hidden class="anchor" aria-hidden="true" href="#softmax-kernel-last-axis-配置设计">#</a></h1>
<p>给出 input，dims，axis，计算是 softmax，根据什么得到 kernel 的配置？</p>
<p>输入参数：</p>
<p>维度：dims = {n=32, c=4, h=256, w=256}
轴：axis = 3（w 维度）
dim_size：w = 256（softmax 归一化的维度大小）
outer_size：外层维度大小，n * c * h = 32 * 4 * 256 = 32,768</p>
<h2 id="kernel-配置设计原则">Kernel 配置设计原则：<a hidden class="anchor" aria-hidden="true" href="#kernel-配置设计原则">#</a></h2>
<ol>
<li>
<p>warp：线程分配应尽量对齐 warp 大小32，避免线程浪费。</p>
</li>
<li>
<p>block：数通常为 32 的倍数。最大是1024（from device property）。</p>
</li>
</ol>
<ul>
<li>占用率&amp;并行性：确保 SM 上驻留多个block，充分并行一个SM</li>
</ul>
<ol start="3">
<li>并行性分配：softmax 的并行性主要来自 <code>outer_size</code>（32,768 个独立的 softmax 计算）和 <code>dim_size</code>（每个 softmax 的 256 个元素）。<code>outer</code> 和 <code>dim_size</code> 是<strong>解耦的，独立并行</strong>。</li>
</ol>
<ul>
<li>外层并行：将 <code>outer_size</code> 分配到多个线程块或 warp；</li>
<li>内层并行：将 <code>dim_size</code> 分配到线程或 warp 内的协作。</li>
</ul>
<ol start="4">
<li>合并内存访问：连续线程访问连续内存，对于softmax，w 维度的访问应尽量连续。</li>
</ol>
<ul>
<li>合并访问是指一个 warp（32 个线程）在一次内存事务中访问<strong>连续的内存地址</strong>，从而最大化全局内存带宽利用率。</li>
<li>要确定内存访问是否合并，我们需要<strong>验证</strong>每个 warp（32 个线程）的访问模式。当 threadIdx.x 从 0 到 31 递增，地址<code> w_idx = threadIdx.x</code> 也从 0 到 31 递增。故是合并访问。</li>
<li>内存事务大小：访问的数据量匹配 GPU 内存事务（通常 32、64 或 128 字节）</li>
<li>一致性：warp 内线程的访问模式一致，无分支导致的分散访问。</li>
</ul>
<ol start="5">
<li>
<p>内存对齐：访问的起始地址应对齐到 128 字节（32 个 float）。input 数组由 <code>cudaMalloc</code> 分配，基地址通常是 128 字节对齐的。</p>
</li>
<li>
<p>规约优化:使用共享内存或 <code>warp shuffle</code> 指令可以加速归约。</p>
</li>
</ol>
<h2 id="配置-kernel-配置">配置 Kernel 配置<a hidden class="anchor" aria-hidden="true" href="#配置-kernel-配置">#</a></h2>
<ol>
<li>确定线程块大小</li>
</ol>
<p>选择一个合适的 block 大小，既能高效处理 dim_size=256 的归约，又能支持 outer_size=32,768 的并行性。
<strong>dim_size = 256 表示每个 softmax 需要处理 256 个元素</strong>。但一个 warp（32 线程）不足以覆盖 256 个元素，所以可以一个 warp 通过循环8次处理 256 个元素。或者多个线程协作: <code>dim3 threads(32, 4, 1)</code> 且 每个 <code>warp（threadIdx.y）</code>处理一个 softmax，网格大小：(32,768 + 4 - 1) / 4 = 8,192。</p>
<p>选择 256 个线程，与 dim_size 一致，每个线程对应一个元素。【如何做256 个元素的reduce？】并且 256 线程（<strong>8 个 warp</strong>）可以高效利用 SM，提供足够的并行性。所以得到了： <code>threads_per_block = 256</code>。</p>
<ol start="2">
<li>确定线程块内的线程组织</li>
</ol>
<p>将 256 个线程组织为 <code>dim3 threads(x, y, z)</code>，以高效映射到数据。故配置 <code>dim3 threads(256, 1, 1)</code>：线程id和元素一一对应，适合逐元素操作。归约操作（max, sum）可以通过线程块内的协作完成（例如<strong>共享内存</strong>或 <strong>warp shuffle</strong>）</p>
<p>直接用一维线程索引更简单，避免复杂索引计算。所以得到：<code>dim3 threads(256, 1, 1)</code>。</p>
<ol start="3">
<li>确定网格大小</li>
</ol>
<p>目标：分配足够的线程块以覆盖 <code>outer_size = 32,768</code> 个 softmax 计算。</p>
<p>假设每个线程块处理 1 个 softmax（256 线程正好覆盖 w=256），需要 <code>outer_size = 32,768</code> 个线程块。所以网格大小为 <code>dim3 blocks(32,768, 1, 1)</code>。</p>
<p>或者，每个线程块处理多个 softmax（例如 4 个）：配置 <code>dim3 threads(256, 4, 1)</code>，每个 <code>threadIdx.y</code> 对应一个 softmax。每个线程块处理 4 个 softmax，网格大小为 <code>(32,768 + 4 - 1) / 4 = 8,192</code>。</p>
<p>选择 <code>dim3 blocks(32,768, 1, 1)</code> 原因：32768 没有超过硬件限制，<code>blockIdx.x</code> 直接映射到外层索引 <code>i</code>。</p>
<ol start="4">
<li>数据到线程的映射</li>
</ol>
<h2 id="为什么这样配置-kernel">为什么这样配置 kernel<a hidden class="anchor" aria-hidden="true" href="#为什么这样配置-kernel">#</a></h2>
<ul>
<li>高效：规约256 线程适合树形归约（每次折半），配合共享内存或 warp shuffle 加速。</li>
<li>合并访问：线程按 w 维度连续访问数据，保证内存访问合并。</li>
<li>并行性: block 内部并行；block 之间并行</li>
</ul>
<h2 id="替代配置">替代配置<a hidden class="anchor" aria-hidden="true" href="#替代配置">#</a></h2>
<p>配置 dim3 threads(32, 4, 1)，</p>
<ul>
<li>优点：更低的寄存器压力，可能提高占用率。</li>
<li>缺点：需要更多线程块，增加调度开销。</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/cuda/">CUDA</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://ashburnLee.github.io/blog-2-hugo/">Junhui&#39;s Journal 2</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
