<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>2.2.LlamaIndex中使用Agents | Junhui&#39;s Journal 2</title>
<meta name="keywords" content="Agent, LlamaIndex, Multi-agent System, RAG">
<meta name="description" content="LlamaIndex 支持的 Agents


Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。


ReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。


Advanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction


初始化 Agents
!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q
使用 AgentWorkflow 初始化一个 Agent。
# 登陆使用serverless API
from huggingface_hub import login
login()

from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI
from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream


def add(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Add two numbers&#34;&#34;&#34;
    return a &#43; b


def subtract(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Subtract two numbers&#34;&#34;&#34;
    return a - b


def multiply(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Multiply two numbers&#34;&#34;&#34;
    return a * b


def divide(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Divide two numbers&#34;&#34;&#34;
    return a / b


llm = HuggingFaceInferenceAPI(model_name=&#34;Qwen/Qwen2.5-Coder-32B-Instruct&#34;)

agent = AgentWorkflow.from_tools_or_functions(
    tools_or_functions=[subtract, multiply, divide, add],
    llm=llm,
    system_prompt=&#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.&#34;,
)
然后就可以执行推理了：">
<meta name="author" content="">
<link rel="canonical" href="https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/">
<link crossorigin="anonymous" href="/blog-2-hugo/assets/css/stylesheet.bdaf5941cb3c05e36e857d9e2953ba0c4485ba7bc2da15db169d66a77cbc7a87.css" integrity="sha256-va9ZQcs8BeNuhX2eKVO6DESFunvC2hXbFp1mp3y8eoc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ashburnLee.github.io/blog-2-hugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ashburnLee.github.io/blog-2-hugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ashburnLee.github.io/blog-2-hugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ashburnLee.github.io/blog-2-hugo/apple-touch-icon.png">
<link rel="mask-icon" href="https://ashburnLee.github.io/blog-2-hugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" id="MathJax-script" async></script>


<meta property="og:url" content="https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/">
  <meta property="og:site_name" content="Junhui&#39;s Journal 2">
  <meta property="og:title" content="2.2.LlamaIndex中使用Agents">
  <meta property="og:description" content="LlamaIndex 支持的 Agents Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。
ReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。
Advanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction
初始化 Agents !pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q 使用 AgentWorkflow 初始化一个 Agent。
# 登陆使用serverless API from huggingface_hub import login login() from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream def add(a: int, b: int) -&gt; int: &#34;&#34;&#34;Add two numbers&#34;&#34;&#34; return a &#43; b def subtract(a: int, b: int) -&gt; int: &#34;&#34;&#34;Subtract two numbers&#34;&#34;&#34; return a - b def multiply(a: int, b: int) -&gt; int: &#34;&#34;&#34;Multiply two numbers&#34;&#34;&#34; return a * b def divide(a: int, b: int) -&gt; int: &#34;&#34;&#34;Divide two numbers&#34;&#34;&#34; return a / b llm = HuggingFaceInferenceAPI(model_name=&#34;Qwen/Qwen2.5-Coder-32B-Instruct&#34;) agent = AgentWorkflow.from_tools_or_functions( tools_or_functions=[subtract, multiply, divide, add], llm=llm, system_prompt=&#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.&#34;, ) 然后就可以执行推理了：">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="agent">
    <meta property="article:published_time" content="2025-08-31T12:14:13+08:00">
    <meta property="article:modified_time" content="2025-08-31T12:14:13+08:00">
    <meta property="article:tag" content="Agent">
    <meta property="article:tag" content="LlamaIndex">
    <meta property="article:tag" content="Multi-Agent System">
    <meta property="article:tag" content="RAG">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2.2.LlamaIndex中使用Agents">
<meta name="twitter:description" content="LlamaIndex 支持的 Agents


Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。


ReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。


Advanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction


初始化 Agents
!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q
使用 AgentWorkflow 初始化一个 Agent。
# 登陆使用serverless API
from huggingface_hub import login
login()

from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI
from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream


def add(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Add two numbers&#34;&#34;&#34;
    return a &#43; b


def subtract(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Subtract two numbers&#34;&#34;&#34;
    return a - b


def multiply(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Multiply two numbers&#34;&#34;&#34;
    return a * b


def divide(a: int, b: int) -&gt; int:
    &#34;&#34;&#34;Divide two numbers&#34;&#34;&#34;
    return a / b


llm = HuggingFaceInferenceAPI(model_name=&#34;Qwen/Qwen2.5-Coder-32B-Instruct&#34;)

agent = AgentWorkflow.from_tools_or_functions(
    tools_or_functions=[subtract, multiply, divide, add],
    llm=llm,
    system_prompt=&#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.&#34;,
)
然后就可以执行推理了：">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Agent",
      "item": "https://ashburnLee.github.io/blog-2-hugo/agent/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "2.2.LlamaIndex中使用Agents",
      "item": "https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2.2.LlamaIndex中使用Agents",
  "name": "2.2.LlamaIndex中使用Agents",
  "description": "LlamaIndex 支持的 Agents Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。\nReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。\nAdvanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction\n初始化 Agents !pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q 使用 AgentWorkflow 初始化一个 Agent。\n# 登陆使用serverless API from huggingface_hub import login login() from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream def add(a: int, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;Add two numbers\u0026#34;\u0026#34;\u0026#34; return a + b def subtract(a: int, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;Subtract two numbers\u0026#34;\u0026#34;\u0026#34; return a - b def multiply(a: int, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;Multiply two numbers\u0026#34;\u0026#34;\u0026#34; return a * b def divide(a: int, b: int) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34;Divide two numbers\u0026#34;\u0026#34;\u0026#34; return a / b llm = HuggingFaceInferenceAPI(model_name=\u0026#34;Qwen/Qwen2.5-Coder-32B-Instruct\u0026#34;) agent = AgentWorkflow.from_tools_or_functions( tools_or_functions=[subtract, multiply, divide, add], llm=llm, system_prompt=\u0026#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\u0026#34;, ) 然后就可以执行推理了：\n",
  "keywords": [
    "Agent", "LlamaIndex", "Multi-agent System", "RAG"
  ],
  "articleBody": "LlamaIndex 支持的 Agents Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。\nReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。\nAdvanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction\n初始化 Agents !pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q 使用 AgentWorkflow 初始化一个 Agent。\n# 登陆使用serverless API from huggingface_hub import login login() from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream def add(a: int, b: int) -\u003e int: \"\"\"Add two numbers\"\"\" return a + b def subtract(a: int, b: int) -\u003e int: \"\"\"Subtract two numbers\"\"\" return a - b def multiply(a: int, b: int) -\u003e int: \"\"\"Multiply two numbers\"\"\" return a * b def divide(a: int, b: int) -\u003e int: \"\"\"Divide two numbers\"\"\" return a / b llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\") agent = AgentWorkflow.from_tools_or_functions( tools_or_functions=[subtract, multiply, divide, add], llm=llm, system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\", ) 然后就可以执行推理了：\nhandler = agent.run(\"What is (2 + 2) * 2?\") async for ev in handler.stream_events(): if isinstance(ev, ToolCallResult): print(\"\") print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=\u003e\", ev.tool_output) elif isinstance(ev, AgentStream): # showing the thought process print(ev.delta, end=\"\", flush=True) resp = await handler resp 记住上下文的 Agents 默认情况下的 Agent 是 stateless 的，没有上下文的，通过 Context 可以让 Agent 记住上下文。\nfrom llama_index.core.workflow import Context ctx = Context(agent) response = await agent.run(\"My name is Bob.\", ctx=ctx) response = await agent.run(\"What was my name again?\", ctx=ctx) response LlamaIndex 中的代理是异步的，因为它们使用了 Python 的 await 操作符。\n使用 QueryEngineTools 创建 RAG 代理 import chromadb from llama_index.core import VectorStoreIndex from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI from llama_index.embeddings.huggingface import HuggingFaceEmbedding from llama_index.core.tools import QueryEngineTool from llama_index.vector_stores.chroma import ChromaVectorStore # Create a vector store db = chromadb.PersistentClient(path=\"./alfred_chroma_db\") chroma_collection = db.get_or_create_collection(\"alfred\") vector_store = ChromaVectorStore(chroma_collection=chroma_collection) # Create a query engine embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\") llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\") index = VectorStoreIndex.from_vector_store( vector_store=vector_store, embed_model=embed_model ) query_engine = index.as_query_engine(llm=llm) query_engine_tool = QueryEngineTool.from_defaults( query_engine=query_engine, name=\"personas\", description=\"descriptions for various types of personas\", return_direct=False, ) # Create a RAG agent query_engine_agent = AgentWorkflow.from_tools_or_functions( tools_or_functions=[query_engine_tool], llm=llm, system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \", ) 展示思考和推理过程：\nhandler = query_engine_agent.run( \"Search the database for 'science fiction' and return some persona descriptions.\" ) async for ev in handler.stream_events(): if isinstance(ev, ToolCallResult): print(\"\") print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=\u003e\", ev.tool_output) elif isinstance(ev, AgentStream): # showing the thought process print(ev.delta, end=\"\", flush=True) resp = await handler resp 创建 Multi-agent systems AgentWorkflow 类也直接支持多智能体系统。通过给每个智能体一个名称和描述，系统维护一个单一的活动说话者，每个智能体都有能力将任务交接给另一个智能体。\n通过缩小每个智能体的作用范围，我们可以帮助提高它们在响应用户消息时的总体准确性。\nLlamaIndex 中的智能体也可以直接用作其他智能体的工具:\nfrom llama_index.core.agent.workflow import ( AgentWorkflow, ReActAgent, ) # Define some tools def add(a: int, b: int) -\u003e int: \"\"\"Add two numbers.\"\"\" return a + b def subtract(a: int, b: int) -\u003e int: \"\"\"Subtract two numbers.\"\"\" return a - b # Create agent configs # NOTE: we can use FunctionAgent or ReActAgent here. # FunctionAgent works for LLMs with a function calling API. # ReActAgent works for any LLM. calculator_agent = ReActAgent( name=\"calculator\", description=\"Performs basic arithmetic operations\", system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\", tools=[add, subtract], # 将agent 用作tool llm=llm, ) query_agent = ReActAgent( name=\"info_lookup\", description=\"Looks up information about XYZ\", system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\", tools=[query_engine_tool], # 将agent 用作tool llm=llm, ) # Create and run the workflow agent = AgentWorkflow(agents=[calculator_agent, query_agent], root_agent=\"calculator\") # Run the system handler = agent.run(user_msg=\"Can you add 5 and 3?\") # 展示思考和推理过程： async for ev in handler.stream_events(): if isinstance(ev, ToolCallResult): print(\"\") print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=\u003e\", ev.tool_output) elif isinstance(ev, AgentStream): # showing the thought process print(ev.delta, end=\"\", flush=True) resp = await handler resp ",
  "wordCount" : "560",
  "inLanguage": "en",
  "datePublished": "2025-08-31T12:14:13+08:00",
  "dateModified": "2025-08-31T12:14:13+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ashburnLee.github.io/blog-2-hugo/agent/2.2.llamaindex%E4%B8%AD%E4%BD%BF%E7%94%A8agents/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Junhui's Journal 2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ashburnLee.github.io/blog-2-hugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ashburnLee.github.io/blog-2-hugo/" accesskey="h" title="Junhui&#39;s Journal 2 (Alt + H)">Junhui&#39;s Journal 2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      2.2.LlamaIndex中使用Agents
    </h1>
    <div class="post-meta"><span title='2025-08-31 12:14:13 +0800 CST'>August 31, 2025</span>

</div>
  </header> 
  <div class="post-content"><h2 id="llamaindex-支持的-agents">LlamaIndex 支持的 Agents<a hidden class="anchor" aria-hidden="true" href="#llamaindex-支持的-agents">#</a></h2>
<ul>
<li>
<p>Function Calling Agents - 这些适用于可以调用特定功能的 AI 模型。</p>
</li>
<li>
<p>ReAct Agents - 这些可以与任何进行聊天或文本端点的 AI 配合使用，并处理复杂的推理任务。</p>
</li>
<li>
<p>Advanced Custom Agents - 这些使用更复杂的方法来处理更复杂的任务和工作流程。比如 LLMCompiler 或 Chain-of-abstraction</p>
</li>
</ul>
<h2 id="初始化-agents">初始化 Agents<a hidden class="anchor" aria-hidden="true" href="#初始化-agents">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q
</span></span></code></pre></div><p>使用 <code>AgentWorkflow</code> 初始化一个 Agent。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#75715e"># 登陆使用serverless API</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> huggingface_hub <span style="color:#f92672">import</span> login
</span></span><span style="display:flex;"><span>login()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.llms.huggingface_api <span style="color:#f92672">import</span> HuggingFaceInferenceAPI
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.core.agent.workflow <span style="color:#f92672">import</span> AgentWorkflow, ToolCallResult, AgentStream
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Add two numbers&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">+</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">subtract</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Subtract two numbers&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">-</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">multiply</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Multiply two numbers&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">*</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">divide</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Divide two numbers&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">/</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> HuggingFaceInferenceAPI(model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Qwen/Qwen2.5-Coder-32B-Instruct&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>agent <span style="color:#f92672">=</span> AgentWorkflow<span style="color:#f92672">.</span>from_tools_or_functions(
</span></span><span style="display:flex;"><span>    tools_or_functions<span style="color:#f92672">=</span>[subtract, multiply, divide, add],
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>    system_prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>然后就可以执行推理了：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>handler <span style="color:#f92672">=</span> agent<span style="color:#f92672">.</span>run(<span style="color:#e6db74">&#34;What is (2 + 2) * 2?&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">for</span> ev <span style="color:#f92672">in</span> handler<span style="color:#f92672">.</span>stream_events():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(ev, ToolCallResult):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Called tool: &#34;</span>, ev<span style="color:#f92672">.</span>tool_name, ev<span style="color:#f92672">.</span>tool_kwargs, <span style="color:#e6db74">&#34;=&gt;&#34;</span>, ev<span style="color:#f92672">.</span>tool_output)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(ev, AgentStream):  <span style="color:#75715e"># showing the thought process</span>
</span></span><span style="display:flex;"><span>        print(ev<span style="color:#f92672">.</span>delta, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>resp <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> handler
</span></span><span style="display:flex;"><span>resp
</span></span></code></pre></div><h2 id="记住上下文的-agents">记住上下文的 Agents<a hidden class="anchor" aria-hidden="true" href="#记住上下文的-agents">#</a></h2>
<p>默认情况下的 Agent 是 stateless 的，没有上下文的，通过 <code>Context</code> 可以<strong>让 Agent 记住上下文</strong>。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.core.workflow <span style="color:#f92672">import</span> Context
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ctx <span style="color:#f92672">=</span> Context(agent)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> agent<span style="color:#f92672">.</span>run(<span style="color:#e6db74">&#34;My name is Bob.&#34;</span>, ctx<span style="color:#f92672">=</span>ctx)
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> agent<span style="color:#f92672">.</span>run(<span style="color:#e6db74">&#34;What was my name again?&#34;</span>, ctx<span style="color:#f92672">=</span>ctx)
</span></span><span style="display:flex;"><span>response
</span></span></code></pre></div><p>LlamaIndex 中的<strong>代理是异步</strong>的，因为它们使用了 Python 的 await 操作符。</p>
<h2 id="使用-queryenginetools-创建-rag-代理">使用 QueryEngineTools 创建 RAG 代理<a hidden class="anchor" aria-hidden="true" href="#使用-queryenginetools-创建-rag-代理">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">import</span> chromadb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.core <span style="color:#f92672">import</span> VectorStoreIndex
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.llms.huggingface_api <span style="color:#f92672">import</span> HuggingFaceInferenceAPI
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.embeddings.huggingface <span style="color:#f92672">import</span> HuggingFaceEmbedding
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.core.tools <span style="color:#f92672">import</span> QueryEngineTool
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.vector_stores.chroma <span style="color:#f92672">import</span> ChromaVectorStore
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a vector store</span>
</span></span><span style="display:flex;"><span>db <span style="color:#f92672">=</span> chromadb<span style="color:#f92672">.</span>PersistentClient(path<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./alfred_chroma_db&#34;</span>)
</span></span><span style="display:flex;"><span>chroma_collection <span style="color:#f92672">=</span> db<span style="color:#f92672">.</span>get_or_create_collection(<span style="color:#e6db74">&#34;alfred&#34;</span>)
</span></span><span style="display:flex;"><span>vector_store <span style="color:#f92672">=</span> ChromaVectorStore(chroma_collection<span style="color:#f92672">=</span>chroma_collection)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a query engine</span>
</span></span><span style="display:flex;"><span>embed_model <span style="color:#f92672">=</span> HuggingFaceEmbedding(model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;BAAI/bge-small-en-v1.5&#34;</span>)
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> HuggingFaceInferenceAPI(model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Qwen/Qwen2.5-Coder-32B-Instruct&#34;</span>)
</span></span><span style="display:flex;"><span>index <span style="color:#f92672">=</span> VectorStoreIndex<span style="color:#f92672">.</span>from_vector_store(
</span></span><span style="display:flex;"><span>    vector_store<span style="color:#f92672">=</span>vector_store, embed_model<span style="color:#f92672">=</span>embed_model
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>query_engine <span style="color:#f92672">=</span> index<span style="color:#f92672">.</span>as_query_engine(llm<span style="color:#f92672">=</span>llm)
</span></span><span style="display:flex;"><span>query_engine_tool <span style="color:#f92672">=</span> QueryEngineTool<span style="color:#f92672">.</span>from_defaults(
</span></span><span style="display:flex;"><span>    query_engine<span style="color:#f92672">=</span>query_engine,
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;personas&#34;</span>,
</span></span><span style="display:flex;"><span>    description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;descriptions for various types of personas&#34;</span>,
</span></span><span style="display:flex;"><span>    return_direct<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create a RAG agent</span>
</span></span><span style="display:flex;"><span>query_engine_agent <span style="color:#f92672">=</span> AgentWorkflow<span style="color:#f92672">.</span>from_tools_or_functions(
</span></span><span style="display:flex;"><span>    tools_or_functions<span style="color:#f92672">=</span>[query_engine_tool],
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>    system_prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;You are a helpful assistant that has access to a database containing persona descriptions. &#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>展示思考和推理过程：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>handler <span style="color:#f92672">=</span> query_engine_agent<span style="color:#f92672">.</span>run(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Search the database for &#39;science fiction&#39; and return some persona descriptions.&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">for</span> ev <span style="color:#f92672">in</span> handler<span style="color:#f92672">.</span>stream_events():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(ev, ToolCallResult):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Called tool: &#34;</span>, ev<span style="color:#f92672">.</span>tool_name, ev<span style="color:#f92672">.</span>tool_kwargs, <span style="color:#e6db74">&#34;=&gt;&#34;</span>, ev<span style="color:#f92672">.</span>tool_output)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(ev, AgentStream):  <span style="color:#75715e"># showing the thought process</span>
</span></span><span style="display:flex;"><span>        print(ev<span style="color:#f92672">.</span>delta, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>resp <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> handler
</span></span><span style="display:flex;"><span>resp
</span></span></code></pre></div><h2 id="创建-multi-agent-systems">创建 Multi-agent systems<a hidden class="anchor" aria-hidden="true" href="#创建-multi-agent-systems">#</a></h2>
<p><code>AgentWorkflow</code> 类也直接支持多智能体系统。通过给每个智能体一个名称和描述，系统维护一个单一的活动说话者，每个智能体都有能力将任务交接给另一个智能体。</p>
<p>通过<strong>缩小每个智能体的作用范围</strong>，我们可以帮助提高它们在响应用户消息时的总体准确性。</p>
<p>LlamaIndex 中的智能体也可以直接用作其他智能体的工具:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> llama_index.core.agent.workflow <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    AgentWorkflow,
</span></span><span style="display:flex;"><span>    ReActAgent,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define some tools</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">add</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Add two numbers.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">+</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">subtract</span>(a: int, b: int) <span style="color:#f92672">-&gt;</span> int:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Subtract two numbers.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> a <span style="color:#f92672">-</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create agent configs</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># NOTE: we can use FunctionAgent or ReActAgent here.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># FunctionAgent works for LLMs with a function calling API.</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ReActAgent works for any LLM.</span>
</span></span><span style="display:flex;"><span>calculator_agent <span style="color:#f92672">=</span> ReActAgent(
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;calculator&#34;</span>,
</span></span><span style="display:flex;"><span>    description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Performs basic arithmetic operations&#34;</span>,
</span></span><span style="display:flex;"><span>    system_prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;You are a calculator assistant. Use your tools for any math operation.&#34;</span>,
</span></span><span style="display:flex;"><span>    tools<span style="color:#f92672">=</span>[add, subtract],  <span style="color:#75715e"># 将agent 用作tool</span>
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query_agent <span style="color:#f92672">=</span> ReActAgent(
</span></span><span style="display:flex;"><span>    name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;info_lookup&#34;</span>,
</span></span><span style="display:flex;"><span>    description<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Looks up information about XYZ&#34;</span>,
</span></span><span style="display:flex;"><span>    system_prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Use your tool to query a RAG system to answer information about XYZ&#34;</span>,
</span></span><span style="display:flex;"><span>    tools<span style="color:#f92672">=</span>[query_engine_tool],  <span style="color:#75715e"># 将agent 用作tool</span>
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create and run the workflow</span>
</span></span><span style="display:flex;"><span>agent <span style="color:#f92672">=</span> AgentWorkflow(agents<span style="color:#f92672">=</span>[calculator_agent, query_agent], root_agent<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;calculator&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run the system</span>
</span></span><span style="display:flex;"><span>handler <span style="color:#f92672">=</span> agent<span style="color:#f92672">.</span>run(user_msg<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Can you add 5 and 3?&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 展示思考和推理过程：</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">async</span> <span style="color:#66d9ef">for</span> ev <span style="color:#f92672">in</span> handler<span style="color:#f92672">.</span>stream_events():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> isinstance(ev, ToolCallResult):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Called tool: &#34;</span>, ev<span style="color:#f92672">.</span>tool_name, ev<span style="color:#f92672">.</span>tool_kwargs, <span style="color:#e6db74">&#34;=&gt;&#34;</span>, ev<span style="color:#f92672">.</span>tool_output)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">elif</span> isinstance(ev, AgentStream):  <span style="color:#75715e"># showing the thought process</span>
</span></span><span style="display:flex;"><span>        print(ev<span style="color:#f92672">.</span>delta, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>resp <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> handler
</span></span><span style="display:flex;"><span>resp
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/agent/">Agent</a></li>
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/llamaindex/">LlamaIndex</a></li>
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/multi-agent-system/">Multi-Agent System</a></li>
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/rag/">RAG</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://ashburnLee.github.io/blog-2-hugo/">Junhui&#39;s Journal 2</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
