<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>3.4.实例summarize_ocr_trans | Junhui&#39;s Journal 2</title>
<meta name="keywords" content="Agent, LangGraph">
<meta name="description" content="我的目标

有 call tools 能力的 LLM
有识别图片中文字的 LLM
有翻译功能（日-&gt;中）的 LLM

我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。
请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？
子任务一
识别图片中的日文，并将其翻译成中文
LangGraph 实现：
import os
from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional
from PIL import Image
import pytesseract
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# 定义状态
class AgentState(TypedDict):
    image_path: str
    prompt: str
    extracted_text: Optional[str]
    translated_text: Optional[str]
    output_file: str

# 节点1：OCR提取日文
def ocr_node(state: AgentState) -&gt; AgentState:
    try:
        image = Image.open(state[&#34;image_path&#34;])
        text = pytesseract.image_to_string(image, lang=&#39;jpn&#39;)
        state[&#34;extracted_text&#34;] = text.strip()
        return state
    except Exception as e:
        state[&#34;extracted_text&#34;] = f&#34;OCR错误: {str(e)}&#34;
        return state

# 节点2：翻译日文到中文
def translate_node(state: AgentState) -&gt; AgentState:
    if not state[&#34;extracted_text&#34;] or &#34;错误&#34; in state[&#34;extracted_text&#34;]:
        state[&#34;translated_text&#34;] = &#34;无法翻译: 无有效文本&#34;
        return state
    
    try:
        # 使用Hugging Face的翻译模型
        model_name = &#34;Helsinki-NLP/opus-mt-ja-zh&#34;
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        inputs = tokenizer(state[&#34;extracted_text&#34;], return_tensors=&#34;pt&#34;, padding=True)
        with torch.no_grad():
            outputs = model.generate(**inputs)
        translated = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        state[&#34;translated_text&#34;] = translated
        return state
    except Exception as e:
        state[&#34;translated_text&#34;] = f&#34;翻译错误: {str(e)}&#34;
        return state

# 节点3：写入文件
def write_to_file_node(state: AgentState) -&gt; AgentState:
    try:
        with open(state[&#34;output_file&#34;], &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
            f.write(state[&#34;translated_text&#34;] or &#34;无翻译结果&#34;)
        return state
    except Exception as e:
        state[&#34;translated_text&#34;] = f&#34;文件写入错误: {str(e)}&#34;
        return state

# 创建工作流
def create_workflow():
    workflow = StateGraph(AgentState)
    
    # 添加节点
    workflow.add_node(&#34;ocr&#34;, ocr_node)
    workflow.add_node(&#34;translate&#34;, translate_node)
    workflow.add_node(&#34;write_to_file&#34;, write_to_file_node)
    
    # 定义流程
    workflow.set_entry_point(&#34;ocr&#34;)
    workflow.add_edge(&#34;ocr&#34;, &#34;translate&#34;)
    workflow.add_edge(&#34;translate&#34;, &#34;write_to_file&#34;)
    workflow.add_edge(&#34;write_to_file&#34;, END)
    
    return workflow.compile()

# 主函数
def main(image_path: str, output_file: str = &#34;translated_output.txt&#34;):
    # 初始化状态
    state = AgentState(
        image_path=image_path,
        prompt=&#34;识别图片中的日文，并将其翻译成中文&#34;,
        extracted_text=None,
        translated_text=None,
        output_file=output_file
    )
    
    # 创建并运行工作流
    app = create_workflow()
    final_state = app.invoke(state)
    
    return final_state

if __name__ == &#34;__main__&#34;:
    # 示例用法
    image_path = &#34;path_to_your_image.jpg&#34;
    output_file = &#34;translated_output.txt&#34;
    result = main(image_path, output_file)
    print(f&#34;处理完成！翻译结果已保存至 {output_file}&#34;)
    print(f&#34;提取的日文: {result[&#39;extracted_text&#39;]}&#34;)
    print(f&#34;翻译的中文: {result[&#39;translated_text&#39;]}&#34;)
上述需求 LanChain 足够了 ，LangChain 实现：">
<meta name="author" content="">
<link rel="canonical" href="https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/">
<link crossorigin="anonymous" href="/blog-2-hugo/assets/css/stylesheet.bdaf5941cb3c05e36e857d9e2953ba0c4485ba7bc2da15db169d66a77cbc7a87.css" integrity="sha256-va9ZQcs8BeNuhX2eKVO6DESFunvC2hXbFp1mp3y8eoc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ashburnLee.github.io/blog-2-hugo/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ashburnLee.github.io/blog-2-hugo/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ashburnLee.github.io/blog-2-hugo/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ashburnLee.github.io/blog-2-hugo/apple-touch-icon.png">
<link rel="mask-icon" href="https://ashburnLee.github.io/blog-2-hugo/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" id="MathJax-script" async></script>


<meta property="og:url" content="https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/">
  <meta property="og:site_name" content="Junhui&#39;s Journal 2">
  <meta property="og:title" content="3.4.实例summarize_ocr_trans">
  <meta property="og:description" content="我的目标 有 call tools 能力的 LLM 有识别图片中文字的 LLM 有翻译功能（日-&gt;中）的 LLM 我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。
请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？
子任务一 识别图片中的日文，并将其翻译成中文
LangGraph 实现：
import os from langgraph.graph import StateGraph, END from typing import TypedDict, Optional from PIL import Image import pytesseract from transformers import AutoTokenizer, AutoModelForSeq2SeqLM import torch # 定义状态 class AgentState(TypedDict): image_path: str prompt: str extracted_text: Optional[str] translated_text: Optional[str] output_file: str # 节点1：OCR提取日文 def ocr_node(state: AgentState) -&gt; AgentState: try: image = Image.open(state[&#34;image_path&#34;]) text = pytesseract.image_to_string(image, lang=&#39;jpn&#39;) state[&#34;extracted_text&#34;] = text.strip() return state except Exception as e: state[&#34;extracted_text&#34;] = f&#34;OCR错误: {str(e)}&#34; return state # 节点2：翻译日文到中文 def translate_node(state: AgentState) -&gt; AgentState: if not state[&#34;extracted_text&#34;] or &#34;错误&#34; in state[&#34;extracted_text&#34;]: state[&#34;translated_text&#34;] = &#34;无法翻译: 无有效文本&#34; return state try: # 使用Hugging Face的翻译模型 model_name = &#34;Helsinki-NLP/opus-mt-ja-zh&#34; tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSeq2SeqLM.from_pretrained(model_name) inputs = tokenizer(state[&#34;extracted_text&#34;], return_tensors=&#34;pt&#34;, padding=True) with torch.no_grad(): outputs = model.generate(**inputs) translated = tokenizer.decode(outputs[0], skip_special_tokens=True) state[&#34;translated_text&#34;] = translated return state except Exception as e: state[&#34;translated_text&#34;] = f&#34;翻译错误: {str(e)}&#34; return state # 节点3：写入文件 def write_to_file_node(state: AgentState) -&gt; AgentState: try: with open(state[&#34;output_file&#34;], &#34;w&#34;, encoding=&#34;utf-8&#34;) as f: f.write(state[&#34;translated_text&#34;] or &#34;无翻译结果&#34;) return state except Exception as e: state[&#34;translated_text&#34;] = f&#34;文件写入错误: {str(e)}&#34; return state # 创建工作流 def create_workflow(): workflow = StateGraph(AgentState) # 添加节点 workflow.add_node(&#34;ocr&#34;, ocr_node) workflow.add_node(&#34;translate&#34;, translate_node) workflow.add_node(&#34;write_to_file&#34;, write_to_file_node) # 定义流程 workflow.set_entry_point(&#34;ocr&#34;) workflow.add_edge(&#34;ocr&#34;, &#34;translate&#34;) workflow.add_edge(&#34;translate&#34;, &#34;write_to_file&#34;) workflow.add_edge(&#34;write_to_file&#34;, END) return workflow.compile() # 主函数 def main(image_path: str, output_file: str = &#34;translated_output.txt&#34;): # 初始化状态 state = AgentState( image_path=image_path, prompt=&#34;识别图片中的日文，并将其翻译成中文&#34;, extracted_text=None, translated_text=None, output_file=output_file ) # 创建并运行工作流 app = create_workflow() final_state = app.invoke(state) return final_state if __name__ == &#34;__main__&#34;: # 示例用法 image_path = &#34;path_to_your_image.jpg&#34; output_file = &#34;translated_output.txt&#34; result = main(image_path, output_file) print(f&#34;处理完成！翻译结果已保存至 {output_file}&#34;) print(f&#34;提取的日文: {result[&#39;extracted_text&#39;]}&#34;) print(f&#34;翻译的中文: {result[&#39;translated_text&#39;]}&#34;) 上述需求 LanChain 足够了 ，LangChain 实现：">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="agent">
    <meta property="article:published_time" content="2025-08-31T12:13:32+08:00">
    <meta property="article:modified_time" content="2025-08-31T12:13:32+08:00">
    <meta property="article:tag" content="Agent">
    <meta property="article:tag" content="LangGraph">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3.4.实例summarize_ocr_trans">
<meta name="twitter:description" content="我的目标

有 call tools 能力的 LLM
有识别图片中文字的 LLM
有翻译功能（日-&gt;中）的 LLM

我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。
请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？
子任务一
识别图片中的日文，并将其翻译成中文
LangGraph 实现：
import os
from langgraph.graph import StateGraph, END
from typing import TypedDict, Optional
from PIL import Image
import pytesseract
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# 定义状态
class AgentState(TypedDict):
    image_path: str
    prompt: str
    extracted_text: Optional[str]
    translated_text: Optional[str]
    output_file: str

# 节点1：OCR提取日文
def ocr_node(state: AgentState) -&gt; AgentState:
    try:
        image = Image.open(state[&#34;image_path&#34;])
        text = pytesseract.image_to_string(image, lang=&#39;jpn&#39;)
        state[&#34;extracted_text&#34;] = text.strip()
        return state
    except Exception as e:
        state[&#34;extracted_text&#34;] = f&#34;OCR错误: {str(e)}&#34;
        return state

# 节点2：翻译日文到中文
def translate_node(state: AgentState) -&gt; AgentState:
    if not state[&#34;extracted_text&#34;] or &#34;错误&#34; in state[&#34;extracted_text&#34;]:
        state[&#34;translated_text&#34;] = &#34;无法翻译: 无有效文本&#34;
        return state
    
    try:
        # 使用Hugging Face的翻译模型
        model_name = &#34;Helsinki-NLP/opus-mt-ja-zh&#34;
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
        
        inputs = tokenizer(state[&#34;extracted_text&#34;], return_tensors=&#34;pt&#34;, padding=True)
        with torch.no_grad():
            outputs = model.generate(**inputs)
        translated = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        state[&#34;translated_text&#34;] = translated
        return state
    except Exception as e:
        state[&#34;translated_text&#34;] = f&#34;翻译错误: {str(e)}&#34;
        return state

# 节点3：写入文件
def write_to_file_node(state: AgentState) -&gt; AgentState:
    try:
        with open(state[&#34;output_file&#34;], &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
            f.write(state[&#34;translated_text&#34;] or &#34;无翻译结果&#34;)
        return state
    except Exception as e:
        state[&#34;translated_text&#34;] = f&#34;文件写入错误: {str(e)}&#34;
        return state

# 创建工作流
def create_workflow():
    workflow = StateGraph(AgentState)
    
    # 添加节点
    workflow.add_node(&#34;ocr&#34;, ocr_node)
    workflow.add_node(&#34;translate&#34;, translate_node)
    workflow.add_node(&#34;write_to_file&#34;, write_to_file_node)
    
    # 定义流程
    workflow.set_entry_point(&#34;ocr&#34;)
    workflow.add_edge(&#34;ocr&#34;, &#34;translate&#34;)
    workflow.add_edge(&#34;translate&#34;, &#34;write_to_file&#34;)
    workflow.add_edge(&#34;write_to_file&#34;, END)
    
    return workflow.compile()

# 主函数
def main(image_path: str, output_file: str = &#34;translated_output.txt&#34;):
    # 初始化状态
    state = AgentState(
        image_path=image_path,
        prompt=&#34;识别图片中的日文，并将其翻译成中文&#34;,
        extracted_text=None,
        translated_text=None,
        output_file=output_file
    )
    
    # 创建并运行工作流
    app = create_workflow()
    final_state = app.invoke(state)
    
    return final_state

if __name__ == &#34;__main__&#34;:
    # 示例用法
    image_path = &#34;path_to_your_image.jpg&#34;
    output_file = &#34;translated_output.txt&#34;
    result = main(image_path, output_file)
    print(f&#34;处理完成！翻译结果已保存至 {output_file}&#34;)
    print(f&#34;提取的日文: {result[&#39;extracted_text&#39;]}&#34;)
    print(f&#34;翻译的中文: {result[&#39;translated_text&#39;]}&#34;)
上述需求 LanChain 足够了 ，LangChain 实现：">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Agent",
      "item": "https://ashburnLee.github.io/blog-2-hugo/agent/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "3.4.实例summarize_ocr_trans",
      "item": "https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "3.4.实例summarize_ocr_trans",
  "name": "3.4.实例summarize_ocr_trans",
  "description": "我的目标 有 call tools 能力的 LLM 有识别图片中文字的 LLM 有翻译功能（日-\u0026gt;中）的 LLM 我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。\n请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？\n子任务一 识别图片中的日文，并将其翻译成中文\nLangGraph 实现：\nimport os from langgraph.graph import StateGraph, END from typing import TypedDict, Optional from PIL import Image import pytesseract from transformers import AutoTokenizer, AutoModelForSeq2SeqLM import torch # 定义状态 class AgentState(TypedDict): image_path: str prompt: str extracted_text: Optional[str] translated_text: Optional[str] output_file: str # 节点1：OCR提取日文 def ocr_node(state: AgentState) -\u0026gt; AgentState: try: image = Image.open(state[\u0026#34;image_path\u0026#34;]) text = pytesseract.image_to_string(image, lang=\u0026#39;jpn\u0026#39;) state[\u0026#34;extracted_text\u0026#34;] = text.strip() return state except Exception as e: state[\u0026#34;extracted_text\u0026#34;] = f\u0026#34;OCR错误: {str(e)}\u0026#34; return state # 节点2：翻译日文到中文 def translate_node(state: AgentState) -\u0026gt; AgentState: if not state[\u0026#34;extracted_text\u0026#34;] or \u0026#34;错误\u0026#34; in state[\u0026#34;extracted_text\u0026#34;]: state[\u0026#34;translated_text\u0026#34;] = \u0026#34;无法翻译: 无有效文本\u0026#34; return state try: # 使用Hugging Face的翻译模型 model_name = \u0026#34;Helsinki-NLP/opus-mt-ja-zh\u0026#34; tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSeq2SeqLM.from_pretrained(model_name) inputs = tokenizer(state[\u0026#34;extracted_text\u0026#34;], return_tensors=\u0026#34;pt\u0026#34;, padding=True) with torch.no_grad(): outputs = model.generate(**inputs) translated = tokenizer.decode(outputs[0], skip_special_tokens=True) state[\u0026#34;translated_text\u0026#34;] = translated return state except Exception as e: state[\u0026#34;translated_text\u0026#34;] = f\u0026#34;翻译错误: {str(e)}\u0026#34; return state # 节点3：写入文件 def write_to_file_node(state: AgentState) -\u0026gt; AgentState: try: with open(state[\u0026#34;output_file\u0026#34;], \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(state[\u0026#34;translated_text\u0026#34;] or \u0026#34;无翻译结果\u0026#34;) return state except Exception as e: state[\u0026#34;translated_text\u0026#34;] = f\u0026#34;文件写入错误: {str(e)}\u0026#34; return state # 创建工作流 def create_workflow(): workflow = StateGraph(AgentState) # 添加节点 workflow.add_node(\u0026#34;ocr\u0026#34;, ocr_node) workflow.add_node(\u0026#34;translate\u0026#34;, translate_node) workflow.add_node(\u0026#34;write_to_file\u0026#34;, write_to_file_node) # 定义流程 workflow.set_entry_point(\u0026#34;ocr\u0026#34;) workflow.add_edge(\u0026#34;ocr\u0026#34;, \u0026#34;translate\u0026#34;) workflow.add_edge(\u0026#34;translate\u0026#34;, \u0026#34;write_to_file\u0026#34;) workflow.add_edge(\u0026#34;write_to_file\u0026#34;, END) return workflow.compile() # 主函数 def main(image_path: str, output_file: str = \u0026#34;translated_output.txt\u0026#34;): # 初始化状态 state = AgentState( image_path=image_path, prompt=\u0026#34;识别图片中的日文，并将其翻译成中文\u0026#34;, extracted_text=None, translated_text=None, output_file=output_file ) # 创建并运行工作流 app = create_workflow() final_state = app.invoke(state) return final_state if __name__ == \u0026#34;__main__\u0026#34;: # 示例用法 image_path = \u0026#34;path_to_your_image.jpg\u0026#34; output_file = \u0026#34;translated_output.txt\u0026#34; result = main(image_path, output_file) print(f\u0026#34;处理完成！翻译结果已保存至 {output_file}\u0026#34;) print(f\u0026#34;提取的日文: {result[\u0026#39;extracted_text\u0026#39;]}\u0026#34;) print(f\u0026#34;翻译的中文: {result[\u0026#39;translated_text\u0026#39;]}\u0026#34;) 上述需求 LanChain 足够了 ，LangChain 实现：\n",
  "keywords": [
    "Agent", "LangGraph"
  ],
  "articleBody": "我的目标 有 call tools 能力的 LLM 有识别图片中文字的 LLM 有翻译功能（日-\u003e中）的 LLM 我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。\n请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？\n子任务一 识别图片中的日文，并将其翻译成中文\nLangGraph 实现：\nimport os from langgraph.graph import StateGraph, END from typing import TypedDict, Optional from PIL import Image import pytesseract from transformers import AutoTokenizer, AutoModelForSeq2SeqLM import torch # 定义状态 class AgentState(TypedDict): image_path: str prompt: str extracted_text: Optional[str] translated_text: Optional[str] output_file: str # 节点1：OCR提取日文 def ocr_node(state: AgentState) -\u003e AgentState: try: image = Image.open(state[\"image_path\"]) text = pytesseract.image_to_string(image, lang='jpn') state[\"extracted_text\"] = text.strip() return state except Exception as e: state[\"extracted_text\"] = f\"OCR错误: {str(e)}\" return state # 节点2：翻译日文到中文 def translate_node(state: AgentState) -\u003e AgentState: if not state[\"extracted_text\"] or \"错误\" in state[\"extracted_text\"]: state[\"translated_text\"] = \"无法翻译: 无有效文本\" return state try: # 使用Hugging Face的翻译模型 model_name = \"Helsinki-NLP/opus-mt-ja-zh\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSeq2SeqLM.from_pretrained(model_name) inputs = tokenizer(state[\"extracted_text\"], return_tensors=\"pt\", padding=True) with torch.no_grad(): outputs = model.generate(**inputs) translated = tokenizer.decode(outputs[0], skip_special_tokens=True) state[\"translated_text\"] = translated return state except Exception as e: state[\"translated_text\"] = f\"翻译错误: {str(e)}\" return state # 节点3：写入文件 def write_to_file_node(state: AgentState) -\u003e AgentState: try: with open(state[\"output_file\"], \"w\", encoding=\"utf-8\") as f: f.write(state[\"translated_text\"] or \"无翻译结果\") return state except Exception as e: state[\"translated_text\"] = f\"文件写入错误: {str(e)}\" return state # 创建工作流 def create_workflow(): workflow = StateGraph(AgentState) # 添加节点 workflow.add_node(\"ocr\", ocr_node) workflow.add_node(\"translate\", translate_node) workflow.add_node(\"write_to_file\", write_to_file_node) # 定义流程 workflow.set_entry_point(\"ocr\") workflow.add_edge(\"ocr\", \"translate\") workflow.add_edge(\"translate\", \"write_to_file\") workflow.add_edge(\"write_to_file\", END) return workflow.compile() # 主函数 def main(image_path: str, output_file: str = \"translated_output.txt\"): # 初始化状态 state = AgentState( image_path=image_path, prompt=\"识别图片中的日文，并将其翻译成中文\", extracted_text=None, translated_text=None, output_file=output_file ) # 创建并运行工作流 app = create_workflow() final_state = app.invoke(state) return final_state if __name__ == \"__main__\": # 示例用法 image_path = \"path_to_your_image.jpg\" output_file = \"translated_output.txt\" result = main(image_path, output_file) print(f\"处理完成！翻译结果已保存至 {output_file}\") print(f\"提取的日文: {result['extracted_text']}\") print(f\"翻译的中文: {result['translated_text']}\") 上述需求 LanChain 足够了 ，LangChain 实现：\nfrom langchain_core.tools import tool from langchain.agents import AgentExecutor, create_react_agent from langchain.prompts import PromptTemplate from PIL import Image import pytesseract from transformers import AutoTokenizer, AutoModelForSeq2SeqLM import torch import os # 定义工具 @tool def ocr_image(image_path: str) -\u003e str: \"\"\"从图片中提取日文文本\"\"\" try: image = Image.open(image_path) text = pytesseract.image_to_string(image, lang='jpn') return text.strip() except Exception as e: return f\"OCR错误: {str(e)}\" @tool def translate_ja_to_zh(text: str) -\u003e str: \"\"\"将日文翻译成中文\"\"\" if not text or \"错误\" in text: return \"无法翻译: 无有效文本\" try: model_name = \"Helsinki-NLP/opus-mt-ja-zh\" tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForSeq2SeqLM.from_pretrained(model_name) inputs = tokenizer(text, return_tensors=\"pt\", padding=True) with torch.no_grad(): outputs = model.generate(**inputs) translated = tokenizer.decode(outputs[0], skip_special_tokens=True) return translated except Exception as e: return f\"翻译错误: {str(e)}\" @tool def write_to_file(text: str, output_file: str) -\u003e str: \"\"\"将文本写入文件\"\"\" try: with open(output_file, \"w\", encoding=\"utf-8\") as f: f.write(text) return f\"成功写入文件: {output_file}\" except Exception as e: return f\"文件写入错误: {str(e)}\" # 创建提示模板 prompt_template = PromptTemplate( input_variables=[\"input\", \"agent_scratchpad\"], template=\"\"\" 你是一个能够处理图像中文本的AI助手。你的任务是： 1. 从图片中提取日文文本 2. 将提取的日文翻译成中文 3. 将翻译结果写入文件 用户输入：{input} 使用以下工具完成任务： - ocr_image: 从图片提取日文 - translate_ja_to_zh: 翻译日文到中文 - write_to_file: 写入文件 {agent_scratchpad} \"\"\" ) # 主函数 def main(image_path: str, output_file: str = \"translated_output.txt\"): from langchain_openai import ChatOpenAI # 初始化语言模型（这里使用模拟的LLM，实际可替换为OpenAI或其他） llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) # 定义工具列表 tools = [ocr_image, translate_ja_to_zh, write_to_file] # 创建代理 agent = create_react_agent(llm, tools, prompt_template) agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # 执行任务 input_prompt = f\"从图片 {image_path} 中提取日文，翻译成中文，并将结果写入 {output_file}\" result = agent_executor.invoke({\"input\": input_prompt}) return result[\"output\"] if __name__ == \"__main__\": # 示例用法 image_path = \"path_to_your_image.jpg\" # 替换为实际图片路径 output_file = \"translated_output.txt\" result = main(image_path, output_file) print(f\"处理完成！结果: {result}\") 子任务二 我有一个文件 txt，构造一个 Ai Agent，它读取这个txt，找到其中所有与汽车相关的名词，然后分别解释这些名词的含义及其功能和使用方法。请使用 LangChain 或 LangGraph 实现。这个过程可以是两个步骤，第一步的prompt是 “找到其中所有与汽车相关的名词”，第二步的prompt是“解释这些名词的含义及其功能和使用方法”。给出构造的code\n实现一：\nfrom langchain_ollama import ChatOllama from langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import JsonOutputParser from langgraph.prebuilt import create_react_agent import os import json # 移除代理设置 os.environ.pop(\"http_proxy\", None) os.environ.pop(\"https_proxy\", None) # 初始化 ChatOllama infer_server_url = \"http://localhost:11434\" model_name = \"qwen3:1.7b\" model = ChatOllama( model=model_name, base_url=infer_server_url, api_key=\"none\", temperature=0, stream=False ) # 读取文本文件 def read_text_file(file_path: str) -\u003e str: \"\"\"读取指定路径的文本文件内容\"\"\" try: with open(file_path, 'r', encoding='utf-8') as file: return file.read() except Exception as e: return f\"读取文件失败: {str(e)}\" # 工具 1：提取汽车相关名词 def extract_car_nouns(text: str) -\u003e dict: \"\"\"从文本中提取汽车相关名词\"\"\" prompt = ChatPromptTemplate.from_messages([ (\"system\", \"\"\" 从以下文本中提取所有与汽车相关的名词，返回 JSON 格式： { \"nouns\": [\"名词1\", \"名词2\", ...] } 确保只提取与汽车直接相关的名词（如部件、系统等），忽略非名词或无关词汇。 文本：{text} \"\"\"), (\"human\", \"{input}\") ]) chain = prompt | model | JsonOutputParser() return chain.invoke({\"input\": text, \"text\": text}) # 工具 2：解释名词的含义、功能和使用方法 def explain_car_nouns(nouns: str) -\u003e dict: \"\"\"解释汽车相关名词的含义、功能和使用方法\"\"\" prompt = ChatPromptTemplate.from_messages([ (\"system\", \"\"\" 对于以下汽车相关名词列表，解释每个名词的含义、功能和使用方法，返回 JSON 格式： { \"explanations\": [ {\"noun\": \"名词1\", \"meaning\": \"含义\", \"function\": \"功能\", \"usage\": \"使用方法\"}, ... ] } 名词列表：{nouns} \"\"\"), (\"human\", \"{input}\") ]) chain = prompt | model | JsonOutputParser() return chain.invoke({\"input\": nouns, \"nouns\": nouns}) # 创建 ReAct 代理 tools = [extract_car_nouns, explain_car_nouns] agent = create_react_agent(model=model, tools=tools, debug=True) # 主逻辑：处理文件并运行代理 def process_car_file(file_path: str): # 读取文件 text_content = read_text_file(file_path) if \"失败\" in text_content: return {\"error\": text_content} # 步骤 1：提取名词 try: extract_response = extract_car_nouns(text_content) if not extract_response.get(\"nouns\"): return {\"error\": \"未提取到汽车相关名词\"} nouns = extract_response[\"nouns\"] except Exception as e: return {\"error\": f\"提取名词失败: {str(e)}\"} # 步骤 2：解释名词 try: explain_response = explain_car_nouns(json.dumps(nouns)) return { \"nouns\": nouns, \"explanations\": explain_response[\"explanations\"] } except Exception as e: return {\"error\": f\"解释名词失败: {str(e)}\"} # 测试查询 file_path = \"car_info.txt\" result = process_car_file(file_path) # 输出结果 print(\"代理响应:\", json.dumps(result, ensure_ascii=False, indent=2)) 实现二：\nfrom langchain.llms import OpenAI # 你可换成其他本地部署的模型接口 from langchain.prompts import PromptTemplate from langchain.chains import LLMChain, SequentialChain from langchain.text_splitter import CharacterTextSplitter # 1. 读取txt文件内容 with open(\"your_file.txt\", \"r\", encoding=\"utf-8\") as f: file_text = f.read() # 如文本过长，可拆分;这里只是示例，假设文件不超长 # 如果需要可用下面代码分块 # splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0) # chunks = splitter.split_text(file_text) # file_text = chunks[0] # 这里只用第一块演示 # 2. 定义两个Prompt # 第一步：找到汽车相关名词 find_nouns_prompt = PromptTemplate( template=( \"请从以下文本中找出所有与汽车相关的名词，\" \"并用逗号分隔列出这些名词：\\n\" \"文本内容：\\n\" \"{text}\" ), input_variables=[\"text\"], ) # 第二步：解释每一个名词 explain_noun_prompt = PromptTemplate( template=( \"请解释名词 “{noun}” 的含义、功能和使用方法，\" \"要求清晰简洁，适合汽车行业相关人员阅读。\" ), input_variables=[\"noun\"], ) # 3. 初始化LLM，这里用OpenAI接口，你可以换成本地模型 llm = OpenAI(temperature=0) # 或用别的llm，如HuggingFacePipeline包装本地模型 # 4. 定义第一步Chain：找名词 find_nouns_chain = LLMChain(llm=llm, prompt=find_nouns_prompt, output_key=\"nouns_str\") # 5. 定义第二步Chain：解释单个名词 explain_chain = LLMChain(llm=llm, prompt=explain_noun_prompt, output_key=\"explanation\") # 6. 执行第一步，获得名词列表 first_step_result = find_nouns_chain.run(text=file_text) # first_step_result 是字符串，形如 “车轮, 引擎, 方向盘” nouns = [noun.strip() for noun in first_step_result.split(\",\") if noun.strip()] # 7. 对每个名词调用第二步Chain解释，并收集结果 explanations = {} for noun in nouns: explanation = explain_chain.run(noun=noun) explanations[noun] = explanation # 8. 输出所有解释 for noun, explanation in explanations.items(): print(f\"名词: {noun}\\n解释: {explanation}\\n{'-'*40}\") ",
  "wordCount" : "919",
  "inLanguage": "en",
  "datePublished": "2025-08-31T12:13:32+08:00",
  "dateModified": "2025-08-31T12:13:32+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ashburnLee.github.io/blog-2-hugo/agent/3.4.%E5%AE%9E%E4%BE%8Bsummarize_ocr_trans/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Junhui's Journal 2",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ashburnLee.github.io/blog-2-hugo/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://ashburnLee.github.io/blog-2-hugo/" accesskey="h" title="Junhui&#39;s Journal 2 (Alt + H)">Junhui&#39;s Journal 2</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://ashburnLee.github.io/blog-2-hugo/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      3.4.实例summarize_ocr_trans
    </h1>
    <div class="post-meta"><span title='2025-08-31 12:13:32 +0800 CST'>August 31, 2025</span>

</div>
  </header> 
  <div class="post-content"><h1 id="我的目标">我的目标<a hidden class="anchor" aria-hidden="true" href="#我的目标">#</a></h1>
<ul>
<li>有 call tools 能力的 LLM</li>
<li>有识别图片中文字的 LLM</li>
<li>有翻译功能（日-&gt;中）的 LLM</li>
</ul>
<p>我的app，有一张图片，它包含日文，首先需要一个 llm 识别图中日文，然后翻译成中文。第二步是将上述中文中提到的名词，提取出来，提取的过程可以通过写一个 tools 工具，供 Agent 调用以达到目的。用另外一个 LLM 用中文解释这些名词是什么？功能是什么？使用 LangGraph 和 Ollama 实现一个 AIagent 来实现上述的application，最好是含有 ReAct 。</p>
<p>请问我应该如何构建这个 LangGraph，每一步使用哪个 LLM（来自Ollama）？</p>
<h2 id="子任务一">子任务一<a hidden class="anchor" aria-hidden="true" href="#子任务一">#</a></h2>
<p>识别图片中的日文，并将其翻译成中文</p>
<p>LangGraph 实现：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langgraph.graph <span style="color:#f92672">import</span> StateGraph, END
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> TypedDict, Optional
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pytesseract
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoTokenizer, AutoModelForSeq2SeqLM
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义状态</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AgentState</span>(TypedDict):
</span></span><span style="display:flex;"><span>    image_path: str
</span></span><span style="display:flex;"><span>    prompt: str
</span></span><span style="display:flex;"><span>    extracted_text: Optional[str]
</span></span><span style="display:flex;"><span>    translated_text: Optional[str]
</span></span><span style="display:flex;"><span>    output_file: str
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 节点1：OCR提取日文</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ocr_node</span>(state: AgentState) <span style="color:#f92672">-&gt;</span> AgentState:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(state[<span style="color:#e6db74">&#34;image_path&#34;</span>])
</span></span><span style="display:flex;"><span>        text <span style="color:#f92672">=</span> pytesseract<span style="color:#f92672">.</span>image_to_string(image, lang<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;jpn&#39;</span>)
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;extracted_text&#34;</span>] <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;extracted_text&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;OCR错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 节点2：翻译日文到中文</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">translate_node</span>(state: AgentState) <span style="color:#f92672">-&gt;</span> AgentState:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> state[<span style="color:#e6db74">&#34;extracted_text&#34;</span>] <span style="color:#f92672">or</span> <span style="color:#e6db74">&#34;错误&#34;</span> <span style="color:#f92672">in</span> state[<span style="color:#e6db74">&#34;extracted_text&#34;</span>]:
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;translated_text&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;无法翻译: 无有效文本&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用Hugging Face的翻译模型</span>
</span></span><span style="display:flex;"><span>        model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Helsinki-NLP/opus-mt-ja-zh&#34;</span>
</span></span><span style="display:flex;"><span>        tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        model <span style="color:#f92672">=</span> AutoModelForSeq2SeqLM<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        inputs <span style="color:#f92672">=</span> tokenizer(state[<span style="color:#e6db74">&#34;extracted_text&#34;</span>], return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pt&#34;</span>, padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            outputs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>generate(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        translated <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>decode(outputs[<span style="color:#ae81ff">0</span>], skip_special_tokens<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;translated_text&#34;</span>] <span style="color:#f92672">=</span> translated
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;translated_text&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;翻译错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 节点3：写入文件</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">write_to_file_node</span>(state: AgentState) <span style="color:#f92672">-&gt;</span> AgentState:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(state[<span style="color:#e6db74">&#34;output_file&#34;</span>], <span style="color:#e6db74">&#34;w&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>write(state[<span style="color:#e6db74">&#34;translated_text&#34;</span>] <span style="color:#f92672">or</span> <span style="color:#e6db74">&#34;无翻译结果&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        state[<span style="color:#e6db74">&#34;translated_text&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;文件写入错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建工作流</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">create_workflow</span>():
</span></span><span style="display:flex;"><span>    workflow <span style="color:#f92672">=</span> StateGraph(AgentState)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 添加节点</span>
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_node(<span style="color:#e6db74">&#34;ocr&#34;</span>, ocr_node)
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_node(<span style="color:#e6db74">&#34;translate&#34;</span>, translate_node)
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_node(<span style="color:#e6db74">&#34;write_to_file&#34;</span>, write_to_file_node)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 定义流程</span>
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>set_entry_point(<span style="color:#e6db74">&#34;ocr&#34;</span>)
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_edge(<span style="color:#e6db74">&#34;ocr&#34;</span>, <span style="color:#e6db74">&#34;translate&#34;</span>)
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_edge(<span style="color:#e6db74">&#34;translate&#34;</span>, <span style="color:#e6db74">&#34;write_to_file&#34;</span>)
</span></span><span style="display:flex;"><span>    workflow<span style="color:#f92672">.</span>add_edge(<span style="color:#e6db74">&#34;write_to_file&#34;</span>, END)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> workflow<span style="color:#f92672">.</span>compile()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 主函数</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(image_path: str, output_file: str <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;translated_output.txt&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 初始化状态</span>
</span></span><span style="display:flex;"><span>    state <span style="color:#f92672">=</span> AgentState(
</span></span><span style="display:flex;"><span>        image_path<span style="color:#f92672">=</span>image_path,
</span></span><span style="display:flex;"><span>        prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;识别图片中的日文，并将其翻译成中文&#34;</span>,
</span></span><span style="display:flex;"><span>        extracted_text<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>        translated_text<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>        output_file<span style="color:#f92672">=</span>output_file
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 创建并运行工作流</span>
</span></span><span style="display:flex;"><span>    app <span style="color:#f92672">=</span> create_workflow()
</span></span><span style="display:flex;"><span>    final_state <span style="color:#f92672">=</span> app<span style="color:#f92672">.</span>invoke(state)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> final_state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 示例用法</span>
</span></span><span style="display:flex;"><span>    image_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;path_to_your_image.jpg&#34;</span>
</span></span><span style="display:flex;"><span>    output_file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;translated_output.txt&#34;</span>
</span></span><span style="display:flex;"><span>    result <span style="color:#f92672">=</span> main(image_path, output_file)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;处理完成！翻译结果已保存至 </span><span style="color:#e6db74">{</span>output_file<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;提取的日文: </span><span style="color:#e6db74">{</span>result[<span style="color:#e6db74">&#39;extracted_text&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;翻译的中文: </span><span style="color:#e6db74">{</span>result[<span style="color:#e6db74">&#39;translated_text&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>上述需求 LanChain 足够了 ，LangChain 实现：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.tools <span style="color:#f92672">import</span> tool
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.agents <span style="color:#f92672">import</span> AgentExecutor, create_react_agent
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.prompts <span style="color:#f92672">import</span> PromptTemplate
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pytesseract
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> AutoTokenizer, AutoModelForSeq2SeqLM
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义工具</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@tool</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ocr_image</span>(image_path: str) <span style="color:#f92672">-&gt;</span> str:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;从图片中提取日文文本&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        image <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(image_path)
</span></span><span style="display:flex;"><span>        text <span style="color:#f92672">=</span> pytesseract<span style="color:#f92672">.</span>image_to_string(image, lang<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;jpn&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> text<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;OCR错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@tool</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">translate_ja_to_zh</span>(text: str) <span style="color:#f92672">-&gt;</span> str:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;将日文翻译成中文&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> text <span style="color:#f92672">or</span> <span style="color:#e6db74">&#34;错误&#34;</span> <span style="color:#f92672">in</span> text:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">&#34;无法翻译: 无有效文本&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Helsinki-NLP/opus-mt-ja-zh&#34;</span>
</span></span><span style="display:flex;"><span>        tokenizer <span style="color:#f92672">=</span> AutoTokenizer<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        model <span style="color:#f92672">=</span> AutoModelForSeq2SeqLM<span style="color:#f92672">.</span>from_pretrained(model_name)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        inputs <span style="color:#f92672">=</span> tokenizer(text, return_tensors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;pt&#34;</span>, padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            outputs <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>generate(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        translated <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>decode(outputs[<span style="color:#ae81ff">0</span>], skip_special_tokens<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> translated
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;翻译错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@tool</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">write_to_file</span>(text: str, output_file: str) <span style="color:#f92672">-&gt;</span> str:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;将文本写入文件&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(output_file, <span style="color:#e6db74">&#34;w&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>write(text)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;成功写入文件: </span><span style="color:#e6db74">{</span>output_file<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;文件写入错误: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建提示模板</span>
</span></span><span style="display:flex;"><span>prompt_template <span style="color:#f92672">=</span> PromptTemplate(
</span></span><span style="display:flex;"><span>    input_variables<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;input&#34;</span>, <span style="color:#e6db74">&#34;agent_scratchpad&#34;</span>],
</span></span><span style="display:flex;"><span>    template<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    你是一个能够处理图像中文本的AI助手。你的任务是：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    1. 从图片中提取日文文本
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    2. 将提取的日文翻译成中文
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    3. 将翻译结果写入文件
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    用户输入：</span><span style="color:#e6db74">{input}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    使用以下工具完成任务：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - ocr_image: 从图片提取日文
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - translate_ja_to_zh: 翻译日文到中文
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - write_to_file: 写入文件
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    </span><span style="color:#e6db74">{agent_scratchpad}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 主函数</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(image_path: str, output_file: str <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;translated_output.txt&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">from</span> langchain_openai <span style="color:#f92672">import</span> ChatOpenAI
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 初始化语言模型（这里使用模拟的LLM，实际可替换为OpenAI或其他）</span>
</span></span><span style="display:flex;"><span>    llm <span style="color:#f92672">=</span> ChatOpenAI(model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-3.5-turbo&#34;</span>, temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 定义工具列表</span>
</span></span><span style="display:flex;"><span>    tools <span style="color:#f92672">=</span> [ocr_image, translate_ja_to_zh, write_to_file]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 创建代理</span>
</span></span><span style="display:flex;"><span>    agent <span style="color:#f92672">=</span> create_react_agent(llm, tools, prompt_template)
</span></span><span style="display:flex;"><span>    agent_executor <span style="color:#f92672">=</span> AgentExecutor(agent<span style="color:#f92672">=</span>agent, tools<span style="color:#f92672">=</span>tools, verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 执行任务</span>
</span></span><span style="display:flex;"><span>    input_prompt <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;从图片 </span><span style="color:#e6db74">{</span>image_path<span style="color:#e6db74">}</span><span style="color:#e6db74"> 中提取日文，翻译成中文，并将结果写入 </span><span style="color:#e6db74">{</span>output_file<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    result <span style="color:#f92672">=</span> agent_executor<span style="color:#f92672">.</span>invoke({<span style="color:#e6db74">&#34;input&#34;</span>: input_prompt})
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> result[<span style="color:#e6db74">&#34;output&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 示例用法</span>
</span></span><span style="display:flex;"><span>    image_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;path_to_your_image.jpg&#34;</span>  <span style="color:#75715e"># 替换为实际图片路径</span>
</span></span><span style="display:flex;"><span>    output_file <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;translated_output.txt&#34;</span>
</span></span><span style="display:flex;"><span>    result <span style="color:#f92672">=</span> main(image_path, output_file)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;处理完成！结果: </span><span style="color:#e6db74">{</span>result<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><h2 id="子任务二">子任务二<a hidden class="anchor" aria-hidden="true" href="#子任务二">#</a></h2>
<p>我有一个文件 txt，构造一个 Ai Agent，它读取这个txt，找到其中所有与汽车相关的名词，然后分别解释这些名词的含义及其功能和使用方法。请使用 LangChain 或 LangGraph 实现。这个过程可以是两个步骤，第一步的prompt是 “找到其中所有与汽车相关的名词”，第二步的prompt是“解释这些名词的含义及其功能和使用方法”。给出构造的code</p>
<p>实现一：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_ollama <span style="color:#f92672">import</span> ChatOllama
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.prompts <span style="color:#f92672">import</span> ChatPromptTemplate
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.output_parsers <span style="color:#f92672">import</span> JsonOutputParser
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langgraph.prebuilt <span style="color:#f92672">import</span> create_react_agent
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 移除代理设置</span>
</span></span><span style="display:flex;"><span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>pop(<span style="color:#e6db74">&#34;http_proxy&#34;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>os<span style="color:#f92672">.</span>environ<span style="color:#f92672">.</span>pop(<span style="color:#e6db74">&#34;https_proxy&#34;</span>, <span style="color:#66d9ef">None</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 初始化 ChatOllama</span>
</span></span><span style="display:flex;"><span>infer_server_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://localhost:11434&#34;</span>
</span></span><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;qwen3:1.7b&#34;</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> ChatOllama(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model_name,
</span></span><span style="display:flex;"><span>    base_url<span style="color:#f92672">=</span>infer_server_url,
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;none&#34;</span>,
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    stream<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 读取文本文件</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_text_file</span>(file_path: str) <span style="color:#f92672">-&gt;</span> str:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;读取指定路径的文本文件内容&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(file_path, <span style="color:#e6db74">&#39;r&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;utf-8&#39;</span>) <span style="color:#66d9ef">as</span> file:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> file<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;读取文件失败: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 工具 1：提取汽车相关名词</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_car_nouns</span>(text: str) <span style="color:#f92672">-&gt;</span> dict:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;从文本中提取汽车相关名词&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    prompt <span style="color:#f92672">=</span> ChatPromptTemplate<span style="color:#f92672">.</span>from_messages([
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">从以下文本中提取所有与汽车相关的名词，返回 JSON 格式：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;nouns&#34;: [&#34;名词1&#34;, &#34;名词2&#34;, ...]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">确保只提取与汽车直接相关的名词（如部件、系统等），忽略非名词或无关词汇。
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">文本：</span><span style="color:#e6db74">{text}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>),
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;human&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{input}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>    chain <span style="color:#f92672">=</span> prompt <span style="color:#f92672">|</span> model <span style="color:#f92672">|</span> JsonOutputParser()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> chain<span style="color:#f92672">.</span>invoke({<span style="color:#e6db74">&#34;input&#34;</span>: text, <span style="color:#e6db74">&#34;text&#34;</span>: text})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 工具 2：解释名词的含义、功能和使用方法</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">explain_car_nouns</span>(nouns: str) <span style="color:#f92672">-&gt;</span> dict:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;解释汽车相关名词的含义、功能和使用方法&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    prompt <span style="color:#f92672">=</span> ChatPromptTemplate<span style="color:#f92672">.</span>from_messages([
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">对于以下汽车相关名词列表，解释每个名词的含义、功能和使用方法，返回 JSON 格式：
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">{
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  &#34;explanations&#34;: [
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    {&#34;noun&#34;: &#34;名词1&#34;, &#34;meaning&#34;: &#34;含义&#34;, &#34;function&#34;: &#34;功能&#34;, &#34;usage&#34;: &#34;使用方法&#34;},
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    ...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">}
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">名词列表：</span><span style="color:#e6db74">{nouns}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>),
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;human&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{input}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>    chain <span style="color:#f92672">=</span> prompt <span style="color:#f92672">|</span> model <span style="color:#f92672">|</span> JsonOutputParser()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> chain<span style="color:#f92672">.</span>invoke({<span style="color:#e6db74">&#34;input&#34;</span>: nouns, <span style="color:#e6db74">&#34;nouns&#34;</span>: nouns})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建 ReAct 代理</span>
</span></span><span style="display:flex;"><span>tools <span style="color:#f92672">=</span> [extract_car_nouns, explain_car_nouns]
</span></span><span style="display:flex;"><span>agent <span style="color:#f92672">=</span> create_react_agent(model<span style="color:#f92672">=</span>model, tools<span style="color:#f92672">=</span>tools, debug<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 主逻辑：处理文件并运行代理</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_car_file</span>(file_path: str):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 读取文件</span>
</span></span><span style="display:flex;"><span>    text_content <span style="color:#f92672">=</span> read_text_file(file_path)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#34;失败&#34;</span> <span style="color:#f92672">in</span> text_content:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;error&#34;</span>: text_content}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 步骤 1：提取名词</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        extract_response <span style="color:#f92672">=</span> extract_car_nouns(text_content)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> extract_response<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;nouns&#34;</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;error&#34;</span>: <span style="color:#e6db74">&#34;未提取到汽车相关名词&#34;</span>}
</span></span><span style="display:flex;"><span>        nouns <span style="color:#f92672">=</span> extract_response[<span style="color:#e6db74">&#34;nouns&#34;</span>]
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;error&#34;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;提取名词失败: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 步骤 2：解释名词</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        explain_response <span style="color:#f92672">=</span> explain_car_nouns(json<span style="color:#f92672">.</span>dumps(nouns))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;nouns&#34;</span>: nouns,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;explanations&#34;</span>: explain_response[<span style="color:#e6db74">&#34;explanations&#34;</span>]
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;error&#34;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;解释名词失败: </span><span style="color:#e6db74">{</span>str(e)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 测试查询</span>
</span></span><span style="display:flex;"><span>file_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;car_info.txt&#34;</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> process_car_file(file_path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 输出结果</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;代理响应:&#34;</span>, json<span style="color:#f92672">.</span>dumps(result, ensure_ascii<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>))
</span></span></code></pre></div><p>实现二：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.llms <span style="color:#f92672">import</span> OpenAI  <span style="color:#75715e"># 你可换成其他本地部署的模型接口</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.prompts <span style="color:#f92672">import</span> PromptTemplate
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains <span style="color:#f92672">import</span> LLMChain, SequentialChain
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.text_splitter <span style="color:#f92672">import</span> CharacterTextSplitter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 1. 读取txt文件内容</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;your_file.txt&#34;</span>, <span style="color:#e6db74">&#34;r&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>    file_text <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如文本过长，可拆分;这里只是示例，假设文件不超长</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 如果需要可用下面代码分块</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># chunks = splitter.split_text(file_text)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># file_text = chunks[0]  # 这里只用第一块演示</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 2. 定义两个Prompt</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第一步：找到汽车相关名词</span>
</span></span><span style="display:flex;"><span>find_nouns_prompt <span style="color:#f92672">=</span> PromptTemplate(
</span></span><span style="display:flex;"><span>    template<span style="color:#f92672">=</span>(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;请从以下文本中找出所有与汽车相关的名词，&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;并用逗号分隔列出这些名词：</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;文本内容：</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{text}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    ),
</span></span><span style="display:flex;"><span>    input_variables<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;text&#34;</span>],
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 第二步：解释每一个名词</span>
</span></span><span style="display:flex;"><span>explain_noun_prompt <span style="color:#f92672">=</span> PromptTemplate(
</span></span><span style="display:flex;"><span>    template<span style="color:#f92672">=</span>(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;请解释名词 “</span><span style="color:#e6db74">{noun}</span><span style="color:#e6db74">” 的含义、功能和使用方法，&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;要求清晰简洁，适合汽车行业相关人员阅读。&#34;</span>
</span></span><span style="display:flex;"><span>    ),
</span></span><span style="display:flex;"><span>    input_variables<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;noun&#34;</span>],
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 3. 初始化LLM，这里用OpenAI接口，你可以换成本地模型</span>
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> OpenAI(temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)  <span style="color:#75715e"># 或用别的llm，如HuggingFacePipeline包装本地模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 4. 定义第一步Chain：找名词</span>
</span></span><span style="display:flex;"><span>find_nouns_chain <span style="color:#f92672">=</span> LLMChain(llm<span style="color:#f92672">=</span>llm, prompt<span style="color:#f92672">=</span>find_nouns_prompt, output_key<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;nouns_str&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 5. 定义第二步Chain：解释单个名词</span>
</span></span><span style="display:flex;"><span>explain_chain <span style="color:#f92672">=</span> LLMChain(llm<span style="color:#f92672">=</span>llm, prompt<span style="color:#f92672">=</span>explain_noun_prompt, output_key<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;explanation&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 6. 执行第一步，获得名词列表</span>
</span></span><span style="display:flex;"><span>first_step_result <span style="color:#f92672">=</span> find_nouns_chain<span style="color:#f92672">.</span>run(text<span style="color:#f92672">=</span>file_text)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># first_step_result 是字符串，形如 “车轮, 引擎, 方向盘”</span>
</span></span><span style="display:flex;"><span>nouns <span style="color:#f92672">=</span> [noun<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> noun <span style="color:#f92672">in</span> first_step_result<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;,&#34;</span>) <span style="color:#66d9ef">if</span> noun<span style="color:#f92672">.</span>strip()]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 7. 对每个名词调用第二步Chain解释，并收集结果</span>
</span></span><span style="display:flex;"><span>explanations <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> noun <span style="color:#f92672">in</span> nouns:
</span></span><span style="display:flex;"><span>    explanation <span style="color:#f92672">=</span> explain_chain<span style="color:#f92672">.</span>run(noun<span style="color:#f92672">=</span>noun)
</span></span><span style="display:flex;"><span>    explanations[noun] <span style="color:#f92672">=</span> explanation
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 8. 输出所有解释</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> noun, explanation <span style="color:#f92672">in</span> explanations<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;名词: </span><span style="color:#e6db74">{</span>noun<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">解释: </span><span style="color:#e6db74">{</span>explanation<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;-&#39;</span><span style="color:#f92672">*</span><span style="color:#ae81ff">40</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/agent/">Agent</a></li>
      <li><a href="https://ashburnLee.github.io/blog-2-hugo/tags/langgraph/">LangGraph</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://ashburnLee.github.io/blog-2-hugo/">Junhui&#39;s Journal 2</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
