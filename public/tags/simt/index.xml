<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>SIMT on Junhui&#39;s Journal 2</title>
    <link>https://ashburnLee.github.io/blog-2-hugo/tags/simt/</link>
    <description>Recent content in SIMT on Junhui&#39;s Journal 2</description>
    <generator>Hugo -- 0.149.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Aug 2025 12:45:51 +0800</lastBuildDate>
    <atom:link href="https://ashburnLee.github.io/blog-2-hugo/tags/simt/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kernel 向量化 SIMT</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simt/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:51 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/kernel-%E5%90%91%E9%87%8F%E5%8C%96-simt/</guid>
      <description>&lt;p&gt;NVIDIA GPU 架构是 SIMT，而编译器又会利用 SIMD 指令来优化 int4 类型的操作，这看起来似乎有些矛盾，但实际上它们并不冲突。&lt;/p&gt;
&lt;h2 id=&#34;simt-和-simd-的关系&#34;&gt;SIMT 和 SIMD 的关系&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SIMT 是&lt;strong&gt;架构层面&lt;/strong&gt;：SIMT 描述的是 NVIDIA GPU 的整体架构和执行模型。它指的是多个线程（以 warp 为单位）执行相同的指令，但处理不同的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SIMD 是&lt;strong&gt;指令层面&lt;/strong&gt;：SIMD 是一种指令集，它允许一条指令同时操作多个数据。编译器可以使用 SIMD 指令来优化代码，提高程序的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以 NV GPU 是 SIMT 架构的：决定了它的基本执行方式：多个线程（warp）执行相同的指令。同时又有 SIMD 优化的：在 SIMT 架构下，编译器仍然可以利用 SIMD 指令来优化代码。例如，对于 int4 类型的操作，编译器可以使用 SIMD 指令一次性加载、存储和计算 4 个整数。&lt;/p&gt;
&lt;p&gt;SIMT 是 NVIDIA GPU 的专有模型，依赖 SM 和 warp 调度。Multiple Thread 体现在Warp内线程异步执行相同指令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;__global__ &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;add&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; a, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; b, &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; c, &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; n) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blockIdx.x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; blockDim.x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; threadIdx.x;  &lt;span style=&#34;color:#75715e&#34;&gt;// 每个线程独立索引
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (idx &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; n) c[idx] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a[idx] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b[idx];  &lt;span style=&#34;color:#75715e&#34;&gt;// SIMT：warp 内线程并行执行加法
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
