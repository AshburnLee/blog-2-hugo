<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Unified Memory on Junhui&#39;s Journal 2</title>
    <link>https://ashburnLee.github.io/blog-2-hugo/tags/unified-memory/</link>
    <description>Recent content in Unified Memory on Junhui&#39;s Journal 2</description>
    <generator>Hugo -- 0.149.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Aug 2025 12:45:57 +0800</lastBuildDate>
    <atom:link href="https://ashburnLee.github.io/blog-2-hugo/tags/unified-memory/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>概念 Unified Memory</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-unified-memory/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-unified-memory/</guid>
      <description>&lt;h2 id=&#34;统一内存编程-unified-memory&#34;&gt;统一内存编程 Unified Memory&lt;/h2&gt;
&lt;p&gt;它允许开发者在编写并行计算程序时，不必显式地管理数据在 CPU 和 GPU 之间的传输。统一内存的引入旨在简化 CUDA 编程，提高开发效率，并通过自动将数据迁移到正在使用它的处理器上来优化数据访问速度。&lt;/p&gt;
&lt;p&gt;统一内存的工作原理是提供一个单一的、连续的虚拟地址空间，这个空间对系统中的所有处理器（包括 CPU 和 GPU ）都是可见的。底层的 CUDA 运行时系统负责管理数据的实际物理位置，并在必要时自动将数据迁移到适当的设备上。这意味着开发者可以使用&lt;strong&gt;单一的指针&lt;/strong&gt;来引用统一内存中的数据，而不需要担心数据实际上是存储在主机内存还是GPU显存中。&lt;/p&gt;
&lt;p&gt;统一内存提供了诸多便利，但它也可能引入一些问题，如内存抖动。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
