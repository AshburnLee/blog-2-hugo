<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Stream on Junhui&#39;s Journal 2</title>
    <link>https://ashburnLee.github.io/blog-2-hugo/tags/stream/</link>
    <description>Recent content in Stream on Junhui&#39;s Journal 2</description>
    <generator>Hugo -- 0.149.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 31 Aug 2025 12:45:57 +0800</lastBuildDate>
    <atom:link href="https://ashburnLee.github.io/blog-2-hugo/tags/stream/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>概念 Stream</title>
      <link>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-stream/</link>
      <pubDate>Sun, 31 Aug 2025 12:45:57 +0800</pubDate>
      <guid>https://ashburnLee.github.io/blog-2-hugo/cuda-notes/%E6%A6%82%E5%BF%B5-stream/</guid>
      <description>&lt;h2 id=&#34;多-stream-用于-overlap-datatransfer&#34;&gt;多 stream 用于 overlap datatransfer&lt;/h2&gt;
&lt;p&gt;并发，隐藏延时要实现数据传输与其他操作的重叠，需要使用 CUDA 流.&lt;/p&gt;
&lt;p&gt;CUDA 中的流是一系列按主机代码发出的顺序在设备上执行的运算。虽然流内的运算保证按预定顺序执行，但不同流中的运算可以交错执行，并且在可能的情况下，它们甚至可以并行运行。***&lt;/p&gt;
&lt;p&gt;所有 CUDA 中在 device 中的操作（内核和数据传输）都在流中运行。当未指定流时，使用默认流（也称为“空流”）。默认流与其他流不同，因为它是一个与设备操作同步的流。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;a, &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d_a;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaMallocHost((&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;a, bytes);   &lt;span style=&#34;color:#75715e&#34;&gt;// 弃用的   // host pinned 更推荐使用 cudaHostAlloc
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaMalloc((&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;d_a, bytes);    &lt;span style=&#34;color:#75715e&#34;&gt;// device
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// create events and streams
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  cudaEvent_t startEvent, stopEvent, dummyEvent;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaStream_t stream[nStreams];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;startEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;stopEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cudaEventCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;dummyEvent);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; nStreams; &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;i)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cudaStreamCreate(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;stream[i]);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在默认流中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// baseline case - sequential transfer and execute
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  memset(a, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, bytes);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventRecord(startEvent,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaMemcpy(d_a, a, bytes, cudaMemcpyHostToDevice) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  kernel&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;n&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;blockSize, blockSize&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;(d_a, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaMemcpy(a, d_a, bytes, cudaMemcpyDeviceToHost) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventRecord(stopEvent, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventSynchronize(stopEvent) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  checkCuda( cudaEventElapsedTime(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;ms, startEvent, stopEvent) );
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Time for sequential transfer and execute (ms): %f&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, ms);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  printf(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;  max error: %e&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;, maxError(a, n));
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;版本1：asynchronous version 1: loop over {copy, kernel-exe, copy-back}&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
